[
  {
    "answerId": 39618787,
    "question": "EC2 instances",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Resharding enables you to increase or decrease the number of shards in a stream in order to adapt to changes in the rate of data flowing through the stream. The Kinesis Client Library (KCL) ensures that for every shard there is a record processor running and processing that shard. It also tracks the shards in the stream using an Amazon DynamoDB table. When new shards are created as a result of resharding, the KCL discovers the new shards and populates new rows in the table. The workers automatically discover the new shards and create processors to handle the data from them. The KCL also distributes the shards in the stream across all the available workers and record processors.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By increasing the instance size and number of shards in your Kinesis stream, the developer allows the instances to handle more record processors, which are running in parallel within the instance. It also allows the stream to properly accommodate the rate of data being sent in. The data capacity of your stream is a function of the number of shards that you specify for the stream. The total capacity of the stream is the sum of the capacities of its shards.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_1.jpg\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Increase both the instance size and the number of open shards</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Increase the instance size to a larger type</strong></b><span>&nbsp;is incorrect.</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b><span>Increasing the instance size alone is incorrect because the current number of Kinesis shards is not enough to accommodate the rate of data flowing through the stream. In this scenario, the best solution is to reshard or to increase the number of shards in the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Increase the number of shards&nbsp;</strong></b><span>is incorrect. This is not enough because the instances cannot hold any more record processors, due to CPU Utilization maxing out. You should either increase the instance size or number of instances along with the increase of shards in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Increase the number of instances up to the number of open shards&nbsp;</strong></b><span>is incorrect because this scenario requires resharding to adapt to changes in the rate of data flowing through the stream. Although adding new instances will improve the compute capacity, the rate of data flowing through the stream would still be low since the number of shards is still unchanged.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References</strong></b><span>:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/building-consumers.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/building-consumers.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557755,
        "value": "Increase the number of shards.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557756,
        "value": "Increase the instance size to a larger type.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557757,
        "value": "Increase the number of instances up to the number of open shards.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557758,
        "value": "Increase both the instance size and the number of open shards.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 0,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557758,
        "questionId": 388633,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388633,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer has a set of EC2 instances that runs the Amazon Kinesis Client Library to process a data stream in AWS. Based on the custom metrics, it shows that the instances are maxing out their CPU Utilization, and there are insufficient Kinesis shards to handle the rate of data flowing through the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the BEST course of action that the developer should take to solve this issue and prevent this situation from re-occurring in the future?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618788,
    "question": "AWS service ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon Cognito identity pools provide temporary AWS credentials for users who are guests (unauthenticated) and for users who have been authenticated and received a token. An identity pool is a store of user identity data specific to your account.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon Cognito identity pools enable you to create unique identities and assign permissions for users. Your identity pool can include:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Users in an Amazon Cognito user pool</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Users who authenticate with external identity providers such as Facebook, Google, or a SAML-based identity provider</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Users authenticated via your own existing authentication process</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>With an identity pool, you can obtain temporary AWS credentials with permissions you define to directly access other AWS services or to access resources through Amazon API Gateway.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_2.jpg\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS Cognito Identity Pools, then enable access to unauthenticated identities.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS Cognito User Pools then enabling access to unauthenticated identities&nbsp;</strong></b><span>is incorrect because a&nbsp;user pool is just a user directory in Amazon Cognito. In addition, this doesn’t enable the mobile game access to unauthenticated identities. You have to use an Identity Pool instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use Amazon Cognito Sync</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this is just a client library that enables cross-device syncing of application-related user data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS IAM Identity Center</strong></b><span>&nbsp;is incorrect because this&nbsp;service just makes it easy for you to centrally manage workforce access to multiple AWS accounts. It also does not allow any “guest” or unauthenticated access, unlike AWS Cognito.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-identity-pools.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-identity-pools.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557759,
        "value": "Use Amazon Cognito Sync.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557760,
        "value": "Use AWS Cognito Identity Pools then enable access to unauthenticated identities.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557761,
        "value": "Use AWS IAM Identity Center.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557762,
        "value": "Use AWS Cognito User Pools then enable access to unauthenticated identities.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 1,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557760,
        "questionId": 388634,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388634,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A mobile game is currently being developed and needs to have an authentication service. You need to use an AWS service which provides temporary AWS credentials for users who have been authenticated via their social media logins as well as for guest users who do not require any authentication.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How can you BEST achieve this using AWS?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618789,
    "question": "Amazon ECS Cluster",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The binpack strategy tries to fit your workloads in as few instances as possible. It gets its name from the bin packing problem where the goal is to fit objects of various sizes in the smallest number of bins. It is well suited to scenarios for minimizing the number of instances in your cluster, perhaps for cost savings, and lends itself well to automatic scaling for elastic workloads, to shut down instances that are not in use.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">task placement strategy</strong></b><span>&nbsp;is an algorithm for selecting instances for task placement or tasks for termination. Task placement strategies can be specified when either running a task or creating a new service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon ECS supports the following task placement strategies:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">binpack</strong></b><span>&nbsp;– Place tasks based on the least available amount of CPU or memory. This minimizes the number of instances in use.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">random</strong></b><span>&nbsp;– Place tasks randomly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">spread</strong></b><span>&nbsp;– Place tasks evenly based on the specified value. Accepted values are attribute key-value pairs,&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">instanceId</em></i><span>, or&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">host</em></i><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_3.jpg\"><span>When you use the binpack strategy, you must also indicate if you are trying to make optimal use of your instances’ CPU or memory. This is done by passing an extra field parameter, which tells the task placement engine which parameter to use to evaluate how “full” your “bins” are. It then chooses the instance with the least available CPU or memory (depending on which you pick). If there are multiple instances with this CPU or memory remaining, it chooses randomly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By spreading tasks among your EC2 instances using the binpack strategy, you can minimize costs and resource consumption since this strategy maximizes available CPU/memory of your already running instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Distribute tasks among all registered EC2 instances based on the least available amount of CPU or memory using the&nbsp;binpack&nbsp;task placement strategy.&nbsp;</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Distribute tasks evenly across all available EC2 instances using the&nbsp;spread&nbsp;task placement strategy&nbsp;</strong></b><span>is incorrect because&nbsp;this strategy is typically used to achieve high availability by making sure that multiple copies of a task are scheduled across multiple instances based on attributes such as Availability Zones. Since the scenario is focused on cost rather than availability, this option is clearly not suitable for this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Place tasks randomly using the&nbsp;random&nbsp;task placement strategy&nbsp;</strong></b><span>is incorrect. Random task placement just ensures tasks are run on instances with sufficient resources to complete them. Binpack has better cost-savings since it strategically places tasks in as few instances as possible.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Distribute tasks evenly across Availability Zones, and then re-distributing the tasks among EC2 instances based on the least available amount of CPU/memory within each Availability Zone&nbsp;</strong></b><span>is incorrect. Although it will meet the required task placement, this method will use more unnecessary EC2 instances. Take note that the scenario requires you to minimize the number of instances in use, which will keep the cost down.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/compute/amazon-ecs-task-placement/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/compute/amazon-ecs-task-placement/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/compute/amazon-ecs-task-placement/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/compute/amazon-ecs-task-placement/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-strategies.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557763,
        "value": "Distribute tasks evenly across Availability Zones, and then re-distribute the tasks among EC2 instances based on the least available amount of CPU/memory within each Availability Zone.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557764,
        "value": "Place tasks randomly using the random task placement strategy.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557765,
        "value": "Distribute tasks among all registered EC2 instances based on the least available amount of CPU or memory using the binpack task placement strategy.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557766,
        "value": "Distribute tasks evenly across all available EC2 instances using the spread task placement strategy.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 2,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557765,
        "questionId": 388635,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388635,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is building a prototype microservices that are running as tasks in an Amazon ECS Cluster. His manager instructed him to define a task placement strategy which needs to be both cost and resource efficient. The task placement should minimize the number of instances in use which will keep the cost down since high availability is not much of a concern for this prototype.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should the developer implement to meet the above requirements?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618790,
    "question": "Amazon SQS ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon SQS</span><i><em class=\"Editor__editor-text-italic___C9n8O\">&nbsp;FIFO First-In-First-Out</em></i><span>&nbsp;queues are designed to enhance messaging between applications when the order of operations and events is critical or where duplicates can’t be tolerated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_4ex.jpg\"><span>SQS remembers the MessageDeduplicationId values it’s seen for at least five minutes, which means deduplication Ids can only reduce, not completely eliminate, the chances of duplication occurring. For example, if a producer was unable to receive an acknowledgment after sending a message due to a network issue and then regains connection after 10 minutes and attempts to resend the message, there is a risk of duplication occurring.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, you can lessen the chances of the Lambda function processing duplicate messages by storing data in an SQS FIFO queue. You may provide a&nbsp;MessageDeduplicationId value so SQS can distinguish one message from another. Optionally, you may enable&nbsp;ContentBasedDeduplication to let SQS create an&nbsp;SHA-256 hash based on the message body and use it as the value for&nbsp;MessageDeduplicationId.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, in this scenario, the correct answer is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Add a&nbsp;MessageDeduplicationId&nbsp;parameter to the&nbsp;SendMessage&nbsp;API request.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Refactoring the Lambda function to store the message’s content and dropping the incoming messages with similar content within a 5-minute period</strong></b><i><em class=\"Editor__editor-text-italic___C9n8O\">&nbsp;</em></i><span>is incorrect because Lambda functions do not share data amongst themselves during a scale-up event. Therefore, if a function is processing a message and another function handles the succeeding message, it would not be able to compare if it is indeed a duplicate or not. You have to configure the SQS FIFO queue to use a Message Deduplication ID in order to avoid having duplicate messages.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the Amazon SQS queue to automatically drop a duplicate message whenever it arrives within the message’s&nbsp;VisibilityTimeout</strong></b><span>&nbsp;is incorrect because the visibility timeout is primarily used to prevent other consumers from processing the message again and not for detecting duplicate messages.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using an Amazon SQS Standard queue instead of a FIFO queue to avoid any duplicate messages&nbsp;</strong></b><span>is incorrect because using&nbsp;standard queues will actually introduce duplicate messages. Take note that FIFO queues help you avoid sending duplicates and not the Standard-type queue.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagededuplicationid-property.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagededuplicationid-property.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.amazonaws.cn/en_us/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.amazonaws.cn/en_us/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/developer/how-the-amazon-sqs-fifo-api-works/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/developer/how-the-amazon-sqs-fifo-api-works/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557767,
        "value": "Use an Amazon SQS Standard queue instead of a FIFO queue to avoid any duplicate messages.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557768,
        "value": "Add a MessageDeduplicationId parameter to the SendMessage API request.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557769,
        "value": "Refactor the Lambda function to store the message's content and drop the incoming messages with similar content within a 5-minute period.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557770,
        "value": "Configure the Amazon SQS queue to automatically drop a duplicate message whenever it arrives within the message’s VisibilityTimeout.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 3,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557770,
        "questionId": 388636,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388636,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer monitors multiple sensors inside a data center which detects various environmental conditions that may affect their running servers. In the current architecture, the data is initially processed by an AWS Lambda function and then stored in a remote data warehouse. To make the system more durable and scalable, the developer plans to use an Amazon SQS FIFO queue to store the data, which will be polled by the Lambda function. There is a known issue with the sensor devices sending duplicate data intermittently.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What action can the developer take to lessen the chances of processing duplicate messages?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618791,
    "question": "Lambda function",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon EventBridge (Amazon CloudWatch Events)&nbsp;</strong></b><span>helps you respond to state changes in your AWS resources. When your resources change state, they automatically send events into an event stream. You can create rules that match selected events in the stream and route them to your AWS Lambda function to take action. For example, you can automatically invoke an AWS Lambda function to log the state of an EC2 instance or AutoScaling Group. You maintain event source mapping in Amazon CloudWatch Events by using a rule target definition.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_5.jpg\"><span>You can also create a Lambda function and direct AWS Lambda to execute it on a regular schedule. You can specify a fixed rate (for example, execute a Lambda function every hour or 15 minutes), or you can specify a Cron expression.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Integrate Amazon EventBridge (Amazon CloudWatch Events) with Lambda, which will automatically trigger the function every 30 minutes.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Launch an EC2 instance that has a cron job that triggers the Lambda function every 30 minutes</strong></b><span>&nbsp;is incorrect because provisioning a new instance incurs additional costs. There is also a possibility that the Lambda function will not be invoked in the event that the instance was stopped or terminated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the Task Scheduler of your Windows PC to trigger the Lambda function every 30 minutes&nbsp;</strong></b><span>is incorrect because this setup is difficult to manage due to the fact that you are using your own computer to trigger the function. This may be the most cost-effective solution but it certainly is not the most manageable option. The best way is to integrate CloudWatch Events with Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Enable scheduling on the AWS Console of your Lambda function. Define a schedule to run it at 30-minute intervals&nbsp;</strong></b><span>is incorrect because there is no feature like this in Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-scheduled-events.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/with-scheduled-events.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557771,
        "value": "Launch an EC2 instance that has a cron job that triggers the Lambda function every 30 minutes.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557772,
        "value": "Integrate Amazon EventBridge (Amazon CloudWatch Events) with Lambda, which will automatically trigger the function every 30 minutes.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557773,
        "value": "Use the Task Scheduler of your Windows PC to trigger the Lambda function every 30 minutes.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557774,
        "value": "Enable scheduling on the AWS Console of your Lambda function. Define a schedule to run it at 30-minute intervals.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 4,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557774,
        "questionId": 388637,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388637,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has developed a Lambda function that will send status updates to a third-party provider for analytics. You need to schedule this function to run every 30 minutes. Which of the following is the MOST manageable and cost-effective way of setting up this task?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618792,
    "question": "DynamoDB database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the&nbsp;UpdateItem&nbsp;operation to implement an&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">atomic counter&nbsp;</em></i><span>— a numeric attribute that is incremented, unconditionally, without interfering with other write requests. (All write requests are applied in the order in which they were received). With an atomic counter, the updates are not idempotent. In other words, the numeric value will increment each time you call&nbsp;UpdateItem.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You might use an atomic counter to keep track of the number of visitors to a website. In this case, your application would increment a numeric value, regardless of its current value. If an&nbsp;UpdateItemoperation should fail, the application could simply retry the operation. This would risk updating the counter twice, but you could probably tolerate a slight overcounting or undercounting of website visitors.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An atomic counter would not be appropriate where overcounting or undercounting cannot be tolerated (For example, in a banking application). In this case, it is safer to use a conditional update instead of an atomic counter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">using&nbsp;atomic counters&nbsp;to increment the counter item in the DynamDB table for every new visitor</strong></b><span>&nbsp;is the most suitable solution in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using&nbsp;conditional writes&nbsp;to update the counter item in the DynamoDB table and set the&nbsp;ReturnConsumedCapacity&nbsp;parameter to&nbsp;TOTAL</strong></b><span>&nbsp;is incorrect because using conditional writes is not required for this scenario as&nbsp;the counter doesn’t need to be idempotent. Remember that it is indicated that they can tolerate a slight overcounting or undercounting of website visitors. In addition, the&nbsp;ReturnConsumedCapacity&nbsp;parameter simply returns the total number of write capacity units consumed hence, it is irrelevant in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using&nbsp;conditional writes&nbsp;to update the counter item in the DynamoDB table only if the item has a unique primary key and the new value is greater than the current value</strong></b><span>&nbsp;is incorrect because although this is a valid solution, it entails a lot of unnecessary configuration as compared to using an atomic counter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Enabling DynamoDB Streams to track the number of new visitors</strong></b><span>&nbsp;is incorrect because DynamoDB streams simply captures a time-ordered sequence of item-level modifications in the table. This is not suitable if you want to track the number of website visitors with minimal configuration.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.UpdateExpressions.html#Expressions.UpdateExpressions.SET.IncrementAndDecrement\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.UpdateExpressions.html#Expressions.UpdateExpressions.SET.IncrementAndDecrement</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557775,
        "value": "Use conditional writes to update the counter item in the DynamoDB table and set the ReturnConsumedCapacity parameter to TOTAL.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557776,
        "value": "Use atomic counters to increment the counter item in the DynamoDB table for every new visitor.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557777,
        "value": "Use conditional writes to update the counter item in the DynamoDB table only if the item has a unique primary key and the new value is greater than the current value.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557778,
        "value": "Enable DynamoDB Streams to track the number of new visitors.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 5,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557776,
        "questionId": 388638,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388638,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer wants to track the number of visitors on their website, which has a DynamoDB database. This is primarily used to give a rough idea on how many people visit the site whenever they launch a new advertisement, which means it can tolerate a slight over-counting or undercounting of website visitors.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following will satisfy the requirement with MINIMAL configuration?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618793,
    "question": "EC2 instances",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon RDS Read Replicas</strong></b><span>&nbsp;provide enhanced performance and durability for the database (DB) instances. This feature makes it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_7.jpg\"><span>You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Because read replicas can be promoted to master status, they are useful as part of a sharding implementation. To shard your database, add a read replica and promote it to master status, then, from each of the resulting DB Instances, delete the data that belongs to the other shard.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct solution in this scenario is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">create an RDS Read Replica instance and configure the application to use this for read queries</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">.&nbsp;</strong></b></i></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Launch a large ElastiCache Cluster as a database cache for RDS and apply the required code change&nbsp;</strong></b><span>is incorrect. Although this will improve the read performance of the application, this solution entails a lot of code changes in the application as compared with just using RDS Read Replicas. It is specifically mentioned in the scenario that you need to solve the issue with the minimal code change.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a multi-AZ deployment configuration in RDS</strong></b><span>&nbsp;is incorrect because configuring a Multi-AZ RDS just improves the availability of the database but does not drastically improve the read performance. The more appropriate solution for this is to use Read Replicas instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Upgrade the EC2 instances to a higher instance type</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because the issue lies with the database, not the application servers hosted in EC2 instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/caching/database-caching/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/caching/database-caching/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/rds/details/read-replicas/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/rds/details/read-replicas/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/elasticache/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/elasticache/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557779,
        "value": "Upgrade the EC2 instances to a higher instance type.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557780,
        "value": "Create an RDS Read Replica instance and configure the application to use this for read queries.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557781,
        "value": "Launch a large ElastiCache Cluster as a database cache for RDS and apply the required code change.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557782,
        "value": "Set up a multi-AZ deployments configuration in RDS.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 6,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557780,
        "questionId": 388639,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388639,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An online magazine is deployed in AWS and uses an Application Load Balancer, an Auto Scaling group of EC2 instances, and an RDS MySQL Database. Some of the readers are complaining about the website’s sluggish performance when loading the articles. Upon checking, there is a high number of read operations in the database, which affects the website’s performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following actions should you take to resolve the issue with minimal code change?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618794,
    "question": "Lambda function",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS Lambda</strong></b><span>&nbsp;is a serverless compute service that allows developers to run code without provisioning or managing servers. It automatically scales based on the workload and charges only for the compute time consumed. Developers can use Lambda to execute code in response to events such as changes in data, HTTP requests, or system state changes, making it ideal for event-driven architectures. Lambda supports multiple programming languages and integrates seamlessly with other AWS services, enabling flexible and scalable application development.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Lambda functions operate within a highly available infrastructure and manage resources automatically, ensuring reliability and performance. Lambda can execute specific business logic by using triggers like S3 events, DynamoDB streams, or API Gateway, making it a key component for building modern, agile applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_8.jpg\"><span>AWS Lambda allows developers to configure memory allocation for 128 MB to 10,240 MB functions. This memory setting directly influences the CPU resources available to the function, as Lambda allocates CPU power proportionally to the configured memory. For instance, at 1,769 MB, a function has the equivalent of one vCPU. Increasing the memory allocation provides more RAM and enhances CPU capacity, which can lead to significant performance improvements for compute-intensive tasks.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Optimize memory allocation for the Lambda function.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS Step Functions to split tasks into smaller workflows</strong></b><span>&nbsp;is incorrect. AWS Step Functions are primarily used for orchestrating workflows and breaking down complex processes into smaller, manageable steps. However, this approach does not directly improve the execution performance of the Lambda function itself. The issue lies in the Lambda function’s CPU resources, which Step Functions simply cannot address. While they can enhance task coordination, they typically do not optimize the speed of underlying tasks within a single function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Increase the timeout setting of the Lambda function</strong></b><span>&nbsp;is incorrect. This option primarily focuses on extending the maximum runtime for the Lambda function. Increasing the timeout setting would allow the function to run longer but not address the underlying inefficiencies caused by insufficient memory or CPU resources. Timeout adjustments are typically useful for handling long-running tasks, not optimizing compute-intensive workloads.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Utilize Amazon S3 Transfer Acceleration for image uploads</strong></b><span>&nbsp;is incorrect. Amazon S3 Transfer Acceleration is designed to improve the upload and download speed of objects to and from S3 by using Amazon’s global edge network. However, this feature is only relevant when data transfer speed between the client and S3 is a bottleneck. In this case, the issue lies with the processing of images within the Lambda function. Transfer Acceleration simply cannot influence the performance of compute tasks, as it is unrelated to the Lambda execution environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-memory.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/configuration-memory.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557783,
        "value": "Optimize memory allocation for the Lambda function.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557784,
        "value": "Use AWS Step Functions to split tasks into smaller workflows.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557785,
        "value": "Increase the timeout setting of the Lambda function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557786,
        "value": "Utilize Amazon S3 Transfer Acceleration for image uploads.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 7,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557783,
        "questionId": 388640,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388640,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is building an image processing utility using an AWS Lambda function. The function processes images in parallel using multiple threads to optimize performance. The images are stored in an Amazon S3 bucket and retrieved for processing. However, the function is not performing as efficiently as expected, with the processing time taking longer than anticipated, even when handling relatively small images.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which action should the developer modify to achieve better performance in the AWS Lambda function?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618795,
    "question": "SAM",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS SAM</strong></b><span>&nbsp;uses AWS CloudFormation as the underlying deployment mechanism.&nbsp;You can deploy your application by using AWS SAM command line interface (CLI) commands. You can also use other AWS services that integrate with AWS SAM to automate your deployments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_9.jpg\"><span>When deploying a SAM application, it’s vital to ensure that all components of the application are properly packaged and that all resources are provisioned correctly in the AWS environment. The&nbsp;sam build&nbsp;command serves this purpose by resolving any dependencies the application might have and constructing deployment artifacts for all functions and layers specified in the SAM template. This is especially important when the SAM template references local file paths, such as&nbsp;CodeUri&nbsp;pointing to local Lambda function codes.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Once the application has been successfully built, the next step is to deploy it. The&nbsp;sam deploy&nbsp;command allows the application to be deployed using AWS CloudFormation, ensuring that all resources defined in the SAM template are provisioned and configured correctly in the target environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answers are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Execute&nbsp;sam build&nbsp;to resolve dependencies and construct deployment artifacts for all functions and layers in the SAM template.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Use the&nbsp;sam deploy&nbsp;command to deploy the application with a specified CloudFormation stack.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Run&nbsp;sam init&nbsp;to initialize a new SAM project&nbsp;</strong></b><span>is incorrect because this command is simply used when creating&nbsp;a new SAM project, not to deploy an existing one.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Execute&nbsp;sam publish&nbsp;to make the application available in the AWS Serverless Application Repository&nbsp;</strong></b><span>is incorrect. This&nbsp;SAM CLI is used to publish applications to the AWS Serverless Application Repository, which is not a mandatory step for deploying SAM applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;sam sync&nbsp;command to synchronize the local changes to the application in AWS&nbsp;</strong></b><span>is incorrect. This command is typically used for quick syncing of local changes to AWS and is more suitable for rapid development testing. In a Production setting, a full deployment using&nbsp;sam deploy&nbsp;is more appropriate to ensure that all configurations and resources are correctly provisioned.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-deploying.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-deploying.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/serverlessrepo/latest/devguide/what-is-serverlessrepo.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/serverlessrepo/latest/devguide/what-is-serverlessrepo.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557787,
        "value": "Execute sam publish to make the application available in the AWS Serverless Application Repository.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557788,
        "value": "Use the sam sync command to synchronize the local changes to the application in AWS.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557789,
        "value": "Use the  sam deploy command to deploy the application with a specified CloudFormation stack.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557790,
        "value": "Run sam init to initialize a new SAM project.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557791,
        "value": "Execute sam build to resolve dependencies and construct deployment artifacts for all functions and layers in the SAM template.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 8,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557791,
        "questionId": 388641,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557789,
        "questionId": 388641,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388641,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A development team is working on an AWS Serverless Application Model (SAM) application with its source code hosted on GitHub. A newly recruited developer clones the repository and observes that the SAM template contains references to AWS Lambda functions with&nbsp;CodeUri&nbsp;pointing to local file paths. The developer has added a new Lambda function and must redeploy the updated version to Production.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which combination of steps must be taken to satisfy the requirement? (Select Two)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618796,
    "question": "EC2 instances ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon Kinesis Data Streams is a massively scalable, highly durable data ingestion and processing service optimized for streaming data. You can configure hundreds of thousands of data producers to continuously put data into a Kinesis data stream. Data will be available within milliseconds to your Amazon Kinesis applications, and those applications will receive data records in the order they were generated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The purpose of resharding in Amazon Kinesis Data Streams is to enable your stream to adapt to changes in the rate of data flow. You split shards to increase the capacity (and cost) of your stream. You merge shards to reduce the cost (and capacity) of your stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>One approach to resharding could be to split every shard in the stream—which would double the stream’s capacity. However, this might provide more additional capacity than you actually need and therefore create unnecessary costs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_10.jpg\"><span>You can also use metrics to determine which are your “hot” or “cold” shards, that is, shards that are receiving much more data, or much less data, than expected. You could then selectively split the hot shards to increase capacity for the hash keys that target those shards. Similarly, you could merge cold shards to make better use of their unused capacity.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can obtain some performance data for your stream from the Amazon CloudWatch metrics that Kinesis Data Streams publishes. However, you can also collect some of your own metrics for your streams. One approach would be to log the hash key values generated by the partition keys for your data records. Recall that you specify the partition key at the time that you add the record to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct statements regarding Kinesis resharding are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;– You can decrease the stream’s capacity by merging shards</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;–&nbsp;You can increase the stream’s capacity by splitting shards</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">you have to merge the hot shards to increase the capacity of the stream</strong></b><span>&nbsp;is incorrect because a hot shard is the one that receives more data in the stream, which you should split rather than merge.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">you have to split the cold shards to decrease the capacity of the stream</strong></b><span>&nbsp;is incorrect because&nbsp;a cold shard is the one that receives fewer data in the stream, which you should merge rather than split.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the data records that are flowing to the parent shards will be lost when you reshard</strong></b><span>&nbsp;is incorrect because&nbsp;the data records are actually re-routed to flow to the child shards based on the hash key values that the data-record partition keys map to. Hence, this is incorrect because the records are not lost.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding-strategies.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding-strategies.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557792,
        "value": "You have to merge the hot shards to increase the capacity of the stream.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557793,
        "value": "You can increase the stream's capacity by splitting shards.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557794,
        "value": "You have to split the cold shards to decrease the capacity of the stream.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557795,
        "value": "You can decrease the stream's capacity by merging shards.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557796,
        "value": "The data records that are flowing to the parent shards will be lost when you reshard.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 9,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557793,
        "questionId": 388642,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557795,
        "questionId": 388642,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388642,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A tech company has a real-time traffic monitoring system which uses Amazon Kinesis Data Stream to collect data and a group of EC2 instances that consume and process the data stream. Your development team is responsible for adjusting the number of shards in the data stream to adapt to changes in the rate of data flow.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following are correct regarding Kinesis resharding which your team should consider in managing the application? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618797,
    "question": "Amazon RDS database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When a Lambda function runs, AWS Lambda retains its execution context for potential subsequent invocations, allowing it to respond quickly without reinitializing the environment. This retention includes the&nbsp;/tmp&nbsp;directory, a writable temporary storage. Data saved in this directory persists across these retained invocations, making it useful for caching.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_11.jpg\"><span>In the scenario, after translating a product description, the result can be saved in&nbsp;/tmp. If the same translation is requested soon after, the Lambda function can retrieve the cached result instead of re-fetching from the database, improving response time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Use the&nbsp;/tmp&nbsp;storage in the Lambda function to cache recently translated product descriptions.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Store the results of the TranslateText API in an Amazon DynamoDB Accelerator (DAX) cluster&nbsp;</strong></b><span>is incorrect because DAX is used to provide a fully managed, in-memory caching solution for Amazon DynamoDB, not for caching results from other AWS services like Amazon Translate. DAX is primarily designed to improve the performance of read-heavy DynamoDB workloads by caching data from DynamoDB tables in memory.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS Step Functions with a Parallel state to concurrently run multiple instances of the Lambda function for translation</strong></b><span>&nbsp;is incorrect. The AWS Step Functions Parallel state allows for the concurrent execution of multiple branches within a state machine. In this context, it could mean breaking down a single translation request into multiple smaller tasks, which doesn’t make sense for translating a single product description. Such an approach could only complicate the process and potentially introduce additional delays. Additionally, running multiple Lambda instances concurrently can be more expensive.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Update the Lambda function to use asynchronous invocation. Push the translation requests to an Amazon SQS queue and then process in batches</strong></b><span>&nbsp;is incorrect. For on-demand translations, users expect translations to be near-instantaneous. Introducing SQS and batch processing would mean that the system would wait to accumulate several translation requests before processing them. This would add delay to the translation response time, potentially worsening the user experience.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/running-lambda-code.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/running-lambda-code.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#function-configuration\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#function-configuration</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557797,
        "value": "Use AWS Step Functions with a Parallel state to concurrently run multiple instances of the Lambda function for translation.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557798,
        "value": "Use the /tmp storage in the Lambda function to cache recently translated product descriptions.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557799,
        "value": "Store the results of the TranslateText API in an Amazon DynamoDB Accelerator (DAX) cluster.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557800,
        "value": "Update the Lambda function to use asynchronous invocation. Push the translation requests to an Amazon SQS queue and then process in batches.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 10,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557798,
        "questionId": 388643,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388643,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A multinational e-commerce company hosts its product descriptions on an Amazon RDS database. All descriptions are originally written in English. Users can request on-demand translations via a Lambda function, which pulls the description and employs Amazon Translate’s TranslateText API for the task. However, during sales of popular products, the surge in translation requests is stressing the RDS, causing increased response times.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How can a developer improve the Lambda function’s response time cost-effectively without performing database optimizations?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618798,
    "question": "S3 bucket",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the simplest case, your browser script makes a GET request for a resource from a server in another domain. Depending on the CORS configuration of that server, if the request is from a domain that’s authorized to submit GET requests, the cross-origin server responds by returning the requested resource.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If either the requesting domain or the type of HTTP request is not authorized, the request is denied. However, CORS makes it possible to preflight the request before actually submitting it. In this case, a preflight request is made in which the&nbsp;OPTIONS&nbsp;access request operation is sent. If the cross-origin server’s CORS configuration grants access to the requesting domain, the server sends back a preflight response that lists all the HTTP request types that the requesting domain can make on the requested resource.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. With CORS support, you can build rich client-side web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To configure your bucket to allow cross-origin requests, you create a CORS configuration, which is an XML document with rules that identify the origins that you will allow to access your bucket, the operations (HTTP methods) that will support for each origin, and other operation-specific information. You can add up to 100 rules to the configuration. You add the XML document as the cors subresource to the bucket either programmatically or by using the Amazon S3 console as shown below:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_12.jpg\"><span>Therefore, you can solve the issue in the scenario by simply</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;enabling cross-origin resource sharing (CORS) configuration in the bucket</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Enabling cross-account access&nbsp;</strong></b><span>is incorrect because this is just a feature in IAM&nbsp;that allows you to provide access to your resources to an IAM User in another AWS account.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Enabling Cross-Zone Load Balancing&nbsp;</strong></b><span>is incorrect because this is only used in ELB and not in S3.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Enabling Cross-Region Replication (CRR)</strong></b><span>&nbsp;is incorrect because&nbsp;this is just a bucket-level configuration that enables automatic, asynchronous copying of objects across buckets in different AWS Regions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Reference:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/cors.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/cors.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557801,
        "value": "Enable Cross-Region Replication (CRR).",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557802,
        "value": "Enable Cross-origin resource sharing (CORS) configuration in the bucket.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557803,
        "value": "Enable Cross-Zone Load Balancing.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557804,
        "value": "Enable cross-account access.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 11,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557802,
        "questionId": 388644,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388644,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You are hosting a website in an Amazon S3 bucket named&nbsp;abc and your users load the website using the&nbsp;http://abc.s3-website-us-east-1.amazonaws.com&nbsp;endpoint. You want to use JavaScript on the webpages that are stored in this bucket to be able to make authenticated GET and PUT requests. These requests are directed to the same bucket through the&nbsp;website.s3.amazonaws.com&nbsp;S3 API endpoint. However, you noticed that your web browser blocks the HTTP requests originating from your website.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should you do to rectify this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618799,
    "question": "IAM roles",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">CloudFormation drift detection</strong></b><span>&nbsp;is a feature that allows you to identify differences between the actual configuration of your AWS resources and their expected configuration as defined in your CloudFormation stack template.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Some of its capabilities are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Compares a stack’s current state of resources with their expected state as defined in the CloudFormation template.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Identifies any discrepancies or “drift” between the actual and expected configurations of resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Assists in identifying potential issues affecting stack operations or overall infrastructure integrity.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Helps maintain consistency and compliance by detecting unintended or unauthorized changes outside of CloudFormation.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_13.jpg\"><span>Running a drift detection check on the CloudFormation stack would allow the organization to identify these unauthorized changes. CloudFormation would detect that the actual configuration of the IAM roles no longer matches the expected configuration defined in the stack template, and it would report these differences as drifts.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By identifying the drifts, the organization can take appropriate actions to remediate the unauthorized changes and bring the resources back into compliance with the CloudFormation stack template. This could involve updating the IAM roles through CloudFormation or reverting the manual changes made to the roles.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Additionally, CloudFormation’s drift detection feature provides detailed information about the specific properties or attributes of the resources that have drifted, making it easier to understand the nature of the changes and take targeted actions to address them.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Run a drift detection check on the CloudFormation stack.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS Config to monitor updates made to the Lambda functions and IAM roles</strong></b><span>&nbsp;is incorrect. While AWS Config can track configuration changes and rule compliance for AWS resources, it wouldn’t directly show which resources have deviated from their CloudFormation stack configuration. AWS Config might identify some changes, but it lacks the direct stack synchronization context provided by drift detection.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Review CloudTrail logs to trace IAM role updates for the Lambda functions&nbsp;</strong></b><span>is incorrect. AWS CloudTrail simply records API calls made within an AWS account, including changes made to IAM roles. Reviewing the CloudTrail logs, the organization can trace the API calls that modified the IAM roles associated with the Lambda functions. However, this approach alone does not identify whether the changes were authorized or unauthorized, nor does it ensure that all resources are in sync with the CloudFormation stack.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Analyze CloudWatch Logs to identify changes to the IAM role permissions</strong></b><span>&nbsp;is incorrect. CloudWatch Logs is primarily used for monitoring and collecting log data from various AWS services. It does not directly provide information about changes to IAM role permissions or help identify unauthorized changes in the context of the CloudFormation stack.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/detect-drift-stack.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/detect-drift-stack.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557805,
        "value": "Run a drift detection check on the CloudFormation stack.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557806,
        "value": "Review CloudTrail logs to trace IAM role updates for the Lambda functions.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557807,
        "value": "Use AWS Config to monitor updates made to the Lambda functions and IAM roles.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557808,
        "value": "Analyze CloudWatch Logs to identify changes to the IAM role permissions.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 12,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557805,
        "questionId": 388645,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388645,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An organization has a serverless application using AWS Lambda, Amazon API Gateway. Recently, the DevOps team discovered that the IAM roles associated with the Lambda functions had been manually modified. The organization must identify these unauthorized changes and ensure all resources are in sync with the CloudFormation stack.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which solution will help the company identify these changes?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618800,
    "question": "AWS SAM",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In general,&nbsp;Scan&nbsp;operations are less efficient than other operations in DynamoDB. A&nbsp;Scan&nbsp;operation always scans the entire table or secondary index. It then filters out values to provide the result you want, essentially adding the extra step of removing data from the result set.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;Scan&nbsp;operation reads every item in a table or a secondary index. By default, a&nbsp;Scan&nbsp;operation returns all of the data attributes for every item in the table or index. You can use the&nbsp;ProjectionExpression&nbsp;parameter so that&nbsp;Scan&nbsp;only returns some of the attributes rather than all of them. On the other hand, the&nbsp;Query&nbsp;operation finds items based on primary key values. You can query any table or secondary index that has a composite primary key (a partition key and a sort key).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_14.jpg\"><span>If possible, you should avoid using a&nbsp;Scan&nbsp;operation on a large table or index with a filter that removes many results. Also, as a table or index grows, the&nbsp;Scan&nbsp;operation slows. The&nbsp;Scan&nbsp;operation examines every item for the requested values and can use up the provisioned throughput for a large table or index in a single operation. For faster response times, design your tables and indexes so that your applications can use&nbsp;Query&nbsp;instead of&nbsp;Scan.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>DynamoDB calculates the number of read capacity units consumed based on item size, not on the amount of data that is returned to an application. For this reason, the number of capacity units consumed will be the same whether you request all of the attributes (the default behavior) or just some of them (using a projection expression). The number will also be the same whether or not you use a filter expression.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">using the Query operation with eventual consistency reads&nbsp;</strong></b><span>is the correct answer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using the Scan operation with eventual consistency reads&nbsp;</strong></b><span>is incorrect because it doesn’t find items based on primary key values but by reading every item in a table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using the Scan operation with strong consistency reads</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because in addition to what is mentioned above about the Scan operation, using strong consistency will consume more RCU. Remember that the scenario requires a solution that uses the LEAST amount of RCU.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using the Query operation with strong consistency reads</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this consumes more RCU in comparison to eventual&nbsp;consistency.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557809,
        "value": "Use the Query operation with eventual consistency reads.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557810,
        "value": "Use the Scan operation with strong consistency reads.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557811,
        "value": "Use the Query operation with strong consistency reads.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557812,
        "value": "Use the Scan operation with eventual consistency reads.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 13,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557809,
        "questionId": 388646,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388646,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using AWS SAM, a developer recently deployed a serverless application consisting of Lambda functions, API Gateway, Kinesis Data stream, and a DynamoDB table. The application has worked fine for a few days, but lately, there were a lot of&nbsp;ProvisionedThroughputExceeded&nbsp;exceptions being returned by DynamoDB. The developer also noticed that there’s a sudden increase in read capacity units (RCU) usage whenever this issue happens.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How should the developer refactor the application to find items based on primary key values and use the LEAST amount of RCU?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618801,
    "question": " Lambda function",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can configure your Lambda function to pull in additional code and content in the form of layers. A layer is a ZIP archive that contains libraries, a</span><span style=\"color: rgb(69, 67, 69);\">&nbsp;</span><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-custom.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span style=\"color: rgb(69, 67, 69);\">custom runtime</span></a><u><span class=\"Editor__editor-text-underline___y38TS\" style=\"color: rgb(69, 67, 69);\">,</span></u><span> or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Layers let you keep your deployment package small, which makes development easier. You can avoid errors that can occur when you install and package dependencies with your function code. For Node.js, Python, and Ruby functions, you can&nbsp;</span><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/code-editor.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span style=\"color: rgb(69, 67, 69);\">develop your function code in the Lambda console</span></a><u><span class=\"Editor__editor-text-underline___y38TS\" style=\"color: rgb(69, 67, 69);\">&nbsp;</span></u><span>as long as you keep your deployment package under 3 MB.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_15.jpg\"><span>A function can use up to 5 layers at a time. The total unzipped size of the function and all layers can’t exceed the unzipped deployment package size limit of 250 MB.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can create layers, or use layers published by AWS and other AWS customers. Layers support resource-based policies for granting layer usage permissions to specific AWS accounts, AWS Organizations, or all accounts. Layers are extracted to the /opt directory in the function execution environment. Each runtime looks for libraries in a different location under /opt, depending on the language. Structure your layer so that function code can access libraries without additional configuration.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">upload the other dependencies of your function as a separate Lambda Layer instead.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Uploading the deployment package to S3&nbsp;</strong></b><span>is incorrect. Although you can upload large deployment packages of over 50 MB in size via S3, your function will still be in a single layer. This doesn’t meet the requirement of making the deployment package small and modularized. You have to use Lambda Layers instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Zipping the deployment package again to further compress the zip file&nbsp;</strong></b><span>is incorrect because doing this will not significantly make the ZIP file smaller.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Compressing the deployment package as TAR file instead</strong></b><span>&nbsp;is incorrect. Although it may decrease the size of the deployment package, it is still not enough to totally solve the issue. A compressed TAR file is not significantly smaller as compared to a ZIP file.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/limits.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/limits.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557813,
        "value": "Upload the other dependencies of your function as a separate Lambda Layer instead.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557814,
        "value": "Compress the deployment package as TAR file instead.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557815,
        "value": "Zip the deployment package again to further compress the zip file.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557816,
        "value": "Upload the deployment package to S3.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 14,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557813,
        "questionId": 388647,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388647,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company is deploying the package of its Lambda function, which is compressed as a ZIP file, to AWS. However, they are getting an error in the deployment process because the package is too large. The manager instructed the developer to keep the deployment package small to make the development process much easier and more modularized. This should also help prevent errors that may occur when dependencies are installed and packaged with the function code.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following options is the MOST suitable solution that the developer should implement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618802,
    "question": "Amazon Kinesis data stream",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Lambda</strong></b><span>&nbsp;counts a request each time it starts executing in response to an event notification or invocation call, including test invokes from the console. You are charged based on&nbsp;the total number of requests processed across all of your Lambda functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_16.jpg\"><span>Duration is calculated from the time your code begins executing until it returns or otherwise terminates, rounded up to the nearest 1ms. The price depends on the amount of memory you allocate to your function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the AWS Lambda resource model, you choose the amount of memory you want for your function and are allocated proportional CPU power and other resources. An increase in memory size triggers an equivalent increase in CPU available to your function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;Increase the allocated memory of the function.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Configure the function to use unreserved account concurrency&nbsp;</strong></b><span>is incorrect because this configuration is primarily used for managing the number of simultaneous executions of your function as well as the capacity reservations for that concurrency level.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Increase the concurrent execution limit of the function&nbsp;</strong></b><span>is incorrect because this will just limit the number of simultaneous executions of your function and not increase the allocated CPU.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use Lambda&nbsp;</strong></b><span>is incorrect because&nbsp;this is actually a feature of Amazon CloudFront that lets you run code closer to users of your application, which improves performance and reduces latency. This will not increase the CPU of your function hence, this option does not meet the requirement.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/configuration-function-common.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/lambda/pricing/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/lambda/pricing/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557817,
        "value": "Use Lambda.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557818,
        "value": "Configure the function to use unreserved account concurrency.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557819,
        "value": "Increase the allocated memory of the function.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557820,
        "value": "Increase the concurrent execution limit of the function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 15,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557819,
        "questionId": 388648,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388648,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You are developing a serverless application in AWS in which you have to control the code execution performance and costs of your Lambda functions. There is a requirement to increase the CPU available to your function in order to efficiently process records from an Amazon Kinesis data stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the BEST way to meet this requirement?</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618803,
    "question": " Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In Elastic Beanstalk, you can include a YAML formatted environment manifest in the root of your application source bundle to configure the environment name, solution stack and environment links to use when creating your environment. An environment manifest uses the same format as Saved Configurations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>This file format includes support for environment groups. To use groups, specify the environment name in the manifest with a + symbol at the end. When you create or update the environment, specify the group name with&nbsp;--group-name&nbsp;(AWS CLI) or&nbsp;--env-group-suffix&nbsp;(EB CLI).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The following example manifest defines a web server environment for the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">abc</strong></b><span>&nbsp;frontend application, with a link to a worker environment component that it is dependent upon. The manifest uses groups to allow creating multiple environments with the same source bundle:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><pre data-highlight-language=\"java\"><code>~/abc/frontend/env.yaml\nAWSConfigurationTemplateVersion: 1.1.0.0\nSolutionStack: 64bit Amazon Linux 2015.09 v2.0.6 running Multi-container Docker 1.7.1 (Generic)\nOptionSettings:\n  aws:elasticbeanstalk:command:\n    BatchSize: '30'\n    BatchSizeType: Percentage\n  aws:elasticbeanstalk:sns:topics:\n    Notification Endpoint: me@abc.com\n  aws:elb:policies:\n    ConnectionDrainingEnabled: true\n    ConnectionDrainingTimeout: '20'\n  aws:elb:loadbalancer:\n    CrossZone: true\n  aws:elasticbeanstalk:environment:\n    ServiceRole: aws-elasticbeanstalk-service-role\n  aws:elasticbeanstalk:application:\n    Application Healthcheck URL: /\n  aws:elasticbeanstalk:healthreporting:system:\n    SystemType: enhanced\n  aws:autoscaling:launchconfiguration:\n    IamInstanceProfile: aws-elasticbeanstalk-ec2-role\n    InstanceType: t2.micro\n    EC2KeyName: workstation-uswest2\n  aws:autoscaling:updatepolicy:rollingupdate:\n    RollingUpdateType: Health\n    RollingUpdateEnabled: true\nTags:\n  Cost Center: ABC Dev\nCName: front-A08G28LG+\nEnvironmentName: front+\nEnvironmentLinks:\n  \"WORKERQUEUE\" : \"worker+\"</code></pre><span>Hence, using the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">env.yaml&nbsp;</strong></b><span>is the correct configuration file to be used in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Dockerrun.aws.json</strong></b><span>&nbsp;is incorrect because&nbsp;this configuration file is primarily used in multicontainer Docker environments that are hosted in Elastic Beanstalk. This can be used alone or combined with source code and content in a source bundle to create an environment on a Docker platform.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">env.config&nbsp;</strong></b><span>is incorrect because this is just a custom configuration file which is not readily available in Elastic Beanstalk.&nbsp;Configuration files are YAML- or JSON-formatted documents with a&nbsp;.config&nbsp;file extension that you place in a folder named&nbsp;.ebextensions&nbsp;and deploy in your application source bundle. The more appropriate configuration file to use here is the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">env.yaml</em></i><span>&nbsp;which can help you configure the environment name, solution stack, and environment links to use when creating your environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">cron.yaml</strong></b><span>&nbsp;is incorrect because this configuration file is primarily used to define periodic tasks that add jobs to your worker environment’s queue automatically at a regular interval.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-cfg-manifest.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-cfg-manifest.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557821,
        "value": "env.config",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557822,
        "value": "Dockerrun.aws.json",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557823,
        "value": "cron.yaml",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557824,
        "value": "env.yaml",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 16,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557821,
        "questionId": 388649,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388649,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer needs to configure the environment name, solution stack, and environment links of his application environment which will be hosted in Elastic Beanstalk. Which configuration file should the developer add in the source bundle to meet the above requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618804,
    "question": "API Gateway",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In Lambda non-proxy (or custom) integration, you can specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For an AWS service action, you have the AWS integration of the non-proxy type only. API Gateway also supports the mock integration, where API Gateway serves as an integration endpoint to respond to a method request. The Lambda custom integration is a special case of the AWS integration, where the integration endpoint corresponds to the&nbsp;</span><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>function-invoking action&nbsp;</span></a><span>of the Lambda service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;Lambda proxy integration type (AWS_PROXY)&nbsp;lets an API method be integrated with the Lambda function invocation action with a flexible, versatile, and streamlined integration setup. This integration relies on direct interactions between the client and the integrated Lambda function. With this type of integration, also known as the Lambda proxy integration, you do not set the integration request or the integration response. API Gateway passes the incoming request from the client as the input to the backend Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;In this scenario, you have to enforce the use of a required&nbsp;courseType&nbsp;query string parameter in the&nbsp;/getcourses&nbsp;resource in API Gateway. In order to do this, you can configure the method request of your resource just as shown in the diagram above.</span><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_18D.jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">configure the method request of the resource</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">.</strong></b></i></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the integration request of the resource&nbsp;</strong></b><span>is incorrect. Although configuring the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">integration request</em></i><span>&nbsp;may also be valid, the client traffic will hit the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">method request</em></i><span>&nbsp;first before it goes to the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">integration request</em></i><span>&nbsp;down to the underlying Lambda function. This is why you should configure the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">method request first</em></i><span>&nbsp;so it won’t be necessary to check the required parameters in the Lambda integration. In addition, the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">integration request</em></i><span>&nbsp;does not have the capability to enforce a request to include certain query string parameter nor enable API caching, unlike the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">method request.</em></i></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the integration response of the resource&nbsp;</strong></b><span>is incorrect because you have to use the method request. Configuring the response, either the method-type or the integration-type, is irrelevant in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the method response of the resource</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because you should configure the method request instead. Take note that the scenario explicitly mentioned about the required query parameter which needs to be present before the processing can proceed.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-request.html#setup-method-request-model\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-request.html#setup-method-request-model</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-input-format\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-input-format</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557825,
        "value": " Configure the method response of the resource.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557826,
        "value": "Configure the integration request of the resource.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557827,
        "value": "Configure the method request of the resource.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557828,
        "value": "Configure the integration response of the resource.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 17,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557827,
        "questionId": 388650,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388650,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A serverless application is using API Gateway with a non-proxy Lambda Integration. A developer was tasked to expose a GET method on a new&nbsp;/getcourses&nbsp;resource to invoke the Lambda function, which will allow the consumers to fetch a list of online courses in JSON format. The consumers must include a query string parameter named&nbsp;courseType&nbsp;in their request to get the data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the MOST efficient solution that the developer should do to accomplish this requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618805,
    "question": " DynamoDB",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">DynamoDB</strong></b><span>&nbsp;supports two types of secondary indexes:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>Global secondary index</span></a><span>&nbsp;—&nbsp;an index with a partition key and a sort key that can be different from those on the base table. A global secondary index is considered “global” because queries on the index can span all of the data in the base table, across all partitions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSI.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>Local secondary index</span></a><span>&nbsp;—&nbsp;an index that has the same partition key as the base table, but a different sort key. A local secondary index is “local” in the sense that every partition of a local secondary index is scoped to a base table partition that has the same partition key value.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">local secondary index</strong></b></i><span>&nbsp;maintains an alternate sort key for a given partition key value. A local secondary index also contains a copy of some or all of the attributes from its base table; you specify which attributes are projected into the local secondary index when you create the table. The data in a local secondary index is organized by the same partition key as the base table, but with a different sort key. This lets you access data items efficiently across this different dimension. For greater query or scan flexibility, you can create up to five local secondary indexes per table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Suppose that an application needs to find all of the threads that have been posted within the last three months. Without a local secondary index, the application would have to&nbsp;Scan&nbsp;the entire&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">Thread&nbsp;</em></i><span>table and discard any posts that were not within the specified time frame. With a local secondary index, a&nbsp;Query&nbsp;operation could use&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">LastPostDateTime</em></i><span>&nbsp;as a sort key and find the data quickly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the provided scenario, you can create a local secondary index named&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">LastPostIndex&nbsp;</em></i><span>to meet the requirements. Note that the partition key is the same as that of the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">Thread</em></i><span>&nbsp;table, but the sort key is&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">LastPostDateTime&nbsp;</em></i><span>as shown in the diagram below:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_19.jpg\"><span>Hence, the most effective solution in this scenario is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Add a local secondary index while creating the new Thread table. Use the Query operation to utilize the LastPostDateTime attribute as the sort key</strong></b><span>&nbsp;in order to find the data quickly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the application to Scan the entire Thread table and discarding any posts that were not within the specified time frame&nbsp;</strong></b><span>is incorrect. Although this option is valid, this solution&nbsp;will consume a large amount of provisioned read-throughput and will take a significant amount of time to complete. This is not a scalable solution, and the time it takes to fetch the data will continue to increase as the table grows.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the application to Query the entire Thread table and discarding any posts that were not within the specified time frame</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because using the Query operation is not sufficient to meet this requirement. You have to create a local secondary index when you create the table to narrow down the results and improve the performance of your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating a global secondary index and using the Query operation to utilize the LastPostDateTime attribute as the sort key</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because using a local secondary index is a more appropriate solution to be used in this scenario. Take note that in this scenario, it is still using the same partition key (ForumName), but with an alternate sort key (LastPostDateTime), which warrants the use of a local secondary index.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSI.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSI.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557829,
        "value": "Create a global secondary index and use the Query operation to utilize the LastPostDateTime attribute as the sort key.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557830,
        "value": "Configure the application to Scan the entire Thread table and discard any posts that were not within the specified time frame.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557831,
        "value": "Add a local secondary index while creating the new Thread table. Use the Query operation to utilize the LastPostDateTime attribute as the sort key.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557832,
        "value": "Configure the application to Query the entire Thread table and discard any posts that were not within the specified time frame.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 18,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557829,
        "questionId": 388651,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388651,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An online forum requires a new table in DynamoDB named&nbsp;Thread&nbsp;in which the partition key is&nbsp;ForumName&nbsp;and the sort key is&nbsp;Subject. The following diagram shows how the items in the table would be organized:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/q_19.jpg\"><span>For reporting purposes, the application needs to find all of the threads that have been posted in a particular forum within the last three months. Which of the following is the MOST effective solution that you should implement?</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618806,
    "question": "S3 bucket",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Server-side encryption is about protecting data at rest. Using server-side encryption with customer-provided encryption keys (SSE-C) allows you to set your own encryption keys. With the encryption key you provide as part of your request, Amazon S3 manages both the encryption, as it writes to disks, and decryption, when you access your objects. Therefore, you don’t need to maintain any code to perform data encryption and decryption. The only thing you do is manage the encryption keys you provide.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_20.jpg\"><span>When you upload an object, Amazon S3 uses the encryption key you provide to apply AES-256 encryption to your data and removes the encryption key from memory. It is important to note that&nbsp;Amazon S3 does not store the encryption key you provide. Instead, it is stored in a randomly salted HMAC value of the encryption key in order to validate future requests. The salted HMAC value cannot be used to derive the value of the encryption key or to decrypt the contents of the encrypted object. That means, if you lose the encryption key, you lose the object.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you retrieve an object, you must provide the same encryption key as part of your request. Amazon S3 first verifies that the encryption key you provided matches, and then decrypts the object before returning the object data to you.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When using server-side encryption with customer-provided encryption keys (SSE-C), you&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">must</strong></b><span>&nbsp;provide encryption key information using the following request headers:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">x-amz-server-side-encryption-customer-algorithm</strong></b><span>&nbsp;– This header specifies the encryption algorithm. The header value must be “AES256”.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">x-amz-server-side-encryption-customer-key&nbsp;</strong></b><span>– This header provides the 256-bit, base64-encoded encryption key for Amazon S3 to use to encrypt or decrypt your data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">x-amz-server-side-encryption-customer-key-MD5&nbsp;</strong></b><span>– This header provides the base64-encoded 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this header for a message integrity check to ensure the encryption key was transmitted without error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;x-amz-server-side</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\" style=\"font-family: Arial, sans-serif;\">​</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\">-encryption</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\" style=\"font-family: Arial, sans-serif;\">​</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\">-customer-algorithm,&nbsp;x-amz-server-side-encryption-customer-key&nbsp;and&nbsp;x-amz-server-side-encryption-customer-key-MD5&nbsp;headers.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Including the&nbsp;x-amz-server-side-encryption&nbsp;and&nbsp;x-amz-server-side-encryption-aws-kms-key-id&nbsp;headers in the upload request</strong></b><span>&nbsp;is incorrect because these headers are primarily used in Server-Side Encryption with AWS KMS Keys (SSE-KMS) and not for Server-Side Encryption with Customer-Provided Keys (SSE-C).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Including the&nbsp;x-amz-server-side-encryption,&nbsp;x-amz-server-side-encryption-customer-key&nbsp;and&nbsp;x-amz-server-side-encryption-customer-key-MD5&nbsp;headers</strong></b><span>&nbsp;is incorrect because the&nbsp;x-amz-server-side-encryption&nbsp;header is not used in SSE-C encryption. This should be replaced with the&nbsp;x-amz-server-side</span><span style=\"font-family: Arial, sans-serif;\">​</span><span>-encryption</span><span style=\"font-family: Arial, sans-serif;\">​</span><span>-customer-algorithm&nbsp;header.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Including just the&nbsp;x-amz-server-side-encryption-customer-key&nbsp;header only</strong></b><span>&nbsp;is incorrect because you have to include the&nbsp;x-amz-server-side</span><span style=\"font-family: Arial, sans-serif;\">​</span><span>-encryption</span><span style=\"font-family: Arial, sans-serif;\">​</span><span>-customer-algorithm&nbsp;and&nbsp;x-amz-server-side-encryption-customer-key-MD5&nbsp;headers as well to upload the objects to the S3 bucket with SSE-C encryption.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html#RESTObjectPUT-responses-examples\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html#RESTObjectPUT-responses-examples</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557833,
        "value": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key and x-amz-server-side-encryption-customer-key-MD5 headers",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557834,
        "value": "x-amz-server-side-encryption and x-amz-server-side-encryption-aws-kms-key-id headers",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557835,
        "value": "x-amz-server-side-encryption, x-amz-server-side-encryption-customer-key and x-amz-server-side-encryption-customer-key-MD5 headers",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557836,
        "value": "x-amz-server-side-encryption-customer-key header only",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 19,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557835,
        "questionId": 388652,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388652,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Your manager assigned you a task of implementing server-side encryption with customer-provided encryption keys (SSE-C) to your S3 bucket, which will allow you to set your own encryption keys. Amazon S3 will manage both the encryption and decryption process using your key when you access your objects, which will remove the burden of maintaining any code to perform data encryption and decryption.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To properly upload data to this bucket, which of the following headers must be included in your request?</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618807,
    "question": "AWS Organizations",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The IAM policy simulator evaluates the policies that you choose and determines the effective permissions for each of the actions that you specify. The simulator uses the same policy evaluation engine that is used during real requests to AWS services. But the simulator differs from the live AWS environment in the following ways:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– The simulator does not make an actual AWS service request, so you can safely test requests that might make unwanted changes to your live AWS environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Because the simulator does not simulate running the selected actions, it cannot report any response to the simulated request. The only result returned is whether the requested action would be allowed or denied.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– If you edit a policy inside the simulator, these changes affect only the simulator. The corresponding policy in your AWS account remains unchanged.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Check out this video on IAM Policy Simulator:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\"><b><strong class=\"Editor__editor-text-bold___25KrR\"> </strong></b><a href=\"https://www.youtube.com/watch?v=FNbHpOTwifQ\" target=\"_blank\" rel=\"noreferrer noopener\" title=\"https://www.youtube.com/watch?v=fnbhpotwifq\" class=\"Editor__editor-link___3vl2C\"><span>https://www.youtube.com/watch?v=FNbHpOTwifQ</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies in the following ways:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Test policies that are attached to IAM users, groups, or roles in your AWS account. If more than one policy is attached to the user, group, or role, you can test all the policies, or select individual policies to test. You can test which actions are allowed or denied by the selected policies for specific resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Test policies that are attached to AWS resources, such as Amazon S3 buckets, Amazon SQS queues, Amazon SNS topics, or Amazon S3 Glacier vaults.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– If your AWS account is a member of an organization in&nbsp;</span><a href=\"https://docs.aws.amazon.com/organizations/latest/userguide/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>AWS Organizations</span></a><span>, then you can test the impact of service control policies (SCPs) on your IAM policies and resource policies.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Test new policies that are not yet attached to a user, group, or role by typing or copying them into the simulator. These are used only in the simulation and are not saved. Take note that you cannot type or copy a resource-based policy into the simulator. To use a resource-based policy in the simulator, you must include the resource in the simulation and select the checkbox to include that resource’s policy in the simulation.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Test the policies with selected services, actions, and resources. For example, you can test to ensure that your policy allows an entity to perform the&nbsp;ListAllMyBuckets,&nbsp;CreateBucket, and&nbsp;DeleteBucket&nbsp;actions in the Amazon S3 service on a specific bucket.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Simulate real-world scenarios by providing context keys, such as an IP address or date, that are included in&nbsp;Condition&nbsp;elements in the policies being tested.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Identify which specific statement in a policy results in allowing or denying access to a particular resource or action.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;Hence, the correct answer is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">IAM Policy Simulator</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS Config</strong></b><span>&nbsp;is incorrect because this is just a service that enables you to assess, audit, and evaluate the configurations of your&nbsp;AWS resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Systems Manager&nbsp;</strong></b><span>is incorrect because this service just&nbsp;provides a unified user interface so you can view operational data from multiple AWS services and allows you to automate operational tasks across your AWS resources. Unlike IAM Policy Simulator, it can’t be used to simulate your policies.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon Inspector&nbsp;</strong></b><span>is incorrect because it is just an automated security assessment service that helps improve the security and compliance of applications deployed on AWS.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_iam_policy-sim-path-console.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_iam_policy-sim-path-console.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557837,
        "value": "AWS Config",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557838,
        "value": "Amazon Inspector",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557839,
        "value": "IAM Policy Simulator",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557840,
        "value": "Systems Manager",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 20,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557839,
        "questionId": 388653,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388653,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company is using AWS Organizations to manage its multiple AWS accounts which is being used by its various departments. To avoid security issues, it is of utmost importance to test the impact of service control policies (SCPs) on your IAM policies and resource policies before applying them.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following services can you use to test and troubleshoot IAM and resource-based policies?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618808,
    "question": "EC2 instance",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;segment document&nbsp;conveys information about a segment to X-Ray. A segment document can be up to 64 kB and contain a whole segment with subsegments, a fragment of a segment that indicates that a request is in progress, or a single subsegment that is sent separately. You can send segment documents directly to X-Ray by using the&nbsp;PutTraceSegments&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>X-Ray compiles and processes segment documents to generate queryable&nbsp;trace summaries&nbsp;and&nbsp;full traces&nbsp;that you can access by using the&nbsp;GetTraceSummaries&nbsp;and&nbsp;BatchGetTraces&nbsp;APIs, respectively. In addition to the segments and subsegments that you send to X-Ray, the service uses information in subsegments to generate&nbsp;inferred segments&nbsp;and adds them to the full trace. Inferred segments represent downstream services and resources in the service map.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A subset of segment fields is indexed by X-Ray for use with filter expressions. For example, if you set the&nbsp;user&nbsp;field on a segment to a unique identifier, you can search for segments associated with specific users in the X-Ray console or by using the&nbsp;GetTraceSummaries&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_21D.jpg\"><span>Below are the optional subsegment fields:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">namespace</strong></b><span>&nbsp;–&nbsp;aws&nbsp;for AWS SDK calls;&nbsp;remote&nbsp;for other downstream calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">http</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-http\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>http</span></a><span>&nbsp;object with information about an outgoing HTTP call.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">aws</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-aws\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>aws</span></a><span>&nbsp;object with information about the downstream AWS resource that your application called.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">error,&nbsp;throttle,&nbsp;fault, and&nbsp;cause</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-errors\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>error</span></a><span>&nbsp;fields that indicate an error occurred and that include information about the exception that caused the error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">annotations</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-annotations\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>annotations</span></a><span>&nbsp;object with key-value pairs that you want X-Ray to index for search.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">metadata</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-metadata\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>metadata</span></a><span>&nbsp;object with any additional data that you want to store in the segment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">subsegments</strong></b><span>&nbsp;– array&nbsp;of subsegment objects.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">precursor_ids</strong></b><span>&nbsp;– array&nbsp;of subsegment IDs that identify subsegments with the same parent that was completed prior to this subsegment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the “metadata” field in the segment section to add custom data for your tracing. If you want to trace all the AWS SDK calls of your application, then you can add a subsegment and set the “namespace” field to “AWS”. Alternatively, you can set the “namespace” value to “remote” if you want to trace other downstream calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the valid considerations in this scenario are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Set the&nbsp;namespace&nbsp;subsegment field to&nbsp;aws&nbsp;for AWS SDK calls and&nbsp;remote&nbsp;for other downstream calls.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Set the&nbsp;metadata&nbsp;object with any additional custom data that you want to store in the segment.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;annotations&nbsp;object with any additional custom data that you want to store in the segment</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this should be the&nbsp;metadata&nbsp;object and not the&nbsp;annotations&nbsp;object.&nbsp;Segments and subsegments can include an annotations object containing one or more fields that X-Ray indexes for use with filter expressions. Fields can have string, number, or Boolean values (no objects or arrays). X-Ray indexes up to 50 annotations per trace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;namespace&nbsp;subsegment field to&nbsp;remote&nbsp;for AWS SDK calls and&nbsp;aws&nbsp;for other downstream calls&nbsp;</strong></b><span>is incorrect because this should be the other way around. You should set the&nbsp;namespace&nbsp;subsegment field to&nbsp;aws&nbsp;for AWS SDK calls and&nbsp;remote&nbsp;for other downstream calls</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;metadata&nbsp;object with key-value pairs that you want X-Ray to index for search&nbsp;</strong></b><span>is incorrect because this should be the&nbsp;annotations&nbsp;object, and not the&nbsp;metadata&nbsp;object.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557841,
        "value": "Set the annotations object with any additional custom data that you want to store in the segment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557842,
        "value": "Set the namespace subsegment field to remote for AWS SDK calls and aws for other downstream calls.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557843,
        "value": "Set the namespace subsegment field to aws for AWS SDK calls and remote for other downstream calls.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557844,
        "value": "Set the metadata object with any additional custom data that you want to store in the segment.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557845,
        "value": "Set the metadata object with key-value pairs that you want X-Ray to index for search.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 21,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557843,
        "questionId": 388654,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": false,
        "choiceId": 1557841,
        "questionId": 388654,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388654,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is instrumenting an application that will be hosted in a large On-Demand EC2 instance in AWS. All of the downstream calls invoked by the application must be traced properly, including the AWS SDK calls. A user-defined data should also be present to expedite the troubleshooting process.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following are valid considerations in AWS X-Ray that the developer should follow? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618809,
    "question": "Amazon CloudWatch",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon CloudWatch</strong></b><span>&nbsp;is basically a metrics repository. An AWS service—such as Amazon EC2—puts metrics into the repository, and you retrieve statistics based on those metrics. If you put your own custom metrics into the repository, you can retrieve statistics on these metrics as well.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">namespace</em></i><span>&nbsp;is a container for CloudWatch metrics. Metrics in different namespaces are isolated from each other so that metrics from different applications are not mistakenly aggregated into the same statistics.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_23.jpg\"><span>There is no default namespace. You must specify a namespace for each data point you publish to CloudWatch. You can specify a namespace name when you create a metric. These names must contain valid XML characters and be fewer than 256 characters in length. Possible characters are: alphanumeric characters (0-9A-Za-z), period (.), hyphen (-), underscore (_), forward slash (/), hash (#), and colon (:).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The AWS namespaces typically use the following naming convention:&nbsp;AWS/service. For example, Amazon EC2 uses the&nbsp;AWS/EC2&nbsp;namespace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch namespace with a unique metric name for each application.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch Alarm with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because&nbsp;a CloudWatch Alarm simply watches a single metric over a specified time period and performs one or more specified actions based on the value of the metric relative to a threshold over time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch Event with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because&nbsp;a CloudWatch Event is primarily used to deliver a near real-time stream of system events that describe changes in Amazon Web Services (AWS) resources, and not for segregating metrics of various applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch dimension with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because a CloudWatch&nbsp;dimension is only a name/value pair that is part of the identity of a metric. You have to use a CloudWatch namespace instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/viewing_metrics_with_cloudwatch.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/viewing_metrics_with_cloudwatch.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557846,
        "value": "Set up a custom CloudWatch namespace with a unique metric name for each application.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557847,
        "value": "Set up a custom CloudWatch Event with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557848,
        "value": "Set up a custom CloudWatch dimension with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557849,
        "value": "Set up a custom CloudWatch Alarm with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 22,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557846,
        "questionId": 388655,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388655,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has 5 different applications running on several On-Demand EC2 instances. The DevOps team is required to set up a graphical representation of the key performance metrics for each application. These system metrics must be available on a single shared screen for more effective and visible monitoring.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should the DevOps team do to satisfy this requirement using Amazon CloudWatch?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618810,
    "question": "AWS SAM",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services.&nbsp;CodeDeploy can deploy application content that runs on a server and is stored in Amazon S3 buckets, GitHub repositories, or Bitbucket repositories. CodeDeploy can also deploy a serverless Lambda function. You do not need to make changes to your existing code before you can use CodeDeploy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>CodeDeploy supports the following deployment configurations:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-In-place (for EC2/On-premises)&nbsp;</strong></b><span>– the application on each instance in the deployment group is stopped, the latest application revision is installed, and the new version of the application is started and validated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Canary (for Lambda/ECS) –</strong></b><span>&nbsp;traffic is shifted in two increments. You can choose from predefined canary options that specify the percentage of traffic shifted to your updated Lambda function or ECS task set in the first increment and the interval, in minutes, before the remaining traffic is shifted in the second increment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Linear&nbsp;(for Lambda/ECS) –</strong></b><span>&nbsp;traffic is shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic shifted in each increment and the number of minutes between each increment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-All-at-once&nbsp;(for Lambda/ECS) –</strong></b><span>&nbsp;all traffic is shifted from the original Lambda function or ECS task set to the updated function or task set all at once.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_24.jpg\"><span>In a&nbsp;Linear&nbsp;deployment configuration, the traffic will be shifted in equal increments with an equal number of minutes between each increment. You can choose from predefined linear options that specify the percentage of traffic shifted in each increment and the number of minutes between each increment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the is the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploy the functions using a Linear deployment configuration.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploy the functions using a Canary deployment configuration</strong></b><span>&nbsp;is incorrect because this will cause the traffic to be shifted in&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">two</strong></b><span>&nbsp;increments. You can choose from predefined canary options that specify the percentage of traffic shifted to your updated Lambda function version in the first increment and the interval, in minutes, before the remaining traffic is shifted in the second increment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploy the functions using an All-at-once deployment configuration&nbsp;</strong></b><span>is incorrect because, with this deployment configuration, the traffic is shifted from the original Lambda function to the updated Lambda function version all at once.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploy the functions using an Immutable deployment configuration</strong></b><span>&nbsp;is incorrect because this is only applicable in Elastic Beanstalk and not to Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557850,
        "value": "Deploy the functions using a Canary deployment configuration.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557851,
        "value": "Deploy the functions using an All-at-once deployment configuration.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557852,
        "value": "Deploy the functions using a Linear deployment configuration.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557853,
        "value": "Deploy the functions using an Immutable deployment configuration.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 23,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557852,
        "questionId": 388656,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388656,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A serverless application, which is composed of multiple Lambda functions, has been deployed using AWS SAM. A developer was instructed to easily manage the deployments of the functions using CodeDeploy. When there is a new deployment, 10 percent of the incoming traffic should be shifted to the new version every 10 minutes until all traffic is shifted from the old version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should the developer do to properly deploy the functions that satisfies this requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618811,
    "question": "Cloud architecture",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the traditional data center-based model of IT, once the infrastructure is deployed, it typically runs whether it is needed or not, and all the capacity is paid for, regardless of how much it gets used. In the cloud, resources are&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">elastic</strong></b><span>, meaning they can instantly grow or shrink to match the requirements of a specific application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Elasticity allows you to match the supply of resources—which cost money—to demand. Because cloud resources are paid for based on usage, matching needs to utilization is critical for cost optimization. Demand includes both external usage, such as the number of customers who visit a website over a given period, and internal usage, such as an application team using development and test environments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>There are two basic types of elasticity:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>1. Time-based</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>2. Volume-based</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Time-based elasticity means turning off resources when they are not being used, such as a development environment that is needed only during business hours. Volume-based elasticity means matching scale to the intensity of demand, whether that’s compute cores, storage sizes, or throughput. By combining monitoring, tagging, and automation, you can get the most value out of your AWS resources and optimize costs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By taking advantage of volume-based elasticity, you can scale resources to match capacity. The best tool for accomplishing this task is&nbsp;Auto Scaling, which you can use to optimize performance by automatically increasing the number of EC2 instances during demand spikes and decreasing capacity during lulls to reduce costs. Auto Scaling is well-suited for applications that have stable demand patterns and for ones that experience hourly, daily, or weekly variability in usage.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can also use a combination of ELB and Auto Scaling to maximize the elasticity of your architecture. Beyond Auto Scaling for Amazon EC2, you can use&nbsp;Application Auto Scaling&nbsp;to automatically scale resources for other AWS services, including:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;- Amazon ECS</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;- Amazon EC2 Spot Fleets</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;- Amazon EMR clusters</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;- Amazon AppStream 2.0 stacks and fleets</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;- Amazon DynamoDB</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For&nbsp;Amazon EC2 Spot Fleets,&nbsp;it can either launch instances (scale out) or terminate instances (scale in), within the range that you choose, in response to one or more scaling policies.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_25D.jpg\"><span>For Amazon DynamoDB, you can dynamically adjust provisioned throughput capacity in response to actual traffic patterns. This enables a table or a global secondary index to increase its provisioned read and write capacity to handle sudden increases in traffic without throttling. When the workload decreases, Application Auto Scaling decreases the throughput so that you don’t pay for unused provisioned capacity.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answers are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon EC2 Spot Fleet.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Amazon DynamoDB.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon CloudFront</strong></b><span>&nbsp;is incorrect because this is primarily helpful for scaling out your application. Moreover, the scenario says that the internal application will only be used by about a hundred employees, which clearly doesn’t warrant the use of a CDN or CloudFront.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS WAF</strong></b><span>&nbsp;is incorrect because it only improves the security of your architecture and not its elasticity.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon RDS</strong></b><span>&nbsp;is incorrect.&nbsp;While Amazon RDS offers robust features and scalability, its cost structure can be higher due to the need for continuous instance uptime, storage, and backup costs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557854,
        "value": "AWS WAF",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557855,
        "value": "Amazon DynamoDB",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557856,
        "value": "Amazon EC2 Spot Fleet",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557857,
        "value": "Amazon RDS",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557858,
        "value": "Amazon CloudFront",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 24,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557855,
        "questionId": 388657,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388657,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is designing the cloud architecture of an internal application which will be used by about a hundred employees. She needs to ensure that the architecture is elastic enough to adequately match the supply of resources to the demand while maintaining its cost-effectiveness.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following services can provide the MOST elasticity to the architecture? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618812,
    "question": "EC2 instances ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CloudWatchAgentServerPolicy</strong></b><span>&nbsp;is an AWS-managed policy that grants the Amazon CloudWatch agent the necessary permission to collect and publish metrics from EC2 instances to CloudWatch. This policy allows actions such as&nbsp;cloudwatch:PutMetricData&nbsp;and&nbsp;logs:PutLogEvents, enabling the agent to send custom metrics and log data to CloudWatch. Attaching this policy to an IAM role associated with your EC2 instances ensures that the CloudWatch agent has the required effective permissions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_26.jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An IAM role is an AWS Identity and Access Management (IAM) entity that defines a set of permissions for making AWS service requests. When you assign an IAM role to an EC2 instance, applications running on that instance can obtain temporary security credentials to interact with other AWS services without the need for embedding long-term credentials. This approach enhances security and simplifies credential management. To assign a role to an EC2 instance, users can create an instance profile that contains the role and then associate it with the instance during or after its launch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By combining the CloudWatchAgentServerPolicy with an appropriately configured IAM role, you enable the CloudWatch agent on your EC2 instances to collect and transmit custom metrics to CloudWatch seamlessly. This setup is essential for monitoring users’ applications and infrastructure’s performance and health, providing users with actionable insights to maintain optimal operations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Attach the&nbsp;CloudWatchAgentServerPolicy&nbsp;policy to the IAM role specified in the EC2 Auto Scaling launch template to ensure proper permissions for the CloudWatch agent.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Add a user data script in the EC2 Auto Scaling launch template to install and start the CloudWatch agent during instance initialization&nbsp;</strong></b><span>is incorrect. While a user data script can automate the installation and startup of the CloudWatch agent, it only addresses the agent’s deployment process. This does not resolve the root cause of the issue, which is the lack of necessary IAM permissions for publishing custom metrics to Amazon CloudWatch. Even if the agent is installed and running, it requires the correct IAM role with the CloudWatchAgentServerPolicy policy attached to send metrics successfully.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Configure the IAM role for the EC2 instances with the&nbsp;CloudWatchAgentReadOnlyAccess&nbsp;policy to allow the CloudWatch agent to read default metrics and publish data</strong></b><span>&nbsp;is incorrect. The&nbsp;CloudWatchAgentReadOnlyAccess&nbsp;policy just provides permissions to view CloudWatch metrics and logs but does not grant the necessary permissions to publish custom metrics. This policy is intended for scenarios requiring read-only access to CloudWatch data and does not meet the requirements for the CloudWatch agent to send custom metrics to CloudWatch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Attach the&nbsp;CloudWatchAgentAdminPolicy&nbsp;IAM policy to the IAM role specified in the EC2 Auto Scaling launch template to provide enhanced permissions for the CloudWatch agent</strong></b><span>&nbsp;is incorrect. Although the&nbsp;CloudWatchAgentAdminPolicy&nbsp;contains permissions for publishing custom metrics, it primarily provides excessive permissions, including administrative-level access to CloudWatch resources. This violates the principle of least privilege, which recommends granting only the permissions required for a task.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/aws-managed-policy/latest/reference/CloudWatchAgentServerPolicy.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/aws-managed-policy/latest/reference/CloudWatchAgentServerPolicy.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557859,
        "value": "Attach the CloudWatchAgentAdminPolicy IAM policy to the IAM role specified in the EC2 Auto Scaling launch template to provide enhanced permissions for the CloudWatch agent.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557860,
        "value": "Configure the IAM role for the EC2 instances with the CloudWatchAgentReadOnlyAccess policy to allow the CloudWatch agent to read default metrics and publish data.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557861,
        "value": "Attach the CloudWatchAgentServerPolicy policy to the IAM role specified in the EC2 Auto Scaling launch template to ensure proper permissions for the CloudWatch agent.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557862,
        "value": "Add a user data script in the EC2 Auto Scaling launch template to install and start the CloudWatch agent during instance initialization.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 25,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557861,
        "questionId": 388658,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388658,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A multinational company uses Amazon EC2 Auto Scaling to maintain a fleet of EC2 instances behind an Application Load Balancer (ALB). The Amazon EC2 instances are configured with the Amazon CloudWatch agent to collect and publish custom metrics. However, the newly launched EC2 instances within the Auto Scaling group fail to send the metrics to Amazon CloudWatch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What changes are required to ensure the custom metrics are sent from all newly launched EC2 instances?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618813,
    "question": "AWS Elastic Beanstalk ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Elastic Beanstalk provides support for running Amazon Relational Database Service (Amazon RDS) instances in your Elastic Beanstalk environment. This works great for development and testing environments. However, it isn’t ideal for a production environment because it ties the lifecycle of the database instance to the lifecycle of your application’s environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you haven’t used a DB instance with your application before, try adding one to a test environment with the Elastic Beanstalk console first. This lets you verify that your application is able to read environment properties, construct a connection string, and connect to a DB instance before you add Amazon Virtual Private Cloud (Amazon VPC) and security group configuration to the mix.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_27.jpg\"><span>To decouple your database instance from your environment, you can run a database instance in Amazon RDS and configure your application to connect to it on launch. This enables you to connect multiple environments to a database, terminate an environment without affecting the database, and perform seamless updates with blue-green deployments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To allow the Amazon EC2 instances in your environment to connect to an outside database, you can configure the environment’s Auto Scaling group with an additional security group. The security group that you attach to your environment can be the same one that is attached to your database instance, or a separate security group from which the database’s security group allows ingress.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can connect your environment to a database by adding a rule to your database’s security group that allows ingress from the autogenerated security group that Elastic Beanstalk attaches to your environment’s Auto Scaling group. However, doing so creates a dependency between the two security groups. Subsequently, when you attempt to terminate the environment, Elastic Beanstalk will be unable to delete the environment’s security group because the database’s security group is dependent on it.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the blue/green deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance. Before terminating the old Elastic Beanstalk environment, remove its security group rule first before proceeding</strong></b><span>&nbsp;is the correct answer in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the blue/green deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance and delete the old environment</strong></b><span>&nbsp;is incorrect. Although the deployment strategy being used here is valid, the existing security group rule is not yet removed, which hinders the deletion of the old environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use a Canary deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance and delete the old environment</strong></b><span>&nbsp;is incorrect because there is no Canary deployment configuration in Elastic Beanstalk. This type of deployment strategy is usually used in Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use a Canary deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and then create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance</strong></b><span>&nbsp;is incorrect because you should use a blue/green deployment strategy instead. This will also cause a data loss since the&nbsp;deletion protection for the database is not enabled.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/decouple-rds-from-beanstalk/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/premiumsupport/knowledge-center/decouple-rds-from-beanstalk/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557863,
        "value": "Use a Canary deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and then create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557864,
        "value": "Use the blue / green deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance and delete the old environment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557865,
        "value": "Use a Canary deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance and delete the old environment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557866,
        "value": "Use the blue / green deployment strategy to decouple the Amazon RDS instance from your Elastic Beanstalk environment. Create an RDS DB snapshot of the database and enable deletion protection. Create a new Elastic Beanstalk environment with the necessary information to connect to the Amazon RDS instance. Before terminating the old Elastic Beanstalk environment, remove its security group rule first before proceeding.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 26,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557864,
        "questionId": 388659,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388659,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An application in your development account is running in an AWS Elastic Beanstalk environment which has an attached Amazon RDS database. You noticed that if you terminate the environment, it also brings down the database which hinders you from performing seamless updates with blue-green deployments. This also poses a critical security risk if the company decides to deploy the application in production.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, how can you decouple your database instance from your environment without having any data loss?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618814,
    "question": "AWS accounts",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can grant your IAM users permission to switch to roles within your AWS account or to roles defined in other AWS accounts that you own.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Imagine that you have Amazon EC2 instances that are critical to your organization. Instead of directly granting your users permission to terminate the instances, you can create a role with those privileges. Then allow administrators to switch to the role when they need to terminate an instance. Doing this adds the following layers of protection to the instances:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– You must explicitly grant your users permission to assume the role.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Your users must actively switch to the role using the AWS Management Console or assume the role using the AWS CLI or AWS API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– You can add multi-factor authentication (MFA) protection to the role so that only users who sign in with an MFA device can assume the role.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_28.jpg\"><span>You can use a role to delegate access to resources that are in different AWS accounts that you own (Production and Testing). You can share resources in one account with users in a different account by setting up cross-account access. In this way, you don’t need to create individual IAM users in each account and the users don’t have to sign out of one account and sign into another in order to access resources that are in different AWS accounts.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the most efficient answer in this scenario is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Grant the developer cross-account access to the resources of Accounts B and C.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Create separate identities and passwords for the developer on both the Test and Production accounts&nbsp;</strong></b><span>is incorrect because although this is a valid option, it is not an efficient one since the developer will have to log in to each individual AWS account in order to access the resources. A better way to do this is to grant cross-account access.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable AWS multi-factor authentication (MFA) to the IAM User of the developer&nbsp;</strong></b><span>is incorrect because although this will improve the security, it still doesn’t solve the access problem of the developer. This can be used in conjunction with cross-account access, but using this alone will not suffice.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up AWS Organizations and attach a Service Control Policy to the developer to access the other accounts&nbsp;</strong></b><span>is incorrect because although it will make the multiple AWS accounts of the company more manageable, it doesn’t address the access requirement of the developer. Take note that SCPs are necessary, but not sufficient, for granting access for the accounts in your organization.&nbsp;You still need to attach IAM policies to users and roles in your organization’s accounts to actually grant permissions to them.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557867,
        "value": "Grant the developer cross-account access to the resources of Accounts B and C.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557868,
        "value": "Enable AWS multi-factor authentication (MFA) to the IAM User of the developer.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557869,
        "value": "Create separate identities and passwords for the developer on both the Test and Production accounts.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557870,
        "value": "Set up AWS Organizations and attach a Service Control Policy to the developer to access the other accounts.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 27,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557867,
        "questionId": 388660,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388660,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has different AWS accounts, namely Account A, Account B, and Account C, which are used for their Development, Test, and Production environments respectively. A developer needs access to perform an audit whenever a new version of the application has been deployed to the Test (Account B) and production (Account C) environments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the MOST efficient way to provide the developer access to execute the specified task?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618815,
    "question": "X-Ray ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A segment can break down the data about the work done into&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">subsegments</strong></b><span>. Subsegments provide more granular timing information and details about downstream calls that your application made to fulfill the original request. A subsegment can contain additional details about a call to an AWS service, an external HTTP API, or an SQL database. You can even define arbitrary subsegments to instrument specific functions or lines of code in your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;For services that don’t send their own segments like Amazon DynamoDB, X-Ray uses subsegments to generate&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">inferred segments</em></i><span>&nbsp;and downstream nodes on the service map. This lets you see all of your downstream dependencies, even if they don’t support tracing, or are external.</span><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_29.jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Subsegments represent your application’s view of a downstream call as a client. If the downstream service is also instrumented, the segment that it sends replaces the inferred segment generated from the upstream client’s subsegment. The node on the service graph always uses information from the service’s segment, if it’s available, while the edge between the two nodes uses the upstream service’s subsegment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is to include&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">subsegments</strong></b><span>&nbsp;in your segment document.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Including</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;tracing header</strong></b><span>&nbsp;is incorrect because this is added in the HTTP request header and not on the segment document. A tracing header (X-Amzn-Trace-Id) can originate from the X-Ray SDK, an AWS service, or the client request.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Including&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">metadata</strong></b><span>&nbsp;is incorrect because this does not record the calls to AWS services and resources that are made by the application.&nbsp;Segments and subsegments can include a&nbsp;metadata&nbsp;object containing one or more fields with values of any type, including objects and arrays.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Including&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">annotations</strong></b><span>&nbsp;is incorrect because just like&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">metadata</em></i><span>, this also does not record the application’s calls to your AWS services and resources.&nbsp;Segments and subsegments can include an annotations object containing one or more fields that X-Ray indexes for use with filter expressions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-subsegments\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-subsegments</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557871,
        "value": "tracing header",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557872,
        "value": "metadata",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557873,
        "value": "annotations",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557874,
        "value": "subsegments",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 28,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557874,
        "questionId": 388661,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388661,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In order to quickly troubleshoot their systems, your manager instructed you to record the calls that your application makes to all AWS services and resources. You developed a custom code that will send the segment documents directly to X-Ray by using the&nbsp;PutTraceSegments&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should you include in your segment document to meet the above requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618816,
    "question": " DynamoDB database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Databases employ locking mechanisms to ensure that data is always updated to the latest version and is concurrent. There are multiple types of locking strategies that benefit different use cases. Some of these are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Optimistic Locking</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Pessimistic Locking</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>– Overly Optimistic Locking</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><i><em class=\"Editor__editor-text-italic___C9n8O\">Optimistic locking</em></i><span>&nbsp;is a strategy to ensure that the client-side item that you are updating (or deleting) is the same as the item in DynamoDB. If you use this strategy, then your database writes are protected from being overwritten by the writes of others — and vice-versa.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>With optimistic locking, each item has an attribute that acts as a version number. If you retrieve an item from a table, the application records the version number of that item. You can update the item, but only if the version number on the server side has not changed. If there is a version mismatch, it means that someone else has modified the item before you did; the update attempt fails, because you have a stale version of the item. If this happens, you simply try again by retrieving the item and then attempting to update it. Optimistic locking prevents you from accidentally overwriting changes that were made by others; it also prevents others from accidentally overwriting your changes.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_30.jpg\"><span>Since the application is already using the AWS SDK for Java, it can support optimistic locking by simply adding the&nbsp;@DynamoDBVersionAttribute&nbsp;annotation to the objects. In the mapping class for your table, you designate one property to store the version number, and mark it using this annotation. When you save an object, the corresponding item in the DynamoDB table will have an attribute that stores the version number. The&nbsp;DynamoDBMapper&nbsp;assigns a version number when you first save the object, and it automatically increments the version number each time you update the item. Your update or delete requests will succeed only if the client-side object version matches the corresponding version number of the item in the DynamoDB table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">implementing optimistic locking with version number</strong></b><span>&nbsp;is the correct answer in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Implementing pessimistic locking with read locking</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this type of&nbsp;locking can interrupt user operations. This is an approach where an entity is locked in the database for the entire time that it is in application memory (often in the form of an object). This can prevent certain users from reading, updating, or deleting an entry depending on the lock type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Implementing pessimistic locking with write locking</strong></b><span>&nbsp;is incorrect because just as explained above, pessimistic locking will significantly affect the performance of your application. Although it will ensure that your data writes are not overwritten on the fly, this type of locking will not meet the performance requirements mentioned in the scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Implementing overly optimistic locking (OOL)&nbsp;</strong></b><span>is incorrect because this strategy is completely inappropriate for multi-user systems since it is used for systems that have only one user or operation performing changes at a single time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptimisticLocking.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptimisticLocking.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBContext.VersionSupport.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBContext.VersionSupport.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557875,
        "value": "Implement pessimistic locking with write locking.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557876,
        "value": "Implement pessimistic locking with read locking.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557877,
        "value": "Implement optimistic locking with version number.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557878,
        "value": "Implement overly optimistic locking (OOL).",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 29,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557877,
        "questionId": 388662,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388662,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A Java web application built using AWS SDK for Java with a DynamoDB database is concurrently accessed by thousands of users during peak time. The application is highly write-intensive and there are a lot of incidents where it overwrites stale data from the DynamoDB table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How can you ensure your database writes are protected from being overwritten by other write operations that are occurring at the same time without affecting the application performance?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618817,
    "question": "EC2 instance",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Applications that run on an EC2 instance must include AWS credentials in their AWS API requests. You could have your developers store AWS credentials directly within the EC2 instance and allow applications in that instance to use those credentials. But developers would then have to manage the credentials and ensure that they securely pass the credentials to each instance and update each EC2 instance when it’s time to rotate the credentials. That’s a lot of additional work.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Instead, you can and should use an IAM role to manage&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">temporary</em></i><span>&nbsp;credentials for applications that run on an EC2 instance. When you use a role, you don’t have to distribute long-term credentials (such as a username and password or access keys) to an EC2 instance. Instead, the role supplies temporary permissions that applications can use when they make calls to other AWS resources. When you launch an EC2 instance, you specify an IAM role to associate with the instance. Applications that run on the instance can then use the role-supplied temporary credentials to sign API requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_31.jpg\"><span>Using roles to grant permissions to applications that run on EC2 instances requires a bit of extra configuration. An application running on an EC2 instance is abstracted from AWS by the virtualized operating system. Because of this extra separation, an additional step is needed to assign an AWS role and its associated permissions to an EC2 instance and make them available to its applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>This extra step is the creation of an&nbsp;</span><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><i><em class=\"Editor__editor-text-italic___C9n8O\">instance profile</em></i></a><span>&nbsp;that is attached to the instance. The instance profile contains the role and can provide the role’s temporary credentials to an application that runs on the instance. Those temporary credentials can then be used in the application’s API calls to access resources and to limit access to only those resources that the role specifies. Note that only one role can be assigned to an EC2 instance at a time, and all applications on the instance share the same role and permissions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using roles in this way has several benefits. Because role credentials are temporary and rotated automatically, you don’t have to manage credentials, and you don’t have to worry about long-term security risks. In addition, if you use a single role for multiple instances, you can make a change to that one role and the change is propagated automatically to all the instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you use the IAM console, the instance profile is managed for you and is mostly transparent to you. However, if you use the AWS CLI or API to create and manage the role and EC2 instance, then you must create the instance profile and assign the role to it as separate steps. Then, when you launch the instance, you must specify the instance profile name instead of the role name.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, the instance has both an attached IAM Role and AWS CLI. Although the Instance Profile role has been updated to only access the development environment, the application running in the instance might still use the access credentials or the old IAM Role that is attached in the AWS CLI. Take note that you have to configure both of your Instance Profile and AWS CLI in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is that the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">application is still using the IAM role that is configured for the AWS CLI Key</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">.</strong></b></i></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the new IAM Role has an attached inline policy</strong></b><span>&nbsp;is incorrect because&nbsp;an inline policy is just a policy that’s embedded in a principal entity (a user, group, or role). This is irrelevant in this scenario as the main issue here is the profile/IAM Role that still exists and used, by the AWS CLI.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">due to eventual consistency, you must wait 24 hours for the change to appear across all of AWS</strong></b><span>&nbsp;is incorrect because although there is eventual consistency in EC2, there is no exact time limit for the changes to be reflected, which is contrary to what this option is saying. Moreover, the existing AWS CLI profile would be a more compelling root cause in this scenario rather than what this option suggests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the instance profile role of a running EC2 instance is static and can’t be replaced at all</strong></b><span>&nbsp;is incorrect because the instance profile role can be changed anytime.&nbsp;You can remove the existing role and then add a different role to an instance profile.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557879,
        "value": "The application is still using the IAM role that is configured for the AWS CLI key.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557880,
        "value": "The new IAM Role has an attached inline policy.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557881,
        "value": "Due to eventual consistency, you must wait 24 hours for the change to appear across all of AWS.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557882,
        "value": "The instance profile role of a running EC2 instance is static and can't be replaced at all.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 30,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557879,
        "questionId": 388663,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388663,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A prototype application is hosted in an EC2 instance, which has an assigned IAM Role to store data from both the development and production S3 buckets.&nbsp;The instance also has AWS CLI access/secret key installed to handle other ad hoc tasks.&nbsp;You assigned a new IAM Role to the instance which has the permission to access the development bucket only. However, upon testing, the instance can still store files to both buckets.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the MOST likely root cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618818,
    "question": "API Gateway Lambda Authorizer",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A Lambda authorizer is an API Gateway feature that uses a Lambda function to control access to your API. When a client makes a request to one of your API’s methods, API Gateway calls your Lambda authorizer, which takes the caller’s identity as input and returns an IAM policy as output.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>There are two types of Lambda authorizers:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– A&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">token-based</strong></b><span>&nbsp;Lambda authorizer (also called a TOKEN authorizer) receives the caller’s identity in a bearer token, such as a JSON Web Token (JWT) or an OAuth token.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– A&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">request parameter-based</strong></b><span>&nbsp;Lambda authorizer (also called a REQUEST authorizer) receives the caller’s identity in a combination of headers, query string parameters, stageVariables, and $context variables.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_32.jpg\"><span>It is possible to use an AWS Lambda function from an AWS account that is different from the one in which you created your Lambda authorizer function by using a Cross-Account Lambda Authorizer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Therefore, the correct answer in this scenario is to use a&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">token-based authorization</strong></b><span>&nbsp;since this is useful if you want to implement a custom authorization scheme that uses a bearer token authentication strategy such as OAuth or SAML.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Requesting Parameter-based Lambda Authorization&nbsp;</strong></b><span>is incorrect because this does not use tokens to identify a caller but through a combination of headers, query string parameters, stageVariables, and $context variables.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS STS-based authentication&nbsp;</strong></b><span>is incorrect because this is not a valid type of&nbsp;API Gateway Lambda Authorizer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Cross-Account Lambda Authorize</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">r</strong></b></i><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b><span>is incorrect because this just enables you to use an AWS Lambda function from a different AWS account as your API authorizer function. Moreover, this is not a valid&nbsp;Lambda authorizer type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-lambda-authorizer-input.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-lambda-authorizer-input.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-lambda-authorizer-cross-account-lambda-authorizer.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-lambda-authorizer-cross-account-lambda-authorizer.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557883,
        "value": "Request Parameter-based Authorization",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557884,
        "value": "AWS STS-based Authentication",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557885,
        "value": "Token-based Authorization",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557886,
        "value": "Cross-Account Lambda Authorizer",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 31,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557885,
        "questionId": 388664,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388664,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is using API Gateway Lambda Authorizer to provide authentication for every API request and control access to your API. The requirement is to implement an authentication strategy which is similar to OAuth or SAML.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST suitable method that the developer should use in this scenario?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618819,
    "question": "DynamoDB",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>One&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">read request unit</em></i><span>&nbsp;represents one strongly consistent read request, or two eventually consistent read requests, for an item up to 4 KB in size. Transactional read requests require 2 read request units to perform one read for items up to 4 KB.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you need to read an item that is larger than 4 KB, DynamoDB needs additional read request units. The total number of read request units required depends on the item size, and whether you want an eventually consistent or strongly consistent read.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_33.jpg\"><span>For example, suppose that you create a table with 10 provisioned read capacity units. This allows you to perform 10 strongly consistent reads per second, or 20 eventually consistent reads per second, for items up to 4 KB.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Reading an item larger than 4 KB consumes more read capacity units. For example, a strongly consistent read of an item that is 8 KB (4 KB × 2) consumes 2 read capacity units. An eventually consistent read on that same item consumes only 1 read capacity unit.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Item sizes for reads are rounded up to the next 4 KB multiple. For example, reading a 3,500-byte item consumes the same throughput as reading a 4 KB item.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">To get the number of strong and eventual consistent read requests that your table can accommodate per second, you simply have to do the following steps:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Step #1&nbsp;Multiply the value of the provisioned RCU by 4 KB</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>= 10 RCU x 4 KB= 40</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Step #2&nbsp;To get the number of strong&nbsp;consistency requests, just divide the result of step 1 by 4 KB</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>= 40 / 4 KB =&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">10 strongly consistent read requests</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Step #3&nbsp;To get the number of eventual&nbsp;consistency requests, just divide the result of step 1 by 2 KB</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>=40&nbsp;/ 2</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b><span>KB=&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">20 eventually consistent read requests</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is&nbsp;that the table can handle&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">10 strongly consistent reads and 20 eventually consistent reads per second.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">10 strongly consistent reads and 10 eventually consistent reads per second</strong></b><span>&nbsp;is incorrect. Although the former value is correct, the latter one is not. Take note that one strongly consistent read request is equivalent to two eventually consistent read request as these two consistency types are quite different from each other.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">5 strongly consistent reads and 20 eventually consistent reads per second</strong></b><span>&nbsp;is incorrect. Although the latter value is correct, the former one is not. If the scenario says that it uses transaction read requests, then it is correct that it will provide 5 strongly consistent reads. However, it is explicitly mentioned to get both strong and eventual consistency.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">20 strongly consistent reads and 10 eventually consistent reads per second</strong></b><span>&nbsp;is incorrect because it should be the other way around. The table can provide 10 strongly consistent reads and 20 eventually consistent reads per second.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html#ItemSizeCalculations.Reads</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557887,
        "value": "20 strongly consistent reads and 10 eventually consistent reads per second",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557888,
        "value": "10 strongly consistent reads and 20 eventually consistent reads per second",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557889,
        "value": "10 strongly consistent reads and 10 eventually consistent reads per second",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557890,
        "value": "5 strongly consistent reads and 20 eventually consistent reads per second",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 32,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557888,
        "questionId": 388665,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388665,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company is re-architecting its legacy application to use AWS Lambda and DynamoDB. The table is provisioned to have 10 read capacity units, and each item has a size of 4 KB.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How many eventual and strong consistent read requests can the table handle per second?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618820,
    "question": "Lambda functions ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The unit of scale for AWS Lambda is a concurrent execution.&nbsp;However, scaling indefinitely is not desirable in all scenarios. For example, you may want to control your concurrency for cost reasons or to regulate how long it takes you to process a batch of events, or to simply match it with a downstream resource. To assist with this, Lambda provides a concurrent execution limit control at both the account level and the function level.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">concurrent executions</em></i><span>&nbsp;refers to the number of executions of your function code that are happening at any given time. You can estimate the concurrent execution count, but the concurrent execution count will differ depending on whether or not your Lambda function is processing events from a poll-based event source.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_34.jpg\"><span>If you create a Lambda function to process events from event sources that aren’t poll-based (for example, Lambda can process every event from other sources, like Amazon S3 or API Gateway), each published event is a unit of work, in parallel, up to your account limits. Therefore, the number of invocations these event sources make influences the concurrency.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you set the concurrent execution limit for a function, the value is deducted from the unreserved concurrency pool. For example, if your account’s concurrent execution limit is 1000 and you have 10 functions, you can specify a limit on one function at 200 and another function at 100. The remaining 700 will be shared among the other 8 functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Lambda will keep the unreserved concurrency pool at a minimum of 100 concurrent executions, so that functions that do not have specific limits set can still process requests. So, in practice, if your total account limit is 1000, you are limited to allocating 900 to individual functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By default, an AWS account’s concurrent execution limit is 1000 which will be shared by all Lambda functions. In this scenario, it is highly likely that the first function has more provisioned concurrency than the other one. It is possible that&nbsp;the concurrency execution limit of the first function is set to a significantly high value (e.g. 900) and the second function is set to use&nbsp;the unreserved account concurrency which may only contain the last 100 units out of the&nbsp;AWS account’s concurrent execution limit of 1000.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct solutions in this scenario are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Set the concurrency execution limit of both functions to 450</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Decrease the concurrency execution limit of the first function.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the concurrency execution limit of both functions to 500&nbsp;</strong></b><span>is incorrect because by default, a newly created AWS account has a concurrent execution limit of only 1000. Take note that AWS Lambda will keep the unreserved concurrency pool at a minimum of 100 concurrent executions so that functions that do not have specific limits set can still process requests. Hence, you can only allocate a concurrent execution limit of 900 for a single Lambda function or 450 for two functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the second function to use an unreserved account concurrency&nbsp;</strong></b><span>is incorrect because this may possibly be the current setting of this function, which is why the requests are being throttled. The total number of concurrent execution limits that you allocated to all Lambda functions affect the value of the unreserved concurrency limit. Since the second function is being throttled, it is highly likely that it is already using an unreserved account concurrency, which only has a low value since the units were already exhausted by the first function. Take note that the unreserved concurrency pool has a minimum value of 100 concurrent executions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the concurrency execution limit of the second function to 0&nbsp;</strong></b><span>is incorrect because this will throttle all future invocations of this function and will make the problem worse.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/scaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/scaling.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557891,
        "value": "Set the concurrency execution limit of both functions to 500.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557892,
        "value": "Set the concurrency execution limit of both functions to 450.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557893,
        "value": "Decrease the concurrency execution limit of the first function.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557894,
        "value": "Configure the second function to use an unreserved account concurrency.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557895,
        "value": "Set the concurrency execution limit of the second function to 0.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 33,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557894,
        "questionId": 388666,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557892,
        "questionId": 388666,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388666,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You recently deployed an application to a newly created AWS account, which uses two identical Lambda functions to process ad-hoc requests. The first function processes incoming requests efficiently but the second one has a longer processing time even though both of the functions have exactly the same code. Based on your monitoring, the&nbsp;Throttles&nbsp;metric of the second function is greater than the first one in Amazon CloudWatch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following are possible solutions that you can implement to fix this issue? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618821,
    "question": "AWS service ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">CodeDeploy</strong></b><span>&nbsp;is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services.&nbsp;CodeDeploy can deploy application content that runs on a server and is stored in Amazon S3 buckets, GitHub repositories, or Bitbucket repositories. CodeDeploy can also deploy a serverless Lambda function. You do not need to make changes to your existing code before you can use CodeDeploy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you deploy to an AWS Lambda compute platform, the deployment configuration specifies the way traffic is shifted to the new Lambda function versions in your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_35.jpg\"><span>Hence, the correct answer is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS CodeDeploy</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS CodeBuild</strong></b><span>&nbsp;is incorrect. This service is mainly used for compiling source code, running tests, and producing software packages ready for deployment. While it is a crucial part of the CI/CD pipeline, it does not handle the deployment process itself.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS CloudFormation&nbsp;</strong></b><span>is incorrect because it only turns your infrastructure into code. This service does not deploy applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon Kinesis</strong></b><span>&nbsp;is incorrect because this is just a data streaming service in AWS.&nbsp;This service does not deploy applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-configurations.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557896,
        "value": "AWS CodeDeploy",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557897,
        "value": "Amazon Kinesis",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557898,
        "value": "AWS CloudFormation",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557899,
        "value": "AWS CodeBuild",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 34,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557898,
        "questionId": 388667,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388667,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has a hybrid cloud architecture that connects its on-premises data center with AWS. The DevOps team has been tasked to set up the company’s continuous integration and continuous delivery (CI/CD) systems. The application deployment to both Amazon EC2 instances and on-premises servers should also be automated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following AWS service should be used to accomplish this?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618822,
    "question": "Elastic Beanstalk ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The EB CLI is a command line interface for Elastic Beanstalk that provides interactive commands that simplify creating, updating and monitoring environments from a local repository. It is recommended that you use the EB CLI as part of your everyday development and testing cycle as an alternative to the AWS Management Console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can tell the EB CLI to deploy a ZIP file or WAR file that you generate as part of a separate build process by adding the following lines to&nbsp;.elasticbeanstalk/config.yml&nbsp;in your project folder:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>deploy:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp; artifact: path/to/buildartifact.zip</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you configure the EB CLI in your Git repository, and you don’t commit the artifact to source, use the –staged option to deploy the latest build:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>~/eb$ eb deploy --staged</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">packaging your application as a&nbsp;zip&nbsp;file and deploying it using the&nbsp;eb deploy&nbsp;command</strong></b><span>&nbsp;is the correct answer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Packaging your application as a&nbsp;tar&nbsp;file and deploying it using the&nbsp;eb deploy&nbsp;command</strong></b><span>&nbsp;is incorrect because&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">tar</em></i><span>&nbsp;is not supported. You can only deploy a ZIP or WAR file.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Packaging your application as a&nbsp;tar&nbsp;file and deploying it using the&nbsp;aws elasticbeanstalk update-application&nbsp;command</strong></b><span>&nbsp;is incorrect because&nbsp;this CLI command just updates the specified properties of the application. This command does not allow you to upload packages to Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Packaging your application as a&nbsp;zip&nbsp;file and deploying it using the&nbsp;aws elasticbeanstalk update-application&nbsp;command</strong></b><span>&nbsp;is incorrect because although you have a valid file type for your application bundle (ZIP), the CLI command that was used is wrong.&nbsp;Remember that the&nbsp;update-application&nbsp;command does not allow you to upload packages to Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-configuration.html#eb-cli3-artifact\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-configuration.html#eb-cli3-artifact</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557900,
        "value": "Package your application as a tar file and deploy it using the eb deploy command.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557901,
        "value": "Package your application as a zip file and deploy it using the aws elasticbeanstalk update-application command.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557902,
        "value": "Package your application as a tar file and deploy it using the aws elasticbeanstalk update-application command.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557903,
        "value": "Package your application as a zip file and deploy it using the eb deploy command.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 35,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557903,
        "questionId": 388668,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388668,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Your team is developing a new feature on your application which is already hosted in Elastic Beanstalk. After several weeks, the new version of the application is ready to be deployed and you were instructed to handle the deployment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the correct way to deploy the new version to Elastic Beanstalk via the CLI?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618823,
    "question": "AWS CLI",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For commands that can return a large list of items, the AWS Command Line Interface (AWS CLI) adds three options that you can use to control the number of items included in the output when the AWS CLI calls a service’s API to populate the list. By default, the AWS CLI uses a page size of 1000 and retrieves all available items.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a “timed out” error. You can use the&nbsp;--page-size&nbsp;option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To include fewer items at a time in the AWS CLI output, use the&nbsp;--max-items&nbsp;option. The AWS CLI still handles pagination with the service as described above, but prints out only the number of items at a time that you specify. If the number of items output is fewer than the total number of items returned by the underlying API calls, the output includes a&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">NextToken</em></i><span>&nbsp;that you can pass to a subsequent command to retrieve the next set of items.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct ones that you should include in the AWS CLI command are the</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;--page-size&nbsp;and&nbsp;--max-items</strong></b><span>&nbsp;parameters.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">–size-only</strong></b><span>&nbsp;parameter is incorrect because this just accepts a boolean value and is typically used along with “s3 sync” command. It makes the size of each key the only criteria to use to decide whether to sync from source to destination.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">–exclude</strong></b><span>&nbsp;parameter is incorrect because it simply makes Amazon S3 exclude all files or objects that match a specified pattern from the result of the command.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">–summary</strong></b><span>&nbsp;parameter is incorrect because this only displays the summary information (number of objects, total size) of objects returned from an “s3 ls” command.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/cli/latest/reference/s3/index.html#cli-aws-s3\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/cli/latest/reference/s3/index.html#cli-aws-s3</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557904,
        "value": "--page-size",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557905,
        "value": "--max-items",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557906,
        "value": "--summarize",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557907,
        "value": "--size-only",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557908,
        "value": "--exclude",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 36,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557904,
        "questionId": 388669,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557905,
        "questionId": 388669,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388669,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An application is sending thousands of log files to an S3 bucket everyday. The request to retrieve the list of objects using the AWS CLI&nbsp;aws s3api list-objects&nbsp;command is timing out due to the high volume of data being fetched. In order to rectify this issue, you have to use pagination to control the number of results returned on your request.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following parameters should you include in CLI command for this scenario? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618824,
    "question": "Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Elastic Beanstalk</strong></b><span>&nbsp;regularly releases new platform versions to update all Linux-based and Windows Server-based&nbsp;platforms. New platform versions provide updates to existing software components and support for new features and configuration options.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the Elastic Beanstalk console or the EB CLI to update your environment’s platform version. Depending on the platform version you’d like to update to, Elastic Beanstalk recommends one of two methods for performing platform updates.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Method 1 – Update your Environment’s Platform Version</strong></b><span>&nbsp;– This is the recommended method when you’re updating to the latest platform version, without a change in runtime, web server, or application server versions, and without a change in the major platform version. This is the most common and routine platform update.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Method 2 – Perform a Blue/Green Deployment</strong></b><span>&nbsp;– This is the recommended method when you’re updating to a different runtime, web server, or application server version or to a different major platform version. This is a good approach&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">when you want to take advantage of new runtime capabilities</strong></b><span>&nbsp;or the latest Elastic Beanstalk functionality.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Because AWS Elastic Beanstalk performs an in-place update when you update your application versions, your application can become unavailable to users for a short period of time. You can avoid this downtime by performing a blue/green deployment, where you deploy the new version to a separate environment and then swap CNAMEs of the two environments to redirect traffic to the new version instantly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Blue/green deployments require that your environment runs independently of your production database if your application uses one. If your environment has an Amazon RDS DB instance attached to it, the data will not transfer over to your second environment and will be lost if you terminate the original environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">perform a Blue/Green deployment&nbsp;</strong></b><span>to safely upgrade the application’s runtime environment from Java 7 to Java 8.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Update the environment’s platform version to Java 8</strong></b><span>&nbsp;is incorrect because&nbsp;using this method is only recommended when you’re updating to the latest platform version&nbsp;without a change in the runtime environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Manually upgrade the Java runtime environment of the EC2 instances in the Elastic Beanstalk environment&nbsp;</strong></b><span>is incorrect. Although this method will work, this entails a lot of configuration to implement compared with just performing a blue/green deployment. In addition, this method may introduce operational risk because the environment may go down while the developer is doing the updates manually.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Perform a Traffic splitting deployment&nbsp;</strong></b><span>is incorrect because the scenario requires all user traffic to be immediately directed towards the new version. Take note that in Traffic splitting, updates are released incrementally to a subset of users.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.bluegreen\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.platform.upgrade.html#using-features.platform.upgrade.bluegreen</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557909,
        "value": "Update the environment's platform version to Java 8.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557910,
        "value": "Perform a Blue/Green Deployment",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557911,
        "value": "Manually upgrade the Java runtime environment of the EC2 instances in the Elastic Beanstalk environment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557912,
        "value": "Perform a Traffic splitting deployment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 37,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557910,
        "questionId": 388670,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388670,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An application is hosted in Elastic Beanstalk, which is currently running in Java 7 runtime environment. A new version of the application is ready to be deployed, and the developer was tasked to upgrade the platform to Java 8 to accommodate the changes. All user traffic must be immediately directed to the new version. If problems arise, the developer should be able to quickly revert to the previous version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST appropriate action that the developer should do to upgrade the platform?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618825,
    "question": "Kinesis Data Streams",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>There are two API calls available for writing records to a Kinesis Data Stream:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">PutRecord</strong></b><span>&nbsp;or&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">PutRecords</strong></b><span>.&nbsp;PutRecord&nbsp;writes a single record to the stream, while&nbsp;PutRecords&nbsp;writes multiple records to the stream in a batch. Kinesis Data Streams attempts to process all records in each&nbsp;PutRecords&nbsp;request. A single record failure does not stop the processing of subsequent records. As a result,&nbsp;PutRecords&nbsp;doesn’t guarantee the ordering of records. If you need to read records in the same order they are written to the stream, use&nbsp;PutRecord&nbsp;along with the&nbsp;&nbsp;SequenceNumberForOrdering&nbsp;parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_39.jpg\"><span>Furthermore, to handle duplicates, you can include a unique ID in each record that you write to the stream. The consumer application can then maintain a record of the unique IDs for the records that it has already processed. This record could be stored in an external database, like DynamoDB. When the consumer application receives a record from the stream, it can check its unique ID against the list of unique IDs that it has already processed. If the unique ID has already been processed, the consumer application can skip processing the record to avoid duplicates.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Embed a unique ID in each bid record. Use Kinesis&nbsp;PutRecord&nbsp;API to write bids. Assign a timestamp-based value for the&nbsp;SequenceNumberForOrdering&nbsp;parameter.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Embed a unique ID in each bid record. Use Kinesis&nbsp;PutRecords&nbsp;API to write bids. Assign a timestamp-based value for the&nbsp;PartitionKey&nbsp;parameter</strong></b><span>&nbsp;is incorrect because&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">PutRecords</strong></b><span>&nbsp;does not guarantee the ordering of records.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Although the SQS FIFO queue guarantees ordering and can prevent duplicates, it’s not designed for real-time applications. Hence, the following options are incorrect:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Replace the stream with an SQS FIFO queue and use the&nbsp;SendMessage&nbsp;API to write bids. Provide a unique id in the&nbsp;MessageDeduplicationId&nbsp;parameter for each bid request.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Replace the stream with an SQS FIFO queue and use the&nbsp;SendMessageBatch&nbsp;API to write bids. Provide a unique id in the&nbsp;MessageDeduplicationId&nbsp;parameter for each bid request.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><br></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html#kinesis-record-processor-duplicates-producer\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html#kinesis-record-processor-duplicates-producer</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557913,
        "value": "Replace the stream with an SQS FIFO queue and use the SendMessage API to write bids. Provide a unique id in the MessageDeduplicationId parameter for each bid request.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557914,
        "value": "Embed a unique ID in each bid record. Use Kinesis PutRecords API to write bids. Assign a timestamp-based value for the PartitionKey parameter.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557915,
        "value": "Embed a unique ID in each bid record. Use Kinesis PutRecord API to write bids. Assign a timestamp-based value for the SequenceNumberForOrdering parameter.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557916,
        "value": "Replace the stream with an SQS FIFO queue and use the SendMessageBatch API to write bids. Provide a unique id in the MessageDeduplicationId parameter for each bid request.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 38,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557915,
        "questionId": 388671,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388671,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is creating a real-time auction app for second-hand cars using Kinesis Data Streams to ingest bids. The auction rules are as follows:</span></p><ol class=\"Editor__editor-list-ol___2onc5\"><li value=\"1\" class=\"Editor__editor-listitem___EW2Qh\"><span>A       bid must be processed only once</span></li><li value=\"2\" class=\"Editor__editor-listitem___EW2Qh\"><span>An       EC2 instance consumer must process bids in the same order they were received.</span></li></ol><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which solution will meet the requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618826,
    "question": "EC2 instances",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS X-Ray receives data from services as&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">segments</em></i><span>. X-Ray then groups segments that have a common request into&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">traces</em></i><span>. X-Ray processes the traces to generate a&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">service graph</em></i><span>&nbsp;that provides a visual representation of your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The compute resources running your application logic send data about their work as&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">segments</strong></b><span>. A segment provides the resource’s name, details about the request, and details about the work done. For example, when an HTTP request reaches your application, it can record the following data about:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The host&nbsp;– hostname, alias or IP address</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The request&nbsp;– method, client address, path, user agent</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The response&nbsp;– status, content</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The work done&nbsp;– start and end times, subsegments</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Issues that occur&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-errors\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>errors, faults and exceptions</span></a><span>, including automatic capture of exception stacks.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_40.jpg\"><span>The X-Ray SDK gathers information from request and response headers, the code in your application, and metadata about the AWS resources on which it runs. You choose the data to collect by modifying your application configuration or code to instrument incoming requests, downstream requests, and AWS SDK clients.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If a load balancer or other intermediary forwards a request to your application, X-Ray takes the client IP from the&nbsp;X-Forwarded-For&nbsp;header in the request instead of from the source IP in the IP packet. The client IP that is recorded for a forwarded request can be forged, so it should not be trusted.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is that, AWS X-Ray will fetch the client IP address&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;X-Forwarded-For&nbsp;header of the request</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;X-Forwarded-Host&nbsp;header&nbsp;of&nbsp;the</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;request</strong></b></i><span>&nbsp;is incorrect because this header is primarily used in identifying the original host&nbsp;where the request originated from and not the IP address.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;ipAddress&nbsp;query parameter of the request if it exists</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because query parameters are primarily used in the application layer and not for the network layer. Take note that AWS X-Ray uses the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">X-Forwarded-For&nbsp;</em></i><span>header of the request and not any query parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;from the source IP of the IP packet</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because&nbsp;AWS X-Ray uses the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">X-Forwarded-For&nbsp;</em></i><span>header of the request and not the source IP of the IP packet since the application is using an Application Load Balancer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557917,
        "value": "From the X-Forwarded-For header of the request.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557918,
        "value": "From the ipAddress query parameter of the request if it exists.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557919,
        "value": "From the X-Forwarded-Host header of the request.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557920,
        "value": "From the source IP of the IP packet.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 39,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557917,
        "questionId": 388672,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388672,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A leading commercial bank has an online banking portal that is hosted in an Auto Scaling group of EC2 instances with an Application Load Balancer in front to distribute the incoming traffic. The application has been instrumented, and the X-Ray daemon has been installed in all instances to allow debugging and troubleshooting using AWS X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this architecture, from which source will AWS X-Ray fetch the client IP address?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618827,
    "question": "EC2 instance",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Applications that run on an EC2 instance must include AWS credentials in their AWS API requests. You could have your developers store AWS credentials directly within the EC2 instance and allow applications in that instance to use those credentials. But developers would then have to manage the credentials and ensure that they securely pass the credentials to each instance and update each EC2 instance when it’s time to rotate the credentials. That’s a lot of additional work.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Instead, you can and should use an IAM role to manage&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">temporary</em></i><span>&nbsp;credentials for applications that run on an EC2 instance. When you use a role, you don’t have to distribute long-term credentials (such as a username and password or access keys) to an EC2 instance. Instead, the role supplies temporary permissions that applications can use when they make calls to other AWS resources. When you launch an EC2 instance, you specify an IAM role to associate with the instance. Applications that run on the instance can then use the role-supplied temporary credentials to sign API requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_41.jpg\"><span>Using roles to grant permissions to applications that run on EC2 instances requires a bit of extra configuration. An application running on an EC2 instance is abstracted from AWS by the virtualized operating system. Because of this extra separation, an additional step is needed to assign an AWS role and its associated permissions to an EC2 instance and make them available to its applications. This extra step is the creation of an&nbsp;</span><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><i><em class=\"Editor__editor-text-italic___C9n8O\">instance profile</em></i></a><span>&nbsp;that is attached to the instance. The instance profile contains the role and can provide the role’s temporary credentials to an application that runs on the instance. Those temporary credentials can then be used in the application’s API calls to access resources and to limit access to only those resources that the role specifies. Note that only one role can be assigned to an EC2 instance at a time, and all applications on the instance share the same role and permissions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using roles in this way has several benefits. Because role credentials are temporary and rotated automatically, you don’t have to manage credentials, and you don’t have to worry about long-term security risks. In addition, if you use a single role for multiple instances, you can make a change to that one role and the change is propagated automatically to all the instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">using an IAM Role to grant the application the necessary permissions to upload data to S3</strong></b><span>&nbsp;is the correct answer for this scenario as this provides the safest way to integrate your application hosted in EC2 and S3.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Storing the access keys in the instance and then using the AWS SDK to upload the results to S3</strong></b><span>&nbsp;is incorrect because this will expose the AWS access credentials to all users who have access to the EC2 instance. Since this option entails a security risk, this is incorrect as is not the safest method.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Installing the AWS CLI then using it to upload the results to S3&nbsp;</strong></b><span>is incorrect. Although this option is valid, this method also presents a security risk just as shown above. By default, an AWS CLI requires you to store the AWS access keys in your instance which will be used in executing the commands. Hence, this option is incorrect.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using an IAM Inline Policy to grant the application the necessary permissions to upload data to S3</strong></b><span>&nbsp;is incorrect because inline policies are useful if you want to maintain a strict one-to-one relationship between a policy and the principal entity that it’s applied to. This option doesn’t provide a secure way of allowing the application that is hosted in EC2 to upload data to an S3 bucket. You should use an IAM Role instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557921,
        "value": "Install the AWS CLI then use it to upload the results to S3.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557922,
        "value": "Use an IAM Inline Policy to grant the application the necessary permissions to upload data to S3.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557923,
        "value": "Store the access keys in the instance then use the AWS SDK to upload the results to S3.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557924,
        "value": "Use an IAM Role to grant the application the necessary permissions to upload data to S3.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 40,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557924,
        "questionId": 388673,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388673,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is building the cloud architecture of an application which will be hosted in a large EC2 instance. The application will process the data and it will upload results to an S3 bucket.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the SAFEST way to implement this architecture?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618828,
    "question": "S3 bucket",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The unit of scale for AWS Lambda is a concurrent execution.&nbsp;However, scaling indefinitely is not desirable in all scenarios. For example, you may want to control your concurrency for cost reasons or to regulate how long it takes you to process a batch of events, or to simply match it with a downstream resource. To assist with this, Lambda provides a concurrent execution limit control at both the account level and the function level.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">concurrent executions</em></i><span>&nbsp;refers to the number of executions of your function code that are happening at any given time. You can estimate the concurrent execution count, but the concurrent execution count will differ depending on whether or not your Lambda function is processing events from a poll-based event source.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you create a Lambda function to process events from event sources that aren’t poll-based (for example, Lambda can process every event from other sources, like Amazon S3 or API Gateway), each published event is a unit of work, in parallel, up to your account limits. Therefore, the number of invocations these event sources make influences the concurrency.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you set the concurrent execution limit for a function, the value is deducted from the unreserved concurrency pool. For example, if your account’s concurrent execution limit is 1000 and you have 10 functions, you can specify a limit on one function at 200 and another function at 100. The remaining 700 will be shared among the other 8 functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Lambda will keep the unreserved concurrency pool at a minimum of 100 concurrent executions, so that functions that do not have specific limits set can still process requests. So, in practice, if your total account limit is 1000, you are limited to allocating 900 to individual functions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The scenario mentioned that an Application Load Balancer is used to distribute the incoming traffic to the two Lambda functions as registered targets, just as shown below:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_42D.jpg\"><span>By default, an AWS account’s concurrent execution limit is 1000 which will be shared by all Lambda functions. In this scenario, it is highly likely that the first function has more provisioned concurrency than the other one. Hence, the correct answer in this scenario is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the concurrency execution limit provided to the first function is significantly higher than the second function.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the first function is using the unreserved account concurrency while the second function has been set with a concurrency execution limit of 800</strong></b><span>&nbsp;is incorrect because this will actually cause the first function to throttle the requests instead of the second one.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the concurrency execution limit provided to the first function is less than the second function</strong></b><span>&nbsp;is incorrect because what is really happening is the other way around:&nbsp;the concurrency execution limit provided to the first function is significantly higher than the second function, which is why the latter is throttling the requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the first function is using the unreserved account concurrency while the second function has been set with a concurrency execution limit of 1000</strong></b><span>&nbsp;is incorrect because, in the first place, you cannot set a concurrency execution limit of 1000 since the maximum that you can allocate per function is only 900. Take note if you allocate the maximum concurrency execution to the second function, the&nbsp;unreserved account concurrency will actually just have a value of 100.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/scaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/scaling.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557925,
        "value": "The first function is using the unreserved account concurrency while the second function has been set with a concurrency execution limit of 1000.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557926,
        "value": "The concurrency execution limit provided to the first function is less than the second function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557927,
        "value": "The first function is using the unreserved account concurrency while the second function has been set with a concurrency execution limit of 800.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557928,
        "value": "The concurrency execution limit provided to the first function is significantly higher than the second function.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 41,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557927,
        "questionId": 388674,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388674,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has an AWS account with only 2 Lambda functions, which process data and store the results in an S3 bucket. An Application Load Balancer is used to distribute the incoming traffic to the two Lambda functions as registered targets. You noticed that in peak times, the first Lambda function works with optimal performance but the second one is throttling the incoming requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely root cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618829,
    "question": "Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can integrate an API method in your API Gateway with a custom HTTP endpoint of your application in two ways:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– HTTP proxy integration</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– HTTP custom integration</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In your API Gateway console, you can define the type of HTTP integration of your resource by checking, or not checking, the “</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Configure as proxy resource</strong></b><span>” checkbox. For example, this API Resource configuration is a type of&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">HTTP Proxy integration</em></i><span>&nbsp;since the appropriate checkbox is ticked:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_43.jpg\"><span>With proxy integration, the setup is simple. You only need to set the HTTP method and the HTTP endpoint URI, according to the backend requirements, if you are not concerned with content encoding or caching.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>With custom integration, setup is more involved. In addition to the proxy integration setup steps, you need to specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response.&nbsp;API Gateway supports the following endpoint ports: 80, 443 and 1024-65535.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Programmatically, you choose an integration type by setting the&nbsp;</span><a href=\"https://docs.aws.amazon.com/apigateway/api-reference/resource/integration/#type\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>type</span></a><span>&nbsp;property on the&nbsp;</span><a href=\"https://docs.aws.amazon.com/apigateway/api-reference/resource/integration/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>Integration</span></a><span>&nbsp;resource. For the Lambda proxy integration, the value is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_PROXY</strong></b><span>. For the Lambda custom integration and all other AWS integrations, it is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS</strong></b><span>. For the HTTP proxy integration and HTTP integration, the value is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">HTTP_PROXY</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">HTTP</strong></b><span>, respectively. For the mock integration, the&nbsp;type&nbsp;value is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">MOCK</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Since the integration type that is being described in the scenario fits the definition of an&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">HTTP proxy integration</em></i><span>, the correct answer in this scenario is to use the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">HTTP_PROXY</strong></b><span>&nbsp;integration type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS</strong></b><span>&nbsp;is incorrect because this type is only used for&nbsp;Lambda custom integration. Take note that the scenario uses an application hosted in EC2 and not in Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_PROXY</strong></b><span>&nbsp;is incorrect because this type is primarily used for&nbsp;Lambda proxy integration. The scenario didn’t mention that it uses a serverless application or Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">HTTP</strong></b><span>&nbsp;is incorrect because this type is only used for HTTP custom integration where you need to specify how the incoming request data is mapped to the integration request and how the resulting integration response data is mapped to the method response.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/setup-http-integrations.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/setup-http-integrations.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-integration-types.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557929,
        "value": "HTTP",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557930,
        "value": "HTTP_PROXY",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557931,
        "value": "AWS_PROXY",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557932,
        "value": "AWS",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 42,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557930,
        "questionId": 388675,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388675,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has a website hosted in a multicontainer Docker environment in Elastic Beanstalk. There is a requirement to integrate the website with API Gateway, where it simply passes client-submitted method requests to the backend. It is important that the client and backend interact directly with no intervention from API Gateway after the API method is set up, except for known issues such as unsupported characters.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following integration types is the MOST suitable one to use to meet this requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618830,
    "question": " CodeDeploy",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The content in the&nbsp;'hooks'&nbsp;section of the AppSpec file varies, depending on the compute platform for your deployment. The&nbsp;'hooks'&nbsp;section for an EC2/On-Premises deployment contains mappings that link deployment lifecycle event hooks to one or more scripts. The&nbsp;'hooks'&nbsp;section for a Lambda or an Amazon ECS deployment specifies Lambda validation functions to run during a deployment lifecycle event. If an event hook is not present, no operation is executed for that event. This section is required only if you are running scripts or Lambda validation functions as part of the deployment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An AWS Lambda hook is one Lambda function specified with a string on a new line after the name of the lifecycle event. Each hook is executed once per deployment. Following are descriptions of the hooks that are available for use in your AppSpec file.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">BeforeAllowTraffic</strong></b><span>&nbsp;– Use to run tasks before traffic is shifted to the deployed Lambda function version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AfterAllowTraffic</strong></b><span>&nbsp;– Use to run tasks after all traffic is shifted to the deployed Lambda function version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In a serverless Lambda function version deployment, event hooks run in the following order:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_44.jpg\"><span>Take note that&nbsp;Start,&nbsp;AllowTraffic, and&nbsp;End&nbsp;events in the deployment cannot be scripted, which is why they appear in gray in the above diagram.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">BeforeAllowTraffic</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Start</strong></b><span>&nbsp;is incorrect because this deployment lifecycle event in Lambda cannot be scripted or used. In this scenario, the correct event that you should configure is the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">BeforeAllowTraffic</em></i><span>&nbsp;event.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">BeforeInstall</strong></b><span>&nbsp;is incorrect because this event is only applicable for ECS, EC2 or On-Premises compute platforms and not for Lambda deployments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Install</strong></b><span>&nbsp;is incorrect because this&nbsp;uses the CodeDeploy agent to copy the revision files from the temporary location to the final destination folder of the EC2 or On-Premises server. This deployment lifecycle event is not available for Lambda as well as for ECS deployments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-lambda\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html#appspec-hooks-lambda</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-steps.html#deployment-steps-lambda\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-steps.html#deployment-steps-lambda</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557933,
        "value": "Install",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557934,
        "value": "Start",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557935,
        "value": "BeforeInstall",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557936,
        "value": "BeforeAllowTraffic",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 43,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557936,
        "questionId": 388676,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388676,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is preparing the application specification (AppSpec) file in CodeDeploy, which will be used to deploy her Lambda functions to AWS. In the deployment, she needs to configure CodeDeploy to run a task before the traffic is shifted to the deployed Lambda function version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which deployment lifecycle event should she configure in this scenario?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618831,
    "question": "DynamoDB database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>DynamoDB Streams provides a time-ordered sequence of item-level changes in any DynamoDB table. The changes are de-duplicated and stored for 24 hours. Applications can access this log and view the data items as they appeared before and after they were modified, in near real time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Kinesis Adapter</strong></b><span>&nbsp;is the recommended way to consume streams from DynamoDB for real-time processing.&nbsp;The DynamoDB Streams API is intentionally similar to that of Kinesis Streams, a service for real-time processing of streaming data at a massive scale.&nbsp;You can write applications for Kinesis Streams using the Kinesis Client Library (KCL). The KCL simplifies coding by providing useful abstractions above the low-level Kinesis Streams API.&nbsp;As a DynamoDB Streams user, you can leverage the design patterns found within the KCL to process DynamoDB Streams shards and stream records. To do this, you use the DynamoDB Streams Kinesis Adapter.&nbsp;The Kinesis Adapter implements the Kinesis Streams interface, so that the KCL can be used for consuming and processing records from DynamoDB Streams.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_45.jpg\"><span>When an item in the table is modified,&nbsp;StreamViewType&nbsp;determines what information is written to the stream for this table. Valid values for&nbsp;StreamViewType&nbsp;are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">KEYS_ONLY</strong></b><span>&nbsp;– Only the key attributes of the modified item are written to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">NEW_IMAGE</strong></b><span>&nbsp;– The entire item, as it appears after it was modified, is written to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">OLD_IMAGE</strong></b><span>&nbsp;– The entire item, as it appeared before it was modified, is written to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">NEW_AND_OLD_IMAGES</strong></b><span>&nbsp;– Both the new and the old item images of the item are written to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable DynamoDB Streams and set the value of&nbsp;StreamViewType&nbsp;to NEW_IMAGE then use Kinesis Adapter in the application to consume streams from DynamoDB.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable DynamoDB Streams and set the value of&nbsp;StreamViewType&nbsp;to NEW_AND_OLD_IMAGE. Create a trigger in AWS Lambda to capture stream data and forward it to your application</strong></b><span>&nbsp;is incorrect. Using Lambda for real-time data analytics is not a suitable solution for this scenario since it reads records in batches. A more appropriate service to use is the Kinesis service. In addition, using the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">StreamViewType&nbsp;of NEW_AND_OLD_IMAGE</em></i><span>&nbsp;is wrong since this will send both the old and the new values of the item. Remember that it is specifically mentioned in the scenario that only the new values should be tracked.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable DynamoDB Streams and set the value of&nbsp;StreamViewType&nbsp;to NEW_IMAGE. Create a trigger in AWS Lambda to capture stream data and forward it to your application</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because just like what is mentioned above, it is better to use Kinesis instead of Lambda for the real-time data analytics application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable DynamoDB Streams and set the value of&nbsp;StreamViewType&nbsp;to NEW_AND_OLD_IMAGE. Use Kinesis Adapter in the application to consume streams from DynamoDB</strong></b><span>&nbsp;is incorrect because this will send both the old and the new values of the item to the data analytics application. The correct&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">StreamViewType&nbsp;to use here should be NEW_IMAGE.</em></i></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.KCLAdapter.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_StreamSpecification.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557937,
        "value": "Enable DynamoDB Streams and set the value of StreamViewType to NEW_AND_OLD_IMAGE. Create a trigger in AWS Lambda to capture stream data and forward it to your application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557938,
        "value": "Enable DynamoDB Streams and set the value of StreamViewType to NEW_IMAGE. Create a trigger in AWS Lambda to capture stream data and forward it to your application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557939,
        "value": "Enable DynamoDB Streams and set the value of StreamViewType to NEW_AND_OLD_IMAGE. Use Kinesis Adapter in the application to consume streams from DynamoDB.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557940,
        "value": "Enable DynamoDB Streams and set the value of StreamViewType to NEW_IMAGE. Use Kinesis Adapter in the application to consume streams from DynamoDB.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 44,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557940,
        "questionId": 388677,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388677,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has a global multi-player game with a multi-master DynamoDB database topology which stores data in multiple AWS regions. You were assigned to develop a real-time data analytics application which will track and store the recent changes on all the tables from various regions. Only the new data of the recently updated item is needed to be tracked by your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST suitable way to configure the data analytics application to detect and retrieve the updated database entries automatically?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618832,
    "question": "Amazon Kinesis Data Stream",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon Kinesis Data Streams supports changes to the data record retention period of your stream. A Kinesis data stream is an ordered sequence of records meant to be written to and read from in real-time. Data records are therefore stored in shards in your stream temporarily. The time period from when a record is added to when it is no longer accessible is called the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">retention period</em></i><span>. A Kinesis data stream stores record for up to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">24 hours</strong></b><span>&nbsp;by default.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_46.jpg\"><span>You can increase the retention period up to 8760 hours (365 days) using the&nbsp;</span><a href=\"https://docs.aws.amazon.com/kinesis/latest/APIReference/API_IncreaseStreamRetentionPeriod.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>IncreaseStreamRetentionPeriod</span></a><span>&nbsp;operation. You can decrease the retention period to a minimum of 24 hours using the&nbsp;</span><a href=\"https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DecreaseStreamRetentionPeriod.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>DecreaseStreamRetentionPeriod</span></a><span>&nbsp;operation. The request syntax for both operations includes the stream name and the retention period in hours. Finally, you can check the current retention period of a stream by calling the&nbsp;</span><a href=\"https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStream.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>DescribeStream</span></a><span>&nbsp;operation.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Kinesis Data Streams supports changes to the data record retention period of your stream. A Kinesis data stream is an ordered sequence of records meant to be written to and read from in real-time. Data records are therefore stored in shards in your stream temporarily.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, the consumer of the data stream is configured to process the data&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">every other day.</strong></b><span>&nbsp;Since the default data retention of the Kinesis data stream is only 24 hours, the data from the day before is already lost prior to the scheduled processing. Hence, the root cause of the problem in this scenario is that&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">by default,&nbsp;the data records are only accessible for 24 hours from the time they are added to a Kinesis stream</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the sensors are having intermittent connection issues</strong></b><span>&nbsp;is incorrect because the sensors have been verified to be working properly, hence, this is not the root cause.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the Amazon Kinesis Data Stream has too many open shards</strong></b><span>&nbsp;is incorrect because having this configuration is irrelevant in this scenario as it just increases the data stream’s rate of data flow.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the Amazon Kinesis Data Stream automatically deletes duplicate data</strong></b><span>&nbsp;is incorrect because Amazon Kinesis does not do this by default.&nbsp;If the sensors send two records with identical data, these will have unique sequence numbers in the stream. This does not have anything to do with data retention; hence, it is irrelevant in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Reference:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"http://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>http://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557941,
        "value": "The sensors are having intermittent connection issues.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557942,
        "value": "By default, the data records are only accessible for 24 hours from the time they are added to a Kinesis stream.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557943,
        "value": "The Amazon Kinesis Data Stream has too many open shards.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557944,
        "value": "The Amazon Kinesis Data Stream automatically deletes duplicate data.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 45,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557942,
        "questionId": 388678,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388678,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A data analytics company has installed sensors to track the number of people that goes to the mall. The data sets are collected in real-time by an Amazon Kinesis Data Stream which has a consumer that is configured to process data every other day and store the results to S3. Your team noticed that your S3 bucket is only receiving half of the data that is being sent to the Kinesis stream but after checking, you have verified that the sensors are properly sending the data to Amazon Kinesis in real-time without any issues.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely root cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618833,
    "question": "DynamoDB database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you create a global secondary index on a provisioned mode table, you must specify read and write capacity units for the expected workload on that index. The provisioned throughput settings of a global secondary index are separate from those of its base table. A&nbsp;Query&nbsp;operation on a global secondary index consumes read capacity units from the index, not the base table. When you put, update, or delete items in a table, the global secondary indexes on that table are also updated; these index updates consume write capacity units from the index, not from the base table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_47.jpg\"><span>For example, if you&nbsp;Query&nbsp;a global secondary index and exceed its provisioned read capacity, your request will be throttled. If you perform heavy write activity on the table but a global secondary index on that table has insufficient write capacity, then the write activity on the table will be throttled.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To avoid potential throttling, the provisioned write capacity for a global secondary index should be equal or greater than the write capacity of the base table since new updates will write to both the base table and global secondary index.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To view the provisioned throughput settings for a global secondary index, use the&nbsp;DescribeTable&nbsp;operation; detailed information about all of the table’s global secondary indexes will be returned.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the most likely cause of this issue is that&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the provisioned write capacity for the global secondary index is less than the write capacity of the base table.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The&nbsp;provisioned write capacity for the global secondary index is greater than the write capacity of the base table&nbsp;</strong></b><span>is incorrect because it should be the other way around, just as mentioned above. If the provisioned WCU of the global secondary index is greater than its base table then this issue is unlikely to happen.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The provisioned throughput exceeds the current throughput limit for your account</strong></b><span>&nbsp;is incorrect because this will only happen if DynamoDB returns a&nbsp;RequestLimitExceeded&nbsp;exception.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The rate of requests exceeds the allowed throughput&nbsp;</strong></b><span>is incorrect because&nbsp;this will only happen if DynamoDB returns a&nbsp;ThrottlingException.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html#GSI.ThroughputConsiderations\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html#GSI.ThroughputConsiderations</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.MessagesAndCodes\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.MessagesAndCodes</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557945,
        "value": "The provisioned write capacity for the global secondary index is less than the write capacity of the base table.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557946,
        "value": "The rate of requests exceeds the allowed throughput.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557947,
        "value": "The provisioned write capacity for the global secondary index is greater than the write capacity of the base table.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557948,
        "value": "The provisioned throughput exceeds the current throughput limit for your account.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 46,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557945,
        "questionId": 388679,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388679,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A write-heavy data analytics application is using DynamoDB database which has global secondary index. Whenever the application is performing heavy write activities on the table, the DynamoDB requests return a&nbsp;ProvisionedThroughputExceededException.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618834,
    "question": "Elastic Beanstalk ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In ElasticBeanstalk, you can choose from a variety of deployment methods:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-All at once</strong></b><span>&nbsp;– Deploy the new version to all instances simultaneously. All instances in your environment are out of service for a short time while the deployment occurs. This is the method that provides the least amount of time for deployment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Rolling</strong></b><span>&nbsp;– Deploy the new version in batches. Each batch is taken out of service during the deployment phase, reducing your environment’s capacity by the number of instances in a batch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Rolling with additional batch</strong></b><span>&nbsp;– Deploy the new version in batches, but first launch a new batch of instances to ensure full capacity during the deployment process.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Immutable</strong></b><span>&nbsp;– Deploy the new version to a fresh group of instances by performing an&nbsp;</span><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environmentmgmt-updates-immutable.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>immutable update</span></a><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">-Blue/Green</strong></b><span>&nbsp;– Deploy the new version to a separate environment, and then swap CNAMEs of the two environments to redirect traffic to the new version instantly.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Refer to the table below for the characteristics of each deployment method as well as the amount of time it takes to do the deployment, as seen in the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploy Time</strong></b><span>&nbsp;column:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_48.jpg\"><span>Hence, the correct answer in this scenario is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">All at once</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Rolling</strong></b><span>&nbsp;is incorrect because this will deploy the new version in batches only to existing instances, without provisioning new resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Immutable</strong></b><span>&nbsp;is incorrect because this will deploy the new version to a fresh group of instances by performing an immutable update. Considering the time to deploy additional instances and installing the new version, this option does not provide the least amount of deployment time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Rolling with additional batch&nbsp;</strong></b><span>is incorrect because this just deploys the new version in batches. It first launches a new batch of instances to ensure full capacity during the deployment process then proceeds in deploying the new version.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.CNAMESwap.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557949,
        "value": "All at once",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557950,
        "value": "Immutable",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557951,
        "value": "Rolling with additional batch",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557952,
        "value": "Rolling",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 47,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557949,
        "questionId": 388680,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388680,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An application has recently been migrated from an on-premises data center to a development Elastic Beanstalk environment. A developer will do iterative tests and therefore needs to deploy code changes and view them as quickly as possible.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following options take the LEAST amount of time to complete the deployment?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618835,
    "question": "MFA",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The&nbsp;GetSessionToken&nbsp;API returns a set of temporary credentials for an AWS account or IAM user. The credentials consist of an access key ID, a secret access key, and a security token. Typically, you use&nbsp;GetSessionToken&nbsp;if you want to use MFA to protect programmatic calls to specific AWS API operations like Amazon EC2 StopInstances. MFA-enabled IAM users would need to call GetSessionToken and submit an MFA code that is associated with their MFA device.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_49.jpg\"><span>Using the temporary security credentials that are returned from the call, IAM users can then make programmatic calls to API operations that require MFA authentication. If you do not supply a correct MFA code, then the API returns an access denied error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Thus, the correct answer is to use the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">GetSessionToken</strong></b><span>&nbsp;API&nbsp;in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AssumeRoleWithWebIdentity</strong></b><span>&nbsp;is incorrect because this only returns a set of temporary security credentials for federated users who are authenticated through public identity providers such as Amazon, Facebook, Google, or OpenID, which were not mentioned in the scenario.&nbsp;This API does not support MFA.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AssumeRoleWithSAML</strong></b><span>&nbsp;is incorrect because&nbsp;this just returns a set of temporary security credentials for users who have been authenticated via a SAML authentication response. This operation provides a mechanism for tying an enterprise identity store or directory to role-based AWS access without user-specific credentials or configuration. This API does not support MFA.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">GetFederationToken</strong></b><span>&nbsp;is incorrect because it does not support MFA. The appropriate STS API that the developer should use is&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">GetSessionToken.</em></i></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html#stsapi_comparison\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html#stsapi_comparison</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557953,
        "value": "AssumeRoleWithSAML",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557954,
        "value": "AssumeRoleWithWebIdentity",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557955,
        "value": "GetFederationToken",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557956,
        "value": "GetSessionToken",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 48,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557954,
        "questionId": 388681,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388681,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer wants to use multi-factor authentication (MFA) to protect programmatic calls to specific AWS API operations like Amazon EC2 StopInstances. He needs to call an API where he can submit the MFA code that is associated with his MFA device. Using the temporary security credentials that are returned from the call, he can then make programmatic calls to API operations that require MFA authentication.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which API should the developer use to properly implement this security feature?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618836,
    "question": "Scenario",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale. Since fast performance is one of the requirements asked in the scenario, DynamoDB should be an option to consider.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In DynamoDB, an&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">item</em></i><span>&nbsp;is a collection of attributes. Each attribute has a name and a value. An attribute value can be a scalar, a set, or a document type.&nbsp;DynamoDB provides four operations for basic create/read/update/delete (CRUD) functionality:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>PutItem&nbsp; &nbsp; &nbsp; – create an item.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>GetItem&nbsp; &nbsp; &nbsp; – read an item.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>UpdateItem&nbsp;– update an item.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>DeleteItem&nbsp;– delete an item.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the&nbsp;UpdateItem&nbsp;operation to implement an&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">atomic counter</em></i><span>—a numeric attribute that is incremented, unconditionally, without interfering with other write requests.&nbsp;With an atomic counter,&nbsp;the numeric value will increment each time you call&nbsp;UpdateItem.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_50.jpg\"><span>For example, you might use an atomic counter to keep track of the number of visitors to a website. In this case, your application would increment a numeric value, regardless of its current value. If an&nbsp;UpdateItem&nbsp;operation should fail, the application could simply retry the operation. This would risk updating the counter twice, but you could probably tolerate a slight overcounting or undercounting of website visitors.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">setup Amazon DynamoDB for the database and implement atomic counters for the&nbsp;UpdateItem&nbsp;operation of the website counter</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using Amazon RDS for the database and setting up SQL AUTO_INCREMENT on your tables&nbsp;</strong></b><span>is incorrect because RDS is not scalable enough to handle&nbsp;millions of data being submitted by readers worldwide. Auto-increment allows a unique number to be generated automatically when a new record is inserted into a table. This is often the primary key field that we would like to be created automatically every time a new record is inserted. Since you would not want to add a new database entry for every link click and immediately consume all your storage space, it would be better to use DynamoDB’s atomic counter instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Launching an Amazon Redshift for the database and applying a step count of 1 for the IDENTITY column</strong></b><span>&nbsp;is incorrect because Redshift is more suited for data warehousing demands that need parallel execution capabilities and columnar storage types.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Taking advantage of Amazon Aurora’s performance speed and AUTO_INCREMENT feature for item updates&nbsp;</strong></b><span>is incorrect. Although Aurora is a scalable database service, using the AUTO_INCREMENT feature of SQL does not suit the scenario’s requirement.&nbsp;Auto-increment simply allows a unique number to be generated automatically when a new record is inserted into a table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/dynamodb/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/dynamodb/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.AtomicCounters\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.AtomicCounters</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_TABLE_NEW.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_TABLE_NEW.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557957,
        "value": "Take advantage of Amazon Aurora's performance speed and AUTO_INCREMENT feature for item updates.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557958,
        "value": "Launch an Amazon Redshift for the database and apply a step count of 1 for the IDENTITY column.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557959,
        "value": "Set up Amazon DynamoDB for the database and implement atomic counters for UpdateItem operation of the website counter.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557960,
        "value": "Use Amazon RDS for the database and setup SQL AUTO_INCREMENT on your tables.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 49,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557959,
        "questionId": 388682,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388682,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is instructed to collect data on the number of times that web visitors click the advertisement link of a popular news website. A database entry containing the count will be incremented for every click. Given that the website has millions of readers worldwide, your database should be configured to provide optimal performance to capture all the click events.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the BEST service that the developer should implement in this scenario?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618837,
    "question": "DynamoDB database",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Lambda supports synchronous and asynchronous invocation of a Lambda function. You can control the invocation type only when you invoke a Lambda function (referred to as&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">on-demand invocation</em></i><span>). The following examples illustrate on-demand invocations:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>-Your custom application invokes a Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>-You manually invoke a Lambda function (for example, using the AWS CLI) for testing purposes.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In both cases, you invoke your Lambda function using the&nbsp;</span><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html\" class=\"Editor__editor-link___3vl2C\"><span>Invoke</span></a><span>&nbsp;operation, and you can specify the invocation type as synchronous or asynchronous.&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_51.jpg\"><span>When you use AWS services as a trigger, the invocation type is predetermined for each service. You have no control over the invocation type that these event sources use when they invoke your Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the Invoke API,&nbsp;you have 3 options to choose from for the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">InvocationType:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">RequestResponse</strong></b><span>&nbsp;(default) – Invoke the function synchronously. Keep the connection open until the function returns a response or times out. The API response includes the function response and additional data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Event</strong></b><span>&nbsp;– Invoke the function asynchronously. Send events that fail multiple times to the function’s dead-letter queue (if it’s configured). The API response only includes a status code.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">DryRun</strong></b><span>&nbsp;– Validate parameter values and verify that the user or role has permission to invoke the function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is the option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;Invoke&nbsp;API to call the Lambda function and set the invocation type request parameter to&nbsp;Event</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;InvokeAsync&nbsp;API to call the Lambda function and set the invocation type request parameter to&nbsp;RequestResponse</strong></b><span>&nbsp;is incorrect because the InvokeAsync API is already deprecated. In addition, using the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">RequestResponse</strong></b><span>&nbsp;type will invoke the Lambda function synchronously.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;Invoke&nbsp;API to call the Lambda function and set the invocation type request parameter to&nbsp;RequestResponse</strong></b><span>&nbsp;is incorrect because this is the default value of the invocation type that will invoke the Lambda function synchronously.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;InvokeAsync&nbsp;API to call the Lambda function and set the invocation type request parameter to&nbsp;Event</strong></b><span>&nbsp;is incorrect. Although it uses the correct invocation type, the InvokeAsync API that it uses is already deprecated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Reference:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/invocation-options.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/invocation-options.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html</span></a></p>",
    "choices": [
      {
        "id": 1557961,
        "value": "Use the Invoke API to call the Lambda function and set the invocation type request parameter to Event.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557962,
        "value": "Use the InvokeAsync API to call the Lambda function and set the invocation type request parameter to RequestResponse.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557963,
        "value": "Use the Invoke API to call the Lambda function and set the invocation type request parameter to RequestResponse.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557964,
        "value": "Use the InvokeAsync API to call the Lambda function and set the invocation type request parameter to Event.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 50,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557964,
        "questionId": 388683,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388683,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You are developing a serverless application in AWS composed of several Lambda functions and a DynamoDB database. The requirement is to process the requests asynchronously.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST suitable way to accomplish this?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618838,
    "question": "ECS cluster ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The AWS X-Ray SDK does not send trace data directly to AWS X-Ray. To avoid calling the service every time your application serves a request, the SDK sends the trace data to a daemon, which collects segments for multiple requests and uploads them in batches. Use a script to run the daemon alongside your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To properly instrument your applications in Amazon ECS, you have to create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster. You can use port mappings and network mode settings in your task definition file to allow your application to communicate with the daemon container.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_52.jpg\"><span>The AWS X-Ray daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. The daemon works in conjunction with the AWS X-Ray SDKs and must be running so that data sent by the SDKs can reach the X-Ray service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct steps to properly instrument the application is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster.&nbsp;</strong></b><span>In addition,</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;you also have to configure the port mappings and network mode settings in your task definition file to allow traffic on UDP port 2000.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the port mappings and network mode settings in the container agent to allow traffic on TCP port 2000&nbsp;</strong></b><span>is incorrect because this should be done in the task definition and not in the container agent. Moreover, X-Ray is primarily using the UDP port 2000, so this should also be added alongside with the TCP port mapping.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Manually installing the X-Ray daemon to the instances via a user data script&nbsp;</strong></b><span>is incorrect because this is only applicable if your application is hosted in an EC2 instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding the&nbsp;xray-daemon.config&nbsp;configuration file in your Docker image</strong></b><span>&nbsp;is incorrect because this step is not suitable for ECS. The&nbsp;xray-daemon.config&nbsp;configuration file is primarily used in Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/scorekeep-ecs.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/scorekeep-ecs.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557965,
        "value": "Create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557966,
        "value": "Configure the port mappings and network mode settings in the container agent to allow traffic on TCP port 2000.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557967,
        "value": "Manually install the X-Ray daemon to the instances via a user data script.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557968,
        "value": "Add the xray-daemon.config configuration file in your Docker image",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557969,
        "value": "Configure the port mappings and network mode settings in your task definition file to allow traffic on UDP port 2000.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 51,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557968,
        "questionId": 388684,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557965,
        "questionId": 388684,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388684,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A Docker application hosted on an ECS cluster has encountered intermittent unavailability issues and timeouts. The lead DevOps engineer instructed you to instrument the application to detect where high latencies are occurring and to determine the specific services and paths impacting application performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following steps should you take to accomplish this task properly? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618839,
    "question": "ECS",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>By default, IAM users don’t have permission to create or modify Amazon ECS resources or perform tasks using the Amazon ECS API. This means that they also can’t do so using the Amazon ECS console or the AWS CLI. To allow IAM users to create or modify resources and perform tasks, you must create IAM policies. Policies grant IAM users permission to use specific resources and API actions. Then, attach those policies to the IAM users or groups that require those permissions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_53.jpg\"><span>When you attach a policy to a user or group of users, it allows or denies the users permission to perform the specified tasks on the specified resources.&nbsp;Likewise, Amazon ECS container instances make calls to the Amazon ECS and Amazon EC2 APIs on your behalf, so they need to authenticate with your credentials. This authentication is accomplished by creating an IAM role for your container instances and associating that role with your container instances when you launch them.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you use an Elastic Load Balancing load balancer with your Amazon ECS services, calls to the Amazon EC2 and Elastic Load Balancing APIs are made on your behalf to register and deregister container instances with your load balancers.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the most suitable solution in this scenario is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Create 4 different IAM Roles with the required permissions and attach them to each of the 4 ECS tasks</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating an IAM Group with all the required permissions and attaching them to each of the 4 ECS tasks&nbsp;</strong></b><span>is incorrect because you cannot directly attach an IAM Group to an ECS Task. Attaching an IAM Role is a more suitable solution in this scenario and not an IAM Group.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating 4 different Container Instance IAM Roles with the required permissions and attaching them to each of the 4 ECS tasks</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because a Container Instance IAM Role only applies if you are using the EC2 launch type. Take note that the scenario says that the application will be using a Fargate launch type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating 4 different Service-Linked Roles with the required permissions and attaching them to each of the 4 ECS tasks</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because a service-linked role is a unique type of IAM role that is linked directly to Amazon ECS itself, not on the ECS task. Service-linked roles are predefined by Amazon ECS and include all the permissions that the service requires to call other AWS services on your behalf.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_IAM_role.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_IAM_role.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html#create_task_iam_policy_and_role\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html#create_task_iam_policy_and_role</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557970,
        "value": "Create an IAM Group with all the required permissions and attach them to each of the 4 ECS tasks.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557971,
        "value": "Create 4 different Container Instance IAM Roles with the required permissions and attach them to each of the 4 ECS tasks.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557972,
        "value": "Create 4 different IAM Roles with the required permissions and attach them to each of the 4 ECS tasks.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557973,
        "value": "Create 4 different Service-Linked Roles with the required permissions and attach them to each of the 4 ECS tasks.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 52,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557972,
        "questionId": 388685,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388685,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is building an application that will be hosted in ECS and must be configured to run tasks and services using the Fargate launch type. The application will have four different tasks, each of which will access different AWS resources than the others.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST efficient solution that can provide your application in ECS access to the required AWS resources?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618840,
    "question": "CloudFormation",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To create a Lambda function, you first create a Lambda function deployment package, a .zip or .jar file consisting of your code and any dependencies. When creating the zip, include only the code and its dependencies, not the containing folder. You will then need to set the appropriate security permissions for the zip package.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you are using a CloudFormation template, you can configure the&nbsp;AWS::Lambda::Function&nbsp;resource which creates a Lambda function. To create a function, you need a deployment package and an execution role. The deployment package contains your function code. The execution role grants the function permission to use AWS services, such as Amazon CloudWatch Logs for log streaming and AWS X-Ray for request tracing.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_54.jpg\"><span>Under the&nbsp;AWS::Lambda::Function&nbsp;resource, you can use the&nbsp;Code&nbsp;property which contains the deployment package for a Lambda function. For all runtimes, you can specify the location of an object in Amazon S3.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For Node.js and Python functions, you can specify the function code inline in the template. Changes to a deployment package in Amazon S3 are not detected automatically during stack updates. To update the function code, change the object key or version in the template.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">including your function source inline in the&nbsp;ZipFile&nbsp;parameter of the&nbsp;AWS::Lambda::Function&nbsp;resource in the CloudFormation template</strong></b><span>&nbsp;is the easiest way to deploy the Lambda function to AWS.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Uploading the code in S3 then specifying the&nbsp;S3Key&nbsp;and&nbsp;S3Bucket&nbsp;parameters under the&nbsp;AWS::Lambda::Function&nbsp;resource in the CloudFormation template&nbsp;</strong></b><span>is incorrect. Although this is a valid deployment step, you still have to upload the code in S3 instead of just including the function source inline in the&nbsp;ZipFile&nbsp;parameter. Take note that the scenario explicitly mentions that you have to pick the easiest way.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Including your function source inline in the&nbsp;Code&nbsp;parameter of the&nbsp;AWS::Lambda::Function&nbsp;resource in the CloudFormation template&nbsp;</strong></b><span>is incorrect because you should use the&nbsp;ZipFile&nbsp;parameter instead. Take note that the&nbsp;Code&nbsp;property is the parent property of the&nbsp;ZipFile&nbsp;parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Uploading the code in S3 as a ZIP file then specifying the S3 path in the&nbsp;ZipFile&nbsp;parameter of the&nbsp;AWS::Lambda::Function&nbsp;resource in the CloudFormation template&nbsp;</strong></b><span>is incorrect because contrary to its name, the&nbsp;ZipFile&nbsp;parameter directly accepts the source code of your Lambda function and not an actual zip file.&nbsp;If you include your function source inline with this parameter, AWS CloudFormation places it in a file named index and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">zips</strong></b><span>&nbsp;it to create a deployment package. This is the reason why it is called the “ZipFile\"&nbsp;parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-function-code.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-lambda-function-code.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557974,
        "value": "Include your function source inline in the ZipFile parameter of the AWS::Lambda::Function resource in the CloudFormation template.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557975,
        "value": "Upload the code in S3 as a ZIP file then specify the S3 path in the ZipFile parameter of the AWS::Lambda::Function resource in the CloudFormation template.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557976,
        "value": "Include your function source inline in the Code parameter of the AWS::Lambda::Function resource in the CloudFormation template.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557977,
        "value": "Upload the code in S3 then specify the S3Key and S3Bucket parameters under the AWS::Lambda::Function resource in the CloudFormation template.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 53,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557975,
        "questionId": 388686,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388686,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Due to the popularity of serverless computing, your manager instructed you to share your technical expertise to the whole software development department of your company. You are planning to deploy a simple Node.js ‘Hello World’ Lambda function to AWS using CloudFormation.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the EASIEST way of deploying the function to AWS?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618841,
    "question": "CodeDeploy",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">CodeDeploy</strong></b><span>&nbsp;is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>CodeDeploy can deploy application content that runs on a server and is stored in Amazon S3 buckets, GitHub repositories, or Bitbucket repositories. CodeDeploy can also deploy a serverless Lambda function. You do not need to make changes to your existing code before you can use CodeDeploy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_55.jpg\"><span>CodeDeploy provides two deployment type options:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">In-place deployment</strong></b><span>: The application on each instance in the deployment group is stopped, the latest application revision is installed, and the new version of the application is started and validated. You can use a load balancer so that each instance is deregistered during its deployment and then restored to service after the deployment is complete. Only deployments that use the EC2/On-Premises compute platform can use in-place deployments. AWS Lambda compute platform deployments cannot use an in-place deployment type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Blue/green deployment</strong></b><span>: The behavior of your deployment depends on which compute platform you use:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><u><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-underline___y38TS\">Blue/green on an EC2/On-Premises compute platform:</strong></b></u><span>&nbsp;The instances in a deployment group (the original environment) are replaced by a different set of instances (the replacement environment). If you use an EC2/On-Premises compute platform, be aware that blue/green deployments work with Amazon EC2 instances only.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><u><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-underline___y38TS\">Blue/green on an AWS Lambda compute platform</strong></b></u><b><strong class=\"Editor__editor-text-bold___25KrR\">:</strong></b><span>&nbsp;Traffic is shifted from your current serverless environment to one with your updated Lambda function versions. You can specify Lambda functions that perform validation tests and choose the way in which the traffic shift occurs. All AWS Lambda compute platform deployments are blue/green deployments. For this reason, you do not need to specify a deployment type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>–&nbsp;</span><u><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-underline___y38TS\">Blue/green on an Amazon ECS compute platform:</strong></b></u><span>&nbsp;Traffic is shifted from the task set with the original version of a containerized application in an Amazon ECS service to a replacement task set in the same service. The protocol and port of a specified load balancer listener are used to reroute production traffic. During deployment, a test listener can be used to serve traffic to the replacement task set while validation tests are run.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The CodeDeploy agent is a software package that, when installed and configured on an instance, makes it possible for that instance to be used in CodeDeploy deployments. The CodeDeploy agent communicates outbound using HTTPS over port 443.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>It is also important to note that the CodeDeploy agent is required only if you deploy to an EC2/On-Premises compute platform. The agent is not required for deployments that use the Amazon ECS or AWS Lambda compute platform.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Therefore, the valid considerations in CodeDeploy in this scenario are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– AWS Lambda compute platform deployments cannot use an in-place deployment type.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– CodeDeploy can deploy applications to both your EC2 instances as well as your on-premises servers.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CodeDeploy can deploy applications to EC2, AWS Lambda, and Amazon ECS only&nbsp;</strong></b><span>is incorrect because it can also deploy to your on-premises servers.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The CodeDeploy agent communicates using HTTP over port 80</strong></b><span>&nbsp;is incorrect because it is actually&nbsp;using HTTPS over port 443 and not HTTP.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">You have to install and use the CodeDeploy agent installed on your EC2 instances and ECS cluster&nbsp;</strong></b><span>is incorrect. Although this statement is true for EC2 instances, it is wrong for the latter as the CodeDeploy agent is not required for deployments that use the Amazon ECS or AWS Lambda compute platform.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/getting-started/projects/set-up-ci-cd-pipeline/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/getting-started/projects/set-up-ci-cd-pipeline/</span></a></p>",
    "choices": [
      {
        "id": 1557978,
        "value": "AWS Lambda compute platform deployments cannot use an in-place deployment type.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557979,
        "value": "CodeDeploy can deploy applications to EC2, AWS Lambda, and Amazon ECS only.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557980,
        "value": "You have to install and use the CodeDeploy agent installed on your EC2 instances and ECS cluster.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557981,
        "value": "The CodeDeploy agent communicates using HTTP over port 80.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557982,
        "value": "CodeDeploy can deploy applications to both your EC2 instances as well as your on-premises servers.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 54,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557979,
        "questionId": 388687,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1557982,
        "questionId": 388687,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388687,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company is heavily using a range of AWS services to host their enterprise applications. Currently, their deployment process still has a lot of manual steps which is why they plan to automate their software delivery process using continuous integration and delivery (CI/CD) pipelines in AWS. They will use CodePipeline to orchestrate each step of their release process and CodeDeploy for deploying applications to various compute platforms in AWS.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this architecture, which of the following are valid considerations when using CodeDeploy? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618842,
    "question": "Lambda function",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Function invocation</strong></b><span>&nbsp;can result in an error for several reasons. Your code might raise an exception, time out, or run out of memory. The runtime executing your code might encounter an error and stop. You might run out of concurrency and be throttled.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When an error occurs, your code might have run completely, partially, or not at all. In most cases, the client or service that invokes your function retries if it encounters an error, so your code must be able to process the same event repeatedly without unwanted effects. If your function manages resources or writes to a database, you need to handle cases where the same request is made several times.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_56.jpg\"><span>AWS Lambda directs events that cannot be processed to the specified Amazon SNS topic or Amazon SQS queue. Functions that don’t specify a DLQ will discard events after they have exhausted their retries. You configure a DLQ by specifying the Amazon Resource Name&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">TargetArn</em></i><span>&nbsp;value on the Lambda function’s&nbsp;DeadLetterConfig&nbsp;parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the setting up a&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Dead Letter Queue&nbsp;</strong></b><span>is the correct answer in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Delay Queue</strong></b><span>&nbsp;is incorrect because&nbsp;this just lets you postpone the delivery of new messages to a queue for a number of seconds. This is not relevant in this scenario since you can’t use a delay queue within Lambda.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">FIFO Queue</strong></b><span>&nbsp;is incorrect because this is primarily used to enhance messaging between applications when the order of operations and events is critical, or where duplicates can’t be tolerated. Although a DLQ is just a normal SQS queue, this option is still incorrect because you don’t necessarily need a FIFO SQS queue since you can also use a Standard SQS queue to be the Dead Letter Queue of your Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon MQ</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because&nbsp;this is simply a managed message broker service for Apache ActiveMQ that makes it easy to set up and operate message brokers in the cloud.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/dlq.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/dlq.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/retries-on-errors.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/retries-on-errors.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557983,
        "value": "Delay Queue",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557984,
        "value": "Dead Letter Queue",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557985,
        "value": "FIFO Queue",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557986,
        "value": "Amazon MQ",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 55,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557984,
        "questionId": 388688,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388688,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You are developing an application that will use a Lambda function, which will be invoked asynchronously. The application will be implemented with exponential back-off that will handle failures so that the requests will be retried twice before the event is discarded. If the retries fail with an unexpected error, you have to direct unprocessed events to another service which will analyze the failure.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST suitable component that you should implement in the application architecture to meet the above requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618843,
    "question": "DynamoDB",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Time To Live (TTL)</strong></b><span>&nbsp;for DynamoDB allows you to define when items in a table expire so that they can be automatically deleted from the database.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>TTL is provided at no extra cost as a way to reduce storage usage and reduce the cost of storing irrelevant data without using provisioned throughput. With TTL enabled on a table, you can set a timestamp for deletion on a per-item basis, allowing you to limit storage usage to only those records that are relevant.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_57.jpg\"><span>TTL is useful if you have continuously accumulated data that lose relevance after a specific time period. For example session data, event logs, usage patterns, and other temporary data. If you have sensitive data that must be retained only for a certain amount of time according to contractual or regulatory obligations, TTL helps you ensure that it is removed promptly and as scheduled.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Turn on Time To Live (TTL) in the table</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use a Lambda function with CloudWatch Events to schedule a purge of stale items in the table on a daily basis&nbsp;</strong></b><span>is incorrect. Although this solution can work, it entails a lot of configuration to implement and can incur an additional cost.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Implement a Write-Through caching strategy in your application&nbsp;</strong></b><span>is incorrect because this strategy simply adds data or updates data in the cache whenever data are written to the database, and not in the event of a cache miss. Since the scenario is about deleting the stale items in the table and not improving the cache performance, this option is incorrect.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Implement a Lazy Loading caching strategy to your application&nbsp;</strong></b><span>is incorrect because this strategy just loads data into the cache only when necessary. Just like the Write-Through caching strategy, this is not applicable in this scenario since the objective is to automatically expire and delete the stale session data in the DynamoDB table to improve the application performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557987,
        "value": "Turn on Time To Live (TTL) in the table.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557988,
        "value": "Implement a Lazy Loading caching strategy to your application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557989,
        "value": "Implement a Write-Through caching strategy in your application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557990,
        "value": "Use a Lambda function with CloudWatch Events to schedule a purge of stale items in the table on a daily basis.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 56,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557987,
        "questionId": 388689,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388689,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A social media application is using DynamoDB to manage and store the session data of its users. As the number of users grew, the number of items in the table exponentially increased as well. You have to reduce storage usage and also reduce the cost of storing irrelevant data without using provisioned throughput to rectify this issue.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST cost-effective solution that you should implement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618844,
    "question": "Encryption",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you encrypt your data, your data is protected, but you have to protect your encryption key. One strategy is to encrypt it.&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Envelope encryption</strong></b><span>&nbsp;is the practice of encrypting plaintext data with a data key and then encrypting the data key under another key.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_58.jpg\"><span>You can even encrypt the data encryption key under another encryption key, and encrypt that encryption key under another encryption key. But, eventually, one key must remain in plaintext so you can decrypt the keys and your data. This top-level plaintext key encryption key is known as the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">root key</em></i><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS KMS</strong></b><span>&nbsp;helps you protect your encryption keys by storing and managing them securely. Root keys stored in AWS KMS, known as AWS KMS keys, never leave the AWS KMS FIPS validated hardware security modules unencrypted. To use an AWS KMS key, you must call AWS KMS.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Envelope encryption offers several benefits:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Protecting data keys</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you encrypt a data key, you don’t have to worry about storing the encrypted data key, because the data key is inherently protected by encryption. You can safely store the encrypted data key alongside the encrypted data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Encrypting the same data under multiple keys</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Encryption operations can be time-consuming, particularly when the data being encrypted are large objects. Instead of re-encrypting raw data multiple times with different keys, you can re-encrypt only the data keys that protect the raw data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Combining the strengths of multiple algorithms</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In general, symmetric key algorithms are faster and produce smaller ciphertexts than public-key algorithms, but public-key algorithms provide inherent separation of roles and easier key management. Envelope encryption lets you combine the strengths of each strategy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Therefore, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Encrypt plaintext data with a data key and then encrypt the data key with a top-level plaintext key.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Encrypt plaintext data with a KMS key and then encrypt the KMS key with a top-level plaintext data key</strong></b><span>&nbsp;is incorrect because you have to encrypt your plaintext data with a data key and not a KMS key. Moreover, the top-level plaintext key should be the root key and not the data key.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Encrypt plaintext data with a KMS key and then encrypt the KMS key with a top-level encrypted data key</strong></b><span>&nbsp;is incorrect because plaintext data should be encrypted with a data key, not a KMS key. Also, the top-level key should be plaintext, not encrypted.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Encrypt plaintext data with a data key and then encrypt the data key with a top-level encrypted key</strong></b><span>&nbsp;is incorrect. While it is correct to encrypt plaintext data with a data key, the top-level key (root key) must be kept in plaintext and not be encrypted.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#enveloping\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#enveloping</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/overview.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/kms/latest/developerguide/overview.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557991,
        "value": "Encrypt plaintext data with a KMS key and then encrypt the KMS key with a top-level encrypted data key.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557992,
        "value": "Encrypt plaintext data with a data key and then encrypt the data key with a top-level encrypted key.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557993,
        "value": "Encrypt plaintext data with a KMS key and then encrypt the KMS key with a top-level plaintext data key.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557994,
        "value": "Encrypt plaintext data with a data key and then encrypt the data key with a top-level plaintext key.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 57,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557992,
        "questionId": 388690,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388690,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Your development team is currently developing a financial application in AWS. One of the requirements is to create and control the encryption keys used to encrypt your data using the envelope encryption strategy to comply with the strict IT security policy of the company.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following correctly describes the process of envelope encryption?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618845,
    "question": "X-Ray ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A segment can break down the data about the work done into&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">subsegments</strong></b><span>. Subsegments provide more granular timing information and details about downstream calls that your application made to fulfill the original request. A subsegment can contain additional details about a call to an AWS service, an external HTTP API, or an SQL database. You can even define arbitrary subsegments to instrument specific functions or lines of code in your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_59.jpg\"><span>For services that don’t send their own segments like Amazon DynamoDB, X-Ray uses subsegments to generate&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">inferred segments</em></i><span>&nbsp;and downstream nodes on the service map. This lets you see all of your downstream dependencies, even if they don’t support tracing or are external.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Subsegments represent your application’s view of a downstream call as a client. If the downstream service is also instrumented, the segment that it sends replaces the inferred segment generated from the upstream client’s subsegment. The node on the service graph always uses information from the service’s segment, if it’s available, while the edge between the two nodes uses the upstream service’s subsegment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use subsegments</strong></b><span>&nbsp;in your segment document.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using</span><i><em class=\"Editor__editor-text-italic___C9n8O\">&nbsp;</em></i><b><strong class=\"Editor__editor-text-bold___25KrR\">inferred segment</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this is the one generated by subsegments, which lets you see all of your downstream dependencies including the external ones even if they don’t support tracing. The more appropriate solution in this scenario is to use&nbsp;subsegments instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">metadata</strong></b><span>&nbsp;is incorrect because this does not record the calls to AWS services and resources that are made by the application.&nbsp;Segments and subsegments can include a&nbsp;metadata&nbsp;object containing one or more fields with values of any type, including objects and arrays.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">annotations</strong></b><span>&nbsp;is incorrect because just like&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">metadata</em></i><span>, this also does not record the application’s calls to your AWS services and resources.&nbsp;Segments and subsegments can include an annotations object containing one or more fields that X-Ray indexes for use with filter expressions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-subsegments\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-subsegments</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557995,
        "value": "Use subsegments",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557996,
        "value": "Use metadata",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557997,
        "value": "Use annotations",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1557998,
        "value": "Use inferred segment",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 58,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1557995,
        "questionId": 388691,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388691,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An ECS Cluster has a running X-Ray Daemon that enables developers to easily debug and troubleshoot their application. However, the trace data being sent to AWS X-Ray is still not as detailed as your manager wants it to be. There is a new requirement that requires the application to provide more granular timing information and more details about its downstream calls to various AWS resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should you do to satisfy this requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618846,
    "question": "X-Ray SDK",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>X-Ray compiles and processes segment documents to generate queryable&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">trace summaries</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">full traces</strong></b><span>&nbsp;that you can access by using the&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\" class=\"Editor__editor-link___3vl2C\"><span>GetTraceSummaries</span></a><span>&nbsp;and&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html\" class=\"Editor__editor-link___3vl2C\"><span>BatchGetTraces</span></a><span>&nbsp;APIs, respectively. In addition to the segments and subsegments that you send to X-Ray, the service uses information in subsegments to generate&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">inferred segments</strong></b><span>&nbsp;and adds them to the full trace. Inferred segments represent downstream services and resources in the service map.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_60.jpg\"><span>In this scenario, the developer should&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use the&nbsp;GetTraceSummaries&nbsp;API to get the list of trace IDs of the application and then retrieve the list of traces using&nbsp;BatchGetTraces&nbsp;API</strong></b><span>&nbsp;in order to develop the custom debug tool</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;GetGroup&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;BatchGetTraces&nbsp;API</strong></b><span>&nbsp;is incorrect because the&nbsp;GetGroup&nbsp;API just retrieves the group resource details.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;GetServiceGraph&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;GetTraceSummaries&nbsp;API&nbsp;</strong></b><span>is incorrect because the&nbsp;GetServiceGraph&nbsp;API just shows which services process the incoming requests, including the downstream services that they call as a result. In addition, you have to use the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">BatchGetTraces</em></i><span>&nbsp;API instead of the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">GetTraceSummaries</em></i><span>&nbsp;API to retrieve the list of traces.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;BatchGetTraces&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;GetTraceSummaries&nbsp;API&nbsp;</strong></b><span>is incorrect because it should be the other way around. You have to use the&nbsp;GetTraceSummaries&nbsp;API to get the list of trace IDs of the application and then use its result as an input parameter to retrieve the list of traces using the&nbsp;BatchGetTraces&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1557999,
        "value": "Use the BatchGetTraces API to get the list of trace IDs of the application and then retrieve the list of traces using GetTraceSummaries API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558000,
        "value": "Use the GetTraceSummaries API to get the list of trace IDs of the application and then retrieve the list of traces using BatchGetTraces API.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558001,
        "value": "Use the GetGroup API to get the list of trace IDs of the application and then retrieve the list of traces using BatchGetTraces API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558002,
        "value": "Use the GetServiceGraph API to get the list of trace IDs of the application and then retrieve the list of traces using GetTraceSummaries API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 59,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1557999,
        "questionId": 388692,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388692,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer has instrumented an application using the X-Ray SDK to collect all data about the requests that an application serves. There is a new requirement to develop a custom debug tool which will enable them to view the full traces of their application without using the X-Ray console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should the developer do to accomplish this task?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618847,
    "question": "Amazon S3",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Concurrent executions refers to the number of executions of your function code that are happening at any given time. You can estimate the concurrent execution count, but the concurrent execution count will differ depending on whether or not your Lambda function is processing events from a poll-based event source.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you create a Lambda function to process events from event sources that aren’t poll-based (for example, Lambda can process every event from other sources, like Amazon S3 or API Gateway), each published event is a unit of work, in parallel, up to your account limits. Therefore, the number of invocations these event sources make influences the concurrency. You can use this formula to estimate the capacity used by your function:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;&nbsp; concurrent executions = invocations per second * average execution duration in seconds</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Supposed you have 10 events coming in per second and it takes 3 seconds for each event to be processed, then 10 instances of the function will be spawned to handle those requests. AWS Lambda won’t be able to reuse those functions for 3 seconds. To accommodate the 2nd batch (another 10 events), AWS Lambda has to spawn another 10 instances of the function, which become busy for another 3 seconds. At the 3rd second, another batch comes in, invoking additional 10 functions. Suppose there’s a continuous stream of events, the concurrent executions that you’ll get at any given time would be 30.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, a Lambda function processes Amazon S3 events where the function takes on an average of three seconds to complete the processing (</span><b><strong class=\"Editor__editor-text-bold___25KrR\">average execution duration&nbsp;in seconds</strong></b><span>) and Amazon S3 publishes 10 events per second (</span><b><strong class=\"Editor__editor-text-bold___25KrR\">invocations per second</strong></b><span>). By using the formula given above:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;&nbsp; concurrent executions = 10 * 3= 30</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, you will have&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">30</strong></b></i><span>&nbsp;concurrent executions of your Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">3</strong></b></i><span>&nbsp;is incorrect because the value of the&nbsp;concurrent executions is not equivalent to the average execution duration of your Lambda function in seconds.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">10</strong></b></i><span>&nbsp;is incorrect because&nbsp;the value of the&nbsp;concurrent executions is not equivalent to the number of invocations your Lambda function receives per second.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">13</strong></b></i><span>&nbsp;is incorrect because the value of the&nbsp;concurrent executions is not equivalent to the sum of the average execution duration and the number of invocations your Lambda function receives per second.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/scaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/scaling.html</span></a></p>",
    "choices": [
      {
        "id": 1558003,
        "value": "10",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558004,
        "value": "3",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558005,
        "value": "30",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558006,
        "value": "13",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 60,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1558004,
        "questionId": 388693,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388693,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A serverless application consisting of a Lambda function and a DynamoDB database is used to process Amazon S3 events. The Lambda function takes an average of three seconds to process the data and Amazon S3 publishes 10 events per second.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the concurrent execution that the function will have?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618848,
    "question": "DynamoDB table",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For applications that need to read or write multiple items, DynamoDB provides the&nbsp;BatchGetItem&nbsp;and&nbsp;BatchWriteItem&nbsp;operations. Using these operations can reduce the number of network round trips from your application to DynamoDB. In addition, DynamoDB performs the individual read or write operations in parallel. Your applications benefit from this parallelism without having to manage concurrency or threading.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_62.jpg\"><span>The batch operations are essentially wrappers around multiple read or write requests. For example, if a&nbsp;BatchGetItem&nbsp;request contains five items, DynamoDB performs five&nbsp;GetItem&nbsp;operations on your behalf. Similarly, if a&nbsp;BatchWriteItem&nbsp;request contains two put requests and four delete requests, DynamoDB performs two&nbsp;PutItem&nbsp;and four&nbsp;DeleteItem&nbsp;requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use DynamoDB’s&nbsp;BatchGetItem&nbsp;and&nbsp;BatchWriteItem&nbsp;API operations</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">.</strong></b></i></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using DynamoDB conditional writes</strong></b><span>&nbsp;is incorrect because&nbsp;conditional writes are only helpful in cases where multiple users attempt to modify the same item. This is because&nbsp;write operations will succeed only if the item attributes meet one or more expected conditions. Otherwise, it returns an error. This method does not decrease the time it takes to process the entries.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Modifying your application to use multithreading&nbsp;</strong></b><span>is incorrect because although refactoring your application to concurrently send multiple requests to the table is a valid solution, this entails a lot of effort to refactor your code in order to support multithreading. Without proper locking mechanisms, threads can mistakenly introduce redundancies hence, using the DynamoDB’s batch API operations is still a better solution.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Deploying your application into a cluster of EC2 instances&nbsp;</strong></b><span>is incorrect because you will need a solution that can track which application is currently handling which item. Although it could work if executed properly, it is not the simplest to do among the choices given. Take note that the scenario explicitly asks for a solution that you can implement with minimal configuration.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalUpdate\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html#WorkingWithItems.ConditionalUpdate</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchGetItem.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1558007,
        "value": "Use DynamoDB conditional writes.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558008,
        "value": "Use DynamoDB’s BatchGetItem and BatchWriteItem API operations.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558009,
        "value": "Modify your application to use multithreading.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558010,
        "value": "Deploy your application into a cluster of EC2 instances.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 61,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1558008,
        "questionId": 388694,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388694,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You have an application that reads an individual item from a DynamoDB table, modifies it locally, and submits the changes as a new entry to a separate table before proceeding onto the next item. The process is repeated for the next 100 entries, and it consumes a lot of time performing this entire process.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which strategy can be applied to your application in order to shorten the time needed to process all the necessary entries with MINIMAL configuration?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618849,
    "question": "DynamoDB table ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When you create a table, in addition to the table name, you must specify the primary key of the table. The primary key uniquely identifies each item in the table so that no two items can have the same key.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>DynamoDB supports two different kinds of primary keys:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>1. Partition key</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>2. Partition key and sort key</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Partition key</strong></b><span>&nbsp;– A simple primary key, composed of one attribute known as the partition key. DynamoDB uses the partition key’s value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored. In a table that has only a partition key, no two items can have the same partition key value.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Partition key and sort key</strong></b><span>&nbsp;– Referred to as a composite primary key, this type of key is composed of two attributes. The first attribute is the partition key, and the second attribute is the sort key. DynamoDB uses the partition key value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored. All items with the same partition key are stored together, in sorted order by sort key value.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In a table that has a partition key and a sort key, it’s possible for two items to have the same partition key value. However, those two items must have different sort key values. A composite primary key gives you additional flexibility when querying data. For example, if you provide only the value for Artist, DynamoDB retrieves all of the songs by that artist. To retrieve only a subset of songs by a particular artist, you can provide a value for Artist along with a range of values for SongTitle.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Thus, in this scenario, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use&nbsp;employee_id&nbsp;because each employee ID is uniqu</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">e</strong></b></i><span>. Using high-cardinality attributes are recommended when creating primary partition keys. Examples of these unique attributes are email, employee_no, customerid, and so on.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Both&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">department_id&nbsp;</strong></b><span>and</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;position_id</strong></b><span>&nbsp;are&nbsp;incorrect because these values are not unique per employee.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Using&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">employee_name</strong></b><span>&nbsp;is not recommended because in big organizations, somebody may share the same name as someone else.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.PrimaryKey\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.PrimaryKey</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1558011,
        "value": "position_id because this will help sort the records per department.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558012,
        "value": "department_id since employees will fall in these departments.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558013,
        "value": "employee_name because this will speed up searching of records.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558014,
        "value": "employee_id because each employee ID is unique.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 62,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1558013,
        "questionId": 388695,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388695,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You are planning to create a DynamoDB table for your employee profile website. This will be used by the Human Resources department to easily view details about each employee.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>When choosing the partition key of the table, which of the following is the BEST attribute to use?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618850,
    "question": "Amazon Cognito",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>With adaptive authentication, you can configure your user pool to block suspicious sign-ins or add second factor authentication in response to an increased risk level. For each sign-in attempt, Amazon Cognito generates a risk score for how likely the sign-in request is to be from a compromised source. This risk score is based on factors that include device and user information.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_64.jpg\"><span>Adaptive authentication can turn on or require multi-factor authentication (MFA) for a user in your user pool when Amazon Cognito detects risk in a user’s session, and the user hasn’t yet chosen an MFA method. When you activate MFA for a user, they always receive a challenge to provide or set up a second factor during authentication, regardless of how you configured adaptive authentication. From your user’s perspective, your app offers to help them set up MFA, and optionally, Amazon Cognito prevents them from signing in again until they have configured an additional factor.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the given scenario, by enabling Adaptive Authentication, the company can require MFA for users only when a sign-in attempt appears suspicious. This aligns with their objective to mitigate risks from the recent data breach without affecting all users.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable Adaptive Authentication for the User Pool.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Recreate the User Pool and enable SMS text message MFA&nbsp;</strong></b><span>is incorrect. This option is cumbersome since the users registered in the current User Pool will be lost. This means users would have to re-register or be re-imported into the new User Pool. Additionally, enabling MFA universally would challenge all users, not just those with suspicious login attempts.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable the Time-based one-time password (TOTP) software token MFA for the User Pool</strong></b><span>&nbsp;is incorrect. Enabling TOTP MFA would apply to all users, not just those with suspicious logins. This doesn’t match the company’s need to enforce MFA only for suspicious attempts.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Create a subscription filter Lambda function that monitors for the&nbsp;CompromisedCredentialRisk&nbsp;metric from Advanced Security Metrics in CloudWatch Logs and triggers MFA when detected&nbsp;</strong></b><span>is incorrect. This approach is not feasible because it operates outside of Cognito’s authentication flow. Furthermore, in Cognito, MFA settings are applied at the User Pool level, not per user.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/security/how-to-use-new-advanced-security-features-for-amazon-cognito-user-pools/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/security/how-to-use-new-advanced-security-features-for-amazon-cognito-user-pools/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1558015,
        "value": "Enable Adaptive Authentication for the User Pool",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558016,
        "value": "Create a subscription filter Lambda function that monitors for the CompromisedCredentialRisk metric from Advanced Security Metrics in CloudWatch Logs and triggers MFA when detected",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558017,
        "value": "Recreate the User Pool and enable SMS text message MFA.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558018,
        "value": "Enable the Time-based one-time password (TOTP) software token MFA for the User Pool",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 63,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1558018,
        "questionId": 388696,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388696,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has an AWS Amplify application, relying on Amazon Cognito for user authentication. Multi-factor authentication (MFA) is disabled for their User Pool. There has been a recent data breach in a popular website. The company is worried that attackers might exploit compromised email addresses and passwords to sign into their applications. For this reason, they want to enforce MFA only on users with suspicious login attempts.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How can the company satisfy these requirements</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  },
  {
    "answerId": 39618851,
    "question": "Amazon S3",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">role</em></i><span>&nbsp;specifies a set of permissions that you can use to access AWS resources. In that sense, it is similar to an IAM User. A principal (person or application) assumes a role to receive temporary permissions to carry out required tasks and interact with AWS resources. The role can be in your own account or any other AWS account.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To assume a role, an application calls the AWS STS&nbsp;AssumeRole&nbsp;API operation and passes the ARN of the role to use. The operation creates a new session with temporary credentials. This session has the same permissions as the identity-based policies for that role.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/ex2/hint_65.jpg\"><span>When you call AssumeRole API, you can optionally pass inline or managed&nbsp;</span><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_session\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>session policies</span></a><span>. Session policies are advanced policies that you pass as a parameter when you programmatically create a temporary credential session for a role or federated user. You can pass a single JSON inline session policy document using the&nbsp;Policy&nbsp;parameter. You can use the&nbsp;PolicyArns&nbsp;parameter to specify up to 10 managed session policies. The resulting session’s permissions are the intersection of the entity’s identity-based policies and the session policies.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Thus, the correct answer is to use the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AssumeRole</strong></b><span>&nbsp;API&nbsp;in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AssumeRoleWithWebIdentity</strong></b><span>&nbsp;is incorrect because this only returns a set of temporary security credentials for federated users who are authenticated through public identity providers such as Amazon, Facebook, Google, or OpenID, which were not mentioned in the scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AssumeRoleWithSAML</strong></b><span>&nbsp;is incorrect because&nbsp;this just returns a set of temporary security credentials for users who have been authenticated via a SAML authentication response. This operation provides a mechanism for tying an enterprise identity store or directory to role-based AWS access without user-specific credentials or configuration.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">GetSessionToken</strong></b><span>&nbsp;is incorrect because&nbsp;this is primarily used to return a set of temporary credentials for an AWS account or IAM user only.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/s3-instance-access-bucket/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/premiumsupport/knowledge-center/s3-instance-access-bucket/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1558019,
        "value": "AssumeRole",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558020,
        "value": "AssumeRoleWithWebIdentity",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558021,
        "value": "AssumeRoleWithSAML",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1558022,
        "value": "GetSessionToken",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 64,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1558019,
        "questionId": 388697,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 388697,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has a central data repository in Amazon S3 that needs to be accessed by developers belonging to different AWS accounts. The required IAM role has been created with the appropriate S3 permissions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Given that the developers mostly interact with S3 via APIs, which API should the developers call to use the IAM role?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8302,
      "name": "CDA-Practice exam-2",
      "skillId": "",
      "categoryId": 1648
    }
  }
]