[
  {
    "answerId": 38808797,
    "question": "X-Ray service",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS X-Ray is an AWS service that allows you to detect, analyze, and optimize performance issues with your AWS Lambda applications. X-Ray collects metadata from the Lambda service and any upstream or downstream services that make up your application. X-Ray uses this metadata to generate a detailed service graph that illustrates performance bottlenecks, latency spikes, and other issues that impact the performance of your Lambda application.AWS Lambda uses environment variables to facilitate communication with the X-Ray daemon and configure the X-Ray SDK.</span><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(1).jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">_X_AMZN_TRACE_ID:</strong></b><span>&nbsp;Contains the tracing header, which includes the sampling decision, trace ID, and parent segment ID.&nbsp;If Lambda receives a tracing header when your function is invoked, that header will be used to populate the _X_AMZN_TRACE_ID environment variable. If a tracing header was not received, Lambda will generate one for you.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_XRAY_CONTEXT_MISSING:</strong></b><span>&nbsp;The X-Ray SDK uses this variable to determine its behavior in the event that your function tries to record X-Ray data, but a tracing header is not available. Lambda sets this value to&nbsp;LOG_ERROR&nbsp;by default.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_XRAY_DAEMON_ADDRESS:</strong></b><span>&nbsp;This environment variable exposes the X-Ray daemon’s address in the following format:&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">IP_ADDRESS</em></i><b><strong class=\"Editor__editor-text-bold___25KrR\">:</strong></b><i><em class=\"Editor__editor-text-italic___C9n8O\">PORT</em></i><span>. You can use the X-Ray daemon’s address to send trace data to the X-Ray daemon directly without using the X-Ray SDK.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Therefore, the correct answers for this scenario are the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">_X_AMZN_TRACE_ID&nbsp;and&nbsp;AWS_XRAY_CONTEXT_MISSING</strong></b><span>&nbsp;environment variables.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_XRAY_TRACING_NAME</strong></b><span>&nbsp;is incorrect because this is primarily used in X-Ray SDK where you can set a service name that the SDK uses for segments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS_XRAY_DEBUG_MODE</strong></b><span>&nbsp;is incorrect because this is used to configure the SDK to output logs to the console without using a logging library.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AUTO_INSTRUMENT</strong></b><span>&nbsp;is incorrect because this is primarily used in X-Ray SDK for Django Framework only.&nbsp;This allows the recording of subsegments for built-in database and template rendering operations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References</strong></b><span>:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html#viewing-lambda-xray-results\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html#viewing-lambda-xray-results</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-nodejs-configuration.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-nodejs-configuration.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-python-configuration.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-python-configuration.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536597,
        "value": "\t_X_AMZN_TRACE_ID",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536598,
        "value": "AWS_XRAY_CONTEXT_MISSING",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536599,
        "value": "AUTO_INSTRUMENT",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536600,
        "value": "AWS_XRAY_DEBUG_MODE",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536601,
        "value": "AWS_XRAY_TRACING_NAME",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 0,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536598,
        "questionId": 383216,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536597,
        "questionId": 383216,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383216,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A recently deployed Lambda function has an intermittent issue in processing customer data. You enabled the active tracing option in order to detect, analyze, and optimize performance issues of your function using the X-Ray service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following environment variables are used by AWS Lambda to facilitate communication with X-Ray? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808798,
    "question": "X-Ray",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Even with sampling, a complex application generates a lot of data. The AWS X-Ray console provides an easy-to-navigate view of the service graph. It shows health and performance information that helps you identify issues and opportunities for optimization in your application. For advanced tracing, you can drill down to traces for individual requests or use&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">filter expressions</strong></b><span>&nbsp;to find traces related to specific paths or users.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(2).jpg\"><span>When you instrument your application, the X-Ray SDK records information about incoming and outgoing requests, the AWS resources used, and the application itself. You can add other information to the segment document as annotations and metadata.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Annotations</strong></b><span>&nbsp;are simple key-value pairs that are indexed for use with&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>filter expressions</span></a><span>. Use annotations to record data that you want to use to group traces in the console, or when calling the&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>GetTraceSummaries</span></a><span>&nbsp;API. X-Ray indexes up to 50 annotations per trace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Metadata</strong></b><span>&nbsp;are key-value pairs with values of any type, including objects and lists, but that are not indexed. Use metadata to record data you want to store in the trace but don’t need to use for searching traces. You can view annotations and metadata in the segment or subsegment details in the X-Ray console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">adding the custom attributes as annotations in your segment document</strong></b><span>&nbsp;is the correct answer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Including the custom attributes as new segment fields in the segment document</strong></b><span>&nbsp;is incorrect because a segment field can’t be used as a filter expression. You have to add the custom attributes as annotations to the segment document that you’ll send to X-Ray, just as mentioned above.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating a new sampling rule based on the custom attributes&nbsp;</strong></b><span>is incorrect because sampling&nbsp;is primarily used to ensure efficient tracing and to provide a representative sample of the requests that your application serves.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding the custom attributes as metadata in your segment document&nbsp;</strong></b><span>is incorrect because metadata is primarily used to record custom data that you want to store in the trace but not for searching traces.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536602,
        "value": "Add the custom attributes as metadata in your segment document.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536603,
        "value": "Include the custom attributes as new segment fields in the segment document.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536604,
        "value": "Add the custom attributes as annotations in your segment document.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536605,
        "value": "Create a new sampling rule based on the custom attributes.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 1,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536604,
        "questionId": 383217,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383217,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An application, which already uses X-Ray, generates thousands of trace data every hour.&nbsp;The developer wants to use a filter expression that will limit the results based on custom attributes or keys that he specifies.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>How should the developer refactor the application in order to filter the results in the X-Ray console?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808799,
    "question": "Amazon CloudWatch",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon CloudWatch</strong></b><span>&nbsp;is basically a metrics repository. An AWS service—such as Amazon EC2—puts metrics into the repository, and you retrieve statistics based on those metrics. If you put your own custom metrics into the repository, you can retrieve statistics on these metrics as well.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">namespace</em></i><span>&nbsp;is a container for CloudWatch metrics. Metrics in different namespaces are isolated from each other so that metrics from different applications are not mistakenly aggregated into the same statistics.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(3).jpg\"><span>There is no default namespace. You must specify a namespace for each data point you publish to CloudWatch. You can specify a namespace name when you create a metric. These names must contain valid XML characters and be fewer than 256 characters in length. Possible characters are: alphanumeric characters (0-9A-Za-z), period (.), hyphen (-), underscore (_), forward slash (/), hash (#), and colon (:).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The AWS namespaces typically use the following naming convention:&nbsp;AWS/service. For example, Amazon EC2 uses the&nbsp;AWS/EC2&nbsp;namespace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch namespace with a unique metric name for each application.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch Alarm with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because&nbsp;a CloudWatch Alarm simply watches a single metric over a specified time period and performs one or more specified actions based on the value of the metric relative to a threshold over time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch Event with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because&nbsp;a CloudWatch Event is primarily used to deliver a near real-time stream of system events that describe changes in Amazon Web Services (AWS) resources, and not for segregating metrics of various applications.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Set up a custom CloudWatch dimension with a unique metric name for each application</strong></b><span>&nbsp;is incorrect because a CloudWatch&nbsp;dimension is only a name/value pair that is part of the identity of a metric. You have to use a CloudWatch namespace instead.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/viewing_metrics_with_cloudwatch.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/viewing_metrics_with_cloudwatch.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-services-cloudwatch-metrics.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b></p>",
    "choices": [
      {
        "id": 1536606,
        "value": "Set up a custom CloudWatch Event with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536607,
        "value": "Set up a custom CloudWatch Alarm with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536608,
        "value": "Set up a custom CloudWatch dimension with a unique metric name for each application.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536609,
        "value": "Set up a custom CloudWatch namespace with a unique metric name for each application.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 2,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536609,
        "questionId": 383218,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383218,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has 5 different applications running on several On-Demand EC2 instances. The DevOps team is required to set up a graphical representation of the key performance metrics for each application. These system metrics must be available on a single shared screen for more effective and visible monitoring.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should the DevOps team do to satisfy this requirement using Amazon CloudWatch?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808800,
    "question": "AWS Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS Identity and Access Management (IAM)</strong></b><span>&nbsp;to grant X-Ray permissions to users and compute resources in your account. IAM controls access to the X-Ray service at the API level to enforce permissions uniformly, regardless of which client (console, AWS SDK, AWS CLI) your users employ.&nbsp;To use the X-Ray console to view service maps and segments, you only need read permissions. To enable console access, add the AWSXrayReadOnlyAccess managed policy to your IAM user. For local development and testing, create an IAM user with read and write permissions. Generate access keys for the user and store them in the standard AWS SDK location. You can use these credentials with the X-Ray daemon, the AWS CLI, and the AWS SDK.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(4).jpg\"><span>To deploy your instrumented app to AWS, create an IAM role with write permissions and assign it to the resources running your application. AWSXRayDaemonWriteAccess includes permission to upload traces, and some read permissions as well to support the use of sampling rules.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The read and write policies do not include permission to configure encryption key settings and sampling rules. Use AWSXrayFullAccess to access these settings, or add configuration APIs in a custom policy. For encryption and decryption with a customer-managed key that you create, you also need permission to use the key.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>On supported platforms, you can use a configuration option to run the X-Ray daemon on the instances in your environment. You can enable the daemon in the Elastic Beanstalk console or by using a configuration file. To upload data to X-Ray, the X-Ray daemon requires IAM permissions in the&nbsp;</span><u><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-underline___y38TS\">AWSXRayDaemonWriteAccess</strong></b></u><span>&nbsp;managed policy. These permissions are included in the Elastic Beanstalk instance profile.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXRayDaemonWriteAccess</strong></b><span>&nbsp;managed policy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayReadOnlyAccess</strong></b><span>&nbsp;is incorrect because this policy is primarily used if you just want a read-only access to X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayFullAccess</strong></b><span>&nbsp;is incorrect. Although this can provide the required access to the daemon, this is not being used in Elastic Beanstalk as it does not abide by the standard security advice of granting the least privilege.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXRayElasticBeanstalkWriteAccess</strong></b><span>&nbsp;is incorrect because this is not an available managed policy.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-debugging.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-debugging.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-permissions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-permissions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/security.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/security.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536610,
        "value": "AWSXrayFullAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536611,
        "value": "AWSXRayDaemonWriteAccess",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536612,
        "value": "AWSXRayElasticBeanstalkWriteAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536613,
        "value": "AWSXrayReadOnlyAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 3,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536611,
        "questionId": 383219,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383219,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is planning to use the AWS Elastic Beanstalk console to run the AWS X-Ray daemon on the EC2 instances in her application environment. She will use X-Ray to construct a service map to help identify issues with her application and to provide insight on which application component to optimize. The environment is using a default Elastic Beanstalk instance profile.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which IAM managed policy does Elastic Beanstalk use for the X-Ray daemon to upload data to X-Ray?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808801,
    "question": "ECS Cluster",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon RDS</strong></b><span>&nbsp;provides metrics in real time for the operating system (OS) that your DB instance runs on. You can view the metrics for your DB instance using the console or consume the Enhanced Monitoring JSON output from CloudWatch Logs in a monitoring system of your choice. By default, Enhanced Monitoring metrics are stored in the CloudWatch Logs for 30 days. To modify the amount of time the metrics are stored in the CloudWatch Logs, change the retention for the&nbsp;RDSOSMetrics&nbsp;log group in the CloudWatch console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(5).jpg\"><span>Take note that&nbsp;there are certain differences between CloudWatch and Enhanced Monitoring Metrics. CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, and Enhanced Monitoring gathers its metrics from an agent on the instance. As a result, you might find differences between the measurements, because the hypervisor layer performs a small amount of work.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The differences can be greater if your DB instances use smaller instance classes because then there are likely more virtual machines (VMs) that are managed by the hypervisor layer on a single physical instance. Enhanced Monitoring metrics are useful when you want to see how different processes or threads on a DB instance use the CPU.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use Enhanced Monitoring in RDS.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Developing a shell script that collects and publishes custom metrics to CloudWatch which tracks the real-time CPU Utilization of the RDS instance</strong></b><span>&nbsp;is incorrect. Although you can use Amazon CloudWatch Logs and CloudWatch dashboard to monitor the CPU Utilization of the database instance, using CloudWatch alone is still not enough to get the specific percentage of the CPU bandwidth and total memory consumed by each database process. The data provided by CloudWatch is not as detailed as compared with the Enhanced Monitoring feature in RDS. Take note as well that you do not have direct access to the instances/servers of your RDS database instance, unlike with your EC2 instances where you can install a CloudWatch agent or a custom script to get CPU and memory utilization of your instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using CloudWatch to track the CPU Utilization of your database</strong></b><span>&nbsp;is incorrect. Although you can use Amazon CloudWatch to monitor the CPU Utilization of your database instance, it does not provide the percentage of the CPU bandwidth and total memory consumed by each database process in your RDS instance. Take note that CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, while RDS Enhanced Monitoring gathers its metrics from an agent on the instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Tracking the&nbsp;CPU%&nbsp;and&nbsp;MEM%&nbsp;metrics which are readily available in the Amazon RDS console&nbsp;</strong></b><span>is incorrect because these metrics are not readily available in the Amazon RDS console, which is contrary to what is being stated in this option.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:&nbsp;</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MonitoringOverview.html#monitoring-cloudwatch\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MonitoringOverview.html#monitoring-cloudwatch</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536614,
        "value": "Track the CPU% and MEM% metrics which are readily available in the Amazon RDS console.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536615,
        "value": "Use Enhanced Monitoring in RDS.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536616,
        "value": "Develop a shell script that collects and publishes custom metrics to CloudWatch which tracks the real-time CPU Utilization of the RDS instance.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536617,
        "value": "Use CloudWatch to track the CPU Utilization of your database.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 4,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536615,
        "questionId": 383220,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383220,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company has an application hosted in an ECS Cluster that heavily uses an RDS database. A developer needs to closely monitor how the different processes on a DB instance use the CPU, such as the percentage of the CPU bandwidth or the total memory consumed by each process to ensure application performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST suitable solution that the developer should implement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808802,
    "question": "X-Ray",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS Elastic Beanstalk</strong></b><span>&nbsp;console or a configuration file to run the AWS X-Ray daemon on the instances in your environment. X-Ray is an AWS service that gathers data about the requests that your application serves, and uses it to construct a service map that you can use to identify issues with your application and opportunities for optimization.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(6).jpg\"><span>To relay trace data from your application to AWS X-Ray, you can run the X-Ray daemon on your Elastic Beanstalk environment’s Amazon EC2 instances.&nbsp;Elastic Beanstalk platforms provide a configuration option that you can set to run the daemon automatically. You can enable the daemon in a configuration file in your source code or by choosing an option in the Elastic Beanstalk console. When you enable the configuration option, the daemon is installed on the instance and runs as a service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">enable the X-Ray daemon by including the&nbsp;xray-daemon.config&nbsp;configuration file in the&nbsp;.ebextensions&nbsp;directory of your source code</strong></b><span>, just as shown above.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using a user data script to run the daemon automatically&nbsp;</strong></b><span>is incorrect because this is only applicable if you want to enable X-Ray to your EC2 instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Creating a Docker image that runs the X-Ray daemon&nbsp;</strong></b><span>is incorrect because this is what you need to do if you want to enable X-Ray on ECS Cluster and not on Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Enabling active tracing in the Elastic Beanstalk by including the&nbsp;healthcheckurl.config&nbsp;configuration file in the&nbsp;.ebextensions&nbsp;directory of your source code</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this configuration file only sets the application&nbsp;health check&nbsp;URL and not X-Ray Tracing.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-debugging.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-debugging.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536618,
        "value": "Create a Docker image that runs the X-Ray daemon.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536619,
        "value": "Use a user data script to run the daemon automatically.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536620,
        "value": "Enable the X-Ray daemon by including the xray-daemon.config configuration file in the .ebextensions directory of your source code.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536621,
        "value": "Enable active tracing in the Elastic Beanstalk by including the healthcheckurl.config configuration file in the .ebextensions directory of your source code.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 5,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536620,
        "questionId": 383221,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383221,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A new IT policy requires you to trace all calls that your&nbsp;Node.js&nbsp;application sends to external HTTP web APIs as well as SQL database queries. You have to instrument your application, which is hosted in Elastic Beanstalk, in order to properly trace the calls via the X-Ray console .</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should you do to comply with the given requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808803,
    "question": "API Gateway ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A gateway response is identified by a response type defined by API Gateway. The response consists of an HTTP status code, a set of additional headers that are specified by parameter mappings, and a payload that is generated by a non-VTL (Apache Velocity Template Language) mapping template.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(7).jpg\"><span>You can set up a gateway response for a supported response type at the API level. Whenever API Gateway returns a response of the type, the header mappings and payload mapping templates defined in the gateway response are applied to return the mapped results to the API caller.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The following are the Gateway response types which are associated with the HTTP 504 error in API Gateway:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_FAILURE</strong></b><span>&nbsp;– The gateway response for an integration failed error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_TIMEOUT</strong></b><span>&nbsp;– The gateway response for an integration timed-out error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For the integration timeout, the range is from 50 milliseconds to 29 seconds for all integration types, including Lambda, Lambda proxy, HTTP, HTTP proxy, and AWS integrations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, there is an issue where the users are getting HTTP 504 errors in the serverless application. This means the Lambda function is working fine at times, but there are instances when it throws an error. Based on this analysis, the most likely cause of the issue is the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_TIMEOUT</strong></b><span>&nbsp;error since you will only get an&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_FAILURE</strong></b><span>&nbsp;error if your AWS Lambda integration does not work at all in the first place.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><b><strong class=\"Editor__editor-text-bold___25KrR\">The underlying Lambda function has been running for more than 29 seconds causing the API Gateway request to time out.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The memory allocated for the Lambda function is insufficient</strong></b><span>&nbsp;is incorrect. The fact that no errors were found in the CloudWatch Logs suggests that the function is not the bottleneck.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The API Gateway automatically enabled throttling in peak times which caused the HTTP 504 errors</strong></b><span>&nbsp;is incorrect because&nbsp;a large number of incoming requests will most likely produce an HTTP 502 or 429 error but not a 504 error.&nbsp;If executing the function would cause you to exceed a concurrency limit at either the account level (</span><i><em class=\"Editor__editor-text-italic___C9n8O\">ConcurrentInvocationLimitExceeded</em></i><span>) or function level (</span><i><em class=\"Editor__editor-text-italic___C9n8O\">ReservedFunctionConcurrentInvocationLimitExceeded</em></i><span>),&nbsp;Lambda may return a&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">TooManyRequestsException</em></i><span>&nbsp;as a response.&nbsp;For functions with a long timeout, your client might be disconnected during synchronous invocation while it waits for a response and returns an HTTP 504 error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">There is an authorization failure occurring between API Gateway and the Lambda function</strong></b><span>&nbsp;is incorrect because&nbsp;an authentication issue usually produces HTTP 403 errors and not 504s.&nbsp;The gateway response for authorization failures for missing authentication token errors, invalid AWS signature errors, or Amazon Cognito authentication problems is HTTP 403, which is why this option is unlikely to cause this issue.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/about-aws/whats-new/2017/11/customize-integration-timeouts-in-amazon-api-gateway/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/about-aws/whats-new/2017/11/customize-integration-timeouts-in-amazon-api-gateway/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536622,
        "value": "The API Gateway automatically enabled throttling in peak times which caused the HTTP 504 errors.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536623,
        "value": "The underlying Lambda function has been running for more than 29 seconds causing the API Gateway request to time out.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536624,
        "value": "There is an authorization failure occurring between API Gateway and the Lambda function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536625,
        "value": "The memory allocated for the Lambda function is insufficient",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 6,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536623,
        "questionId": 383222,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383222,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span style=\"background-color: rgb(255, 255, 255); color: rgb(69, 67, 69); font-family: &quot;Source Sans Pro&quot;, &quot;helvetica sans-serif&quot;; font-weight: 400; font-size: 14px;\">,</span><span>A serverless application, which uses a Lambda function integrated with API Gateway provides data to a front-end application written in ReactJS. The users are complaining that they are getting HTTP 504 errors intermittently when they are using the application in peak times. The developer found no errors in the CloudWatch logs of the Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808804,
    "question": " Lambda function ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS Lambda uses the VPC information you provide to set up ENIs that allow your Lambda function to access VPC resources. Each ENI is assigned a private IP address from the IP address range within the subnets you specify but is not assigned any public IP addresses.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(8).jpg\"><span>Therefore, if your Lambda function requires Internet access (for example, to access AWS services that don’t have VPC endpoints ), you can configure a NAT instance inside your VPC, or you can use the Amazon VPC NAT gateway. You cannot use an Internet gateway attached to your VPC since that requires the ENI to have public IP addresses.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If your Lambda function needs Internet access, just as described in this scenario, do not attach it to a public subnet or to a private subnet without Internet access. Instead, attach it only to private subnets with Internet access through a NAT instance or&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">add a NAT gateway to your VPC</strong></b><span>. You should also&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">ensure that the associated security group of the Lambda function allows outbound connections.&nbsp;</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Submit a limit increase request to AWS to raise the concurrent executions limit of your Lambda function&nbsp;</strong></b><span>is incorrect because&nbsp;the root cause of the problem is that the function cannot connect to public GraphQL APIs over the Internet. The scenario doesn’t mention anything about a concurrency problem.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring your function to forward payloads that were not processed to a dead-letter queue (DLQ) using Amazon SQS&nbsp;</strong></b><span>is incorrect because it will only improve the error handling of your Lambda function. The issue here is the Internet connectivity of your function and not its error handling hence, this option will not solve the problem.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting up elastic network interfaces (ENIs) to enable your Lambda function to connect securely to other resources within your private VPC</strong></b><span>&nbsp;is incorrect because this is already done automatically by AWS Lambda. It uses the VPC information you provide to automatically set up ENIs that allow your Lambda function to access VPC resources. You don’t need to do this step in order for your Lambda function to be integrated with your VPC.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/vpc.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/lambda/latest/dg/vpc.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/premiumsupport/knowledge-center/internet-access-lambda-function/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536626,
        "value": "Ensure that the associated security group of the Lambda function allows outbound connections",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536627,
        "value": "Submit a limit increase request to AWS to raise the concurrent executions limit of your Lambda function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536628,
        "value": "Configure your function to forward payloads that were not processed to a dead-letter queue (DLQ) using Amazon SQS.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536629,
        "value": "Add a NAT gateway to your VPC.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536630,
        "value": "Set up elastic network interfaces (ENIs) to enable your Lambda function to connect securely to other resources within your private VPC.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 7,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536626,
        "questionId": 383223,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536629,
        "questionId": 383223,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383223,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is refactoring a Lambda function that currently processes data using a public GraphQL API. There’s a new requirement to store query results in a database hosted in a VPC. The function has been configured with additional VPC-specific information, and the database connection has been successfully established. However, the engineer has discovered that the function can no longer connect to the internet after testing.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should the developer do to fix this issue? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808805,
    "question": "X-Ray SDK",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>X-Ray compiles and processes segment documents to generate queryable&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">trace summaries</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">full traces</strong></b><span>&nbsp;that you can access by using the&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\" class=\"Editor__editor-link___3vl2C\"><span>GetTraceSummaries</span></a><span>&nbsp;and&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html\" class=\"Editor__editor-link___3vl2C\"><span>BatchGetTraces</span></a><span>&nbsp;APIs, respectively. In addition to the segments and subsegments that you send to X-Ray, the service uses information in subsegments to generate&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">inferred segments</strong></b><span>&nbsp;and adds them to the full trace. Inferred segments represent downstream services and resources in the service map.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(9).jpg\"><span>In this scenario, the developer should&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">use the&nbsp;GetTraceSummaries&nbsp;API to get the list of trace IDs of the application and then retrieve the list of traces using&nbsp;BatchGetTraces&nbsp;API</strong></b><span>&nbsp;in order to develop the custom debug tool</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;GetGroup&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;BatchGetTraces&nbsp;API</strong></b><span>&nbsp;is incorrect because the&nbsp;GetGroup&nbsp;API just retrieves the group resource details.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;GetServiceGraph&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;GetTraceSummaries&nbsp;API&nbsp;</strong></b><span>is incorrect because the&nbsp;GetServiceGraph&nbsp;API just shows which services process the incoming requests, including the downstream services that they call as a result. In addition, you have to use the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">BatchGetTraces</em></i><span>&nbsp;API instead of the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">GetTraceSummaries</em></i><span>&nbsp;API to retrieve the list of traces.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use the&nbsp;BatchGetTraces&nbsp;API to get the list of trace IDs of the application and then retrieving the list of traces using&nbsp;GetTraceSummaries&nbsp;API&nbsp;</strong></b><span>is incorrect because it should be the other way around. You have to use the&nbsp;GetTraceSummaries&nbsp;API to get the list of trace IDs of the application and then use its result as an input parameter to retrieve the list of traces using the&nbsp;BatchGetTraces&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/api/API_BatchGetTraces.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536631,
        "value": "Use the GetGroup API to get the list of trace IDs of the application and then retrieve the list of traces using BatchGetTraces API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536632,
        "value": "Use the BatchGetTraces API to get the list of trace IDs of the application and then retrieve the list of traces using GetTraceSummaries API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536633,
        "value": "Use the GetTraceSummaries API to get the list of trace IDs of the application and then retrieve the list of traces using BatchGetTraces API.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536634,
        "value": "Use the GetServiceGraph API to get the list of trace IDs of the application and then retrieve the list of traces using GetTraceSummaries API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 8,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536633,
        "questionId": 383224,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383224,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer has instrumented an application using the X-Ray SDK to collect all data about the requests that an application serves. There is a new requirement to develop a custom debug tool which will enable them to view the full traces of their application without using the X-Ray console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should the developer do to accomplish this task?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808806,
    "question": "Lambda functions ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A gateway response is identified by a response type defined by API Gateway. The response consists of an HTTP status code, a set of additional headers that are specified by parameter mappings, and a payload that is generated by a non-VTL (Apache Velocity Template Language) mapping template.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(10).jpg\"><span>You can set up a gateway response for a supported response type at the API level. Whenever API Gateway returns a response of the type, the header mappings and payload mapping templates defined in the gateway response are applied to return the mapped results to the API caller.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The following are the Gateway response types which are associated with the HTTP 504 error in API Gateway:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_FAILURE</strong></b><span>&nbsp;– The gateway response for an integration failed error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_TIMEOUT</strong></b><span>&nbsp;– The gateway response for an integration timed out error. If the response type is unspecified, this response defaults to the DEFAULT_5XX type.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For the integration timeout, the range is from 50 milliseconds to 29 seconds for all integration types, including Lambda, Lambda proxy, HTTP, HTTP proxy, and AWS integrations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this scenario, there is an issue where the users are getting HTTP 504 errors in the serverless application. This means the Lambda function is working fine at times but there are instances when it throws an error. Based on this analysis, the most likely cause of the issue is the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_TIMEOUT</strong></b><span>&nbsp;error since you will only get an&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">INTEGRATION_FAILURE</strong></b><span>&nbsp;error if your AWS Lambda integration does not work at all in the first place.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the root cause of this issue is that the</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;API Gateway request has timed out because the underlying Lambda function has been running for more than 29 seconds</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Since the incoming requests are increasing, the API Gateway automatically enabled throttling which caused the HTTP 504 errors</strong></b><span>&nbsp;is incorrect because&nbsp;a large number of incoming requests will most likely produce an HTTP 502 or 429 error but not a 504 error.&nbsp;If executing the function would cause you to exceed a concurrency limit at either the account level (</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">ConcurrentInvocationLimitExceeded</strong></b></i><span>) or function level (</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">ReservedFunctionConcurrentInvocationLimitExceeded</strong></b></i><span>),&nbsp;Lambda may return a&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">TooManyRequestsException</strong></b></i><span>&nbsp;as a response.&nbsp;For functions with a long timeout, your client might be disconnected during synchronous invocation while it waits for a response and returns an HTTP 504 error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">An authorization failure occurred between API Gateway and the Lambda function</strong></b><span>&nbsp;is incorrect because&nbsp;an authentication issue usually produces HTTP 403 errors and not 504s.&nbsp;The gateway response for authorization failures for missing authentication token error, invalid AWS signature error, or Amazon Cognito authentication problems is HTTP 403, which is why this option is unlikely to be the cause of this issue.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The usage plan quota has been exceeded for the Lambda function</strong></b><span>&nbsp;is incorrect. Although this is a possible root cause for this scenario, this option has the least chance to produce HTTP 504 errors. The scenario says that the issue happens from&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">time to time</em></i><span>&nbsp;and not&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">all the time</em></i><span>&nbsp;which suggests that this happens intermittently. If the usage plan indeed exceeded the quota, then the 504 error should always show up and not just from</span><i><em class=\"Editor__editor-text-italic___C9n8O\">&nbsp;time to time</em></i><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/limits.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/about-aws/whats-new/2017/11/customize-integration-timeouts-in-amazon-api-gateway/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/about-aws/whats-new/2017/11/customize-integration-timeouts-in-amazon-api-gateway/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536635,
        "value": "Since the incoming requests are increasing, the API Gateway automatically enabled throttling which caused the HTTP 504 errors.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536636,
        "value": "An authorization failure occurred between API Gateway and the Lambda function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536637,
        "value": "The usage plan quota has been exceeded for the Lambda function.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536638,
        "value": "API Gateway request has timed out because the underlying Lambda function has been running for more than 29 seconds.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 9,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536638,
        "questionId": 383225,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383225,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A serverless application consisting of Lambda functions integrated with API Gateway, and DynamoDB processes ad hoc requests that its users send. Due to the recent spike in incoming traffic, some of your customers are complaining that they are getting HTTP 504 errors from time to time.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808807,
    "question": "Auto Scaling ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS X-Ray receives data from services as&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">segments</em></i><span>. X-Ray then groups segments that have a common request into&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">traces</em></i><span>. X-Ray processes the traces to generate a&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">service graph</em></i><span>&nbsp;that provides a visual representation of your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The compute resources running your application logic send data about their work as&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">segments</strong></b><span>. A segment provides the resource’s name, details about the request, and details about the work done. For example, when an HTTP request reaches your application, it can record the following data about:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The host&nbsp;– hostname, alias or IP address</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The request&nbsp;– method, client address, path, user agent</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The response&nbsp;– status, content</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The work done&nbsp;– start and end times, subsegments</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Issues that occur&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-errors\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>errors, faults and exceptions</span></a><span>, including automatic capture of exception stacks.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(11).jpg\"><span>The X-Ray SDK gathers information from request and response headers, the code in your application, and metadata about the AWS resources on which it runs. You choose the data to collect by modifying your application configuration or code to instrument incoming requests, downstream requests, and AWS SDK clients.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If a load balancer or other intermediary forwards a request to your application, X-Ray takes the client IP from the&nbsp;X-Forwarded-For&nbsp;header in the request instead of from the source IP in the IP packet. The client IP that is recorded for a forwarded request can be forged, so it should not be trusted.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is that, AWS X-Ray will fetch the client IP address&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;X-Forwarded-For&nbsp;header of the request</strong></b><span>.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;X-Forwarded-Host&nbsp;header&nbsp;of&nbsp;the</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;request</strong></b></i><span>&nbsp;is incorrect because this header is primarily used in identifying the original host&nbsp;where the request originated from and not the IP address.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">from the&nbsp;ipAddress&nbsp;query parameter of the request if it exists</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because query parameters are primarily used in the application layer and not for the network layer. Take note that AWS X-Ray uses the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">X-Forwarded-For&nbsp;</em></i><span>header of the request and not any query parameter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;from the source IP of the IP packet</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because&nbsp;AWS X-Ray uses the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">X-Forwarded-For&nbsp;</em></i><span>header of the request and not the source IP of the IP packet since the application is using an Application Load Balancer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536639,
        "value": "From the ipAddress query parameter of the request if it exists.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536640,
        "value": "From the X-Forwarded-Host header of the request.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536641,
        "value": "From the X-Forwarded-For header of the request.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536642,
        "value": "From the source IP of the IP packet.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 10,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536641,
        "questionId": 383226,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383226,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A leading commercial bank has an online banking portal that is hosted in an Auto Scaling group of EC2 instances with an Application Load Balancer in front to distribute the incoming traffic. The application has been instrumented, and the X-Ray daemon has been installed in all instances to allow debugging and troubleshooting using AWS X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In this architecture, from which source will AWS X-Ray fetch the client IP address?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808808,
    "question": "Auto Scaling group ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. Flow log data can be published to Amazon CloudWatch Logs and Amazon S3. After you’ve created a flow log, you can retrieve and view its data in the chosen destination.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(12logo).jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Flow logs can help you with a number of tasks; for example, to troubleshoot why specific traffic is not reaching an instance, which in turn helps you diagnose overly restrictive security group rules. You can also use flow logs as a security tool to monitor the traffic that is reaching your instance. CloudWatch Logs charges apply when using flow logs, whether you send them to CloudWatch Logs or to Amazon S3.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, you should&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">create a flow log in your VPC</strong></b><span>&nbsp;to&nbsp;capture information about the IP traffic going to and from network interfaces in your VPC.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using CloudTrail logs to track all API calls and capture information about the IP traffic going to and from your VPC&nbsp;</strong></b><span>is incorrect. Although you can indeed use CloudTrail to track the API call, it can’t capture information about the IP traffic of your VPC.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Installing and running the AWS X-Ray daemon to your EC2 instances using an instance metadata script</strong></b><span>&nbsp;is incorrect because you have to use a user data script and not a metadata. Alternatively, you can instrument your application which is running in an EC2 instance to capture the client’s IP address. However, it is much easier to just enable VPC Flow Logs to meet the requirement.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using AWS Inspector to capture information about the IP traffic going to and from the network interfaces of your EC2 instances</strong></b><span>&nbsp;is incorrect because this service is just an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. It doesn’t have the ability to capture IP traffic of your VPC.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536643,
        "value": "Create a flow log in your VPC.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536644,
        "value": "Use AWS Inspector to capture information about the IP traffic going to and from the network interfaces of your EC2 instances.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536645,
        "value": "Install and run the AWS X-Ray daemon to your EC2 instances using an instance metadata script.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536646,
        "value": "Use CloudTrail logs to track all API calls and capture information about the IP traffic going to and from your VPC.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 11,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536643,
        "questionId": 383227,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383227,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An online stock trading platform is hosted in an Auto Scaling group of EC2 instances with an Application Load Balancer in front to distribute the incoming traffic evenly. The developer must capture information about the IP traffic going to and from network interfaces in your VPC to comply with financial regulatory requirements.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following options should the developer do to meet the requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808809,
    "question": "Amazon Kinesis Data Stream",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>There are two primary reasons why records may be delivered more than one time to your Amazon Kinesis Data Streams application: producer retries and consumer retries. Your application must anticipate and appropriately handle processing individual records multiple times.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(13).jpg\"><span>Consider a producer that experiences a network-related timeout after it makes a call to&nbsp;PutRecord, but before it can receive an acknowledgment from Amazon Kinesis Data Streams. The producer cannot be sure if the record was delivered to Kinesis Data Streams. Assuming that every record is important to the application, the producer would have written to retry the call with the same data. If both&nbsp;PutRecord&nbsp;calls on that same data were successfully committed to Kinesis Data Streams, then there will be two Kinesis Data Streams records. Although the two records have identical data, they also have unique sequence numbers. Applications that need strict guarantees should embed a primary key within the record to remove duplicates later when processing. Note that the number of duplicates due to producer retries is usually low compared to the number of duplicates due to consumer retries.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">embed a primary key within the record</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>to remove duplicates later when processing.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding more shards</strong></b><span>&nbsp;is incorrect because this is not a suitable solution for handling duplicate records in the Kinesis data stream. This is primarily used to increase the rate of data flowing through the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Splitting shards of the data stream&nbsp;</strong></b><span>is incorrect because&nbsp;this is used to increase the capacity of the stream and not to avoid any duplicate data.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Merging shards of the data stream</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this is primarily used to make better use of the unused capacity in the stream and to save on costs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html</span></a></p>",
    "choices": [
      {
        "id": 1536647,
        "value": "Add more shards.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536648,
        "value": "Split shards of the data stream.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536649,
        "value": "Merge shards of the data stream",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536650,
        "value": "Embed a primary key within the record",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 12,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536650,
        "questionId": 383228,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383228,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A clickstream application uses Amazon Kinesis Data Stream for real-time processing.&nbsp;PutRecord&nbsp;API calls are being used by the producer to send data to the stream. However, there are cases where the producer intermittently restarted while doing the processing, which resulted in sending the same data twice to the stream. This inadvertently causes duplication of entries in the data stream, which affects the processing of the consumers.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should you implement to resolve this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808810,
    "question": "AWS X-Ray",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The compute resources running your application logic send data about their work as&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">segments</strong></b><span>. A segment provides the resource’s name, details about the request, and details about the work done.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A subset of segment fields are indexed by X-Ray for use with filter expressions. You can search for segments associated with specific information in the X-Ray console or by using the&nbsp;GetTraceSummaries&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(14).jpg\"><span>Even with sampling, a complex application generates a lot of data. When you choose a time period of traces to view in the X-Ray console, you might get more results than the console can display. You can narrow the results to just the traces that you want to find by using a&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">filter expression</strong></b><span>.&nbsp;Running the&nbsp;GetTraceSummaries&nbsp;operation retrieves IDs and annotations for traces available for a specified time frame using an optional filter.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">using filter expressions via the X-Ray console</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">fetching the trace IDs and annotations using the&nbsp;GetTraceSummaries&nbsp;API</strong></b><span>&nbsp;are the correct answers in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Fetching the data using the&nbsp;BatchGetTraces&nbsp;API</strong></b><span>&nbsp;is incorrect because this API simply retrieves a list of traces specified by ID. It does not support filter expressions nor returns the annotations.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Sending trace results to an S3 bucket then querying the trace output using Amazon Athena</strong></b><span>&nbsp;is incorrect. Although this solution may work, this entails a lot of configuration which is contrary to what the scenario requires. There are other simpler methods of searching through traces in X-Ray such as using annotations and filter expressions.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring Sampling Rules in the AWS X-Ray Console</strong></b><span>&nbsp;is incorrect because&nbsp;sampling rules just tell the X-Ray SDK how many requests to record for a set of criteria.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536651,
        "value": "Configure Sampling Rules in the AWS X-Ray Console.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536652,
        "value": "Send trace results to an S3 bucket then query the trace output using Amazon Athena.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536653,
        "value": "Fetch the data using the BatchGetTraces API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536654,
        "value": "Use filter expressions via the X-Ray console.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536655,
        "value": "Fetch the trace IDs and annotations using the GetTraceSummaries API.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 13,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536655,
        "questionId": 383229,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536654,
        "questionId": 383229,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383229,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer uses AWS X-Ray to create a trace on an instrumented web application to identify any performance bottlenecks. The segment documents being sent by the application contain annotations that the developer wants to utilize in order to identify and filter out specific data from the trace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should the developer do in order to satisfy this requirement with minimal configuration? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808811,
    "question": "AWS X-Ray ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can send trace data to X-Ray in the form of segment documents. A&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">segment document</strong></b><span>&nbsp;is a JSON formatted string that contains information about the work that your application does in service of a request. Your application can record data about the work that it does itself in segments or work that uses downstream services and resources in subsegments.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A segment document can be up to 64 kB and contain a whole segment with subsegments, a fragment of a segment that indicates that a request is in progress, or a single subsegment that is sent separately. You can send segment documents directly to X-Ray by using the&nbsp;PutTraceSegments&nbsp;API. An alternative is, instead of sending segment documents to the X-Ray API, you can send segments and subsegments to an X-Ray daemon, which will buffer them and upload to the X-Ray API in batches. The X-Ray SDK sends segment documents to the daemon to avoid making calls to AWS directly. This is the correct option among the choices.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(15).jpg\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">using X-Ray SDK to generate segment documents with subsegments and sending them to the X-Ray daemon, which will buffer them and upload to the X-Ray API in batches</strong></b><span>&nbsp;is the correct answer in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Using AWS X-Ray SDK to upload a trace segment by executing&nbsp;PutTraceSegments&nbsp;API&nbsp;</strong></b><span>is incorrect because you should upload the&nbsp;segment documents&nbsp;with subsegments instead.&nbsp;A&nbsp;trace segment&nbsp;is just a JSON representation of a request that your application serves.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Installing AWS X-Ray on the different services that communicate with the application including the AWS resources that the application calls&nbsp;</strong></b><span>is incorrect because you cannot run a trace on the application and the services at the same time as this will produce two different results. You simply have to send the&nbsp;segment documents with subsegments to get the information about downstream calls that your application makes to AWS resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Passing multiple trace segments as a parameter of&nbsp;PutTraceSegments&nbsp;API</strong></b><span>&nbsp;is incorrect because, contrary to the API’s name, you have to upload&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">segment</strong></b><span>&nbsp;documents and not trace segments. The API has a single parameter:&nbsp;TraceSegmentDocuments, that takes a list of JSON segment documents.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-sendingdata.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-sendingdata.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_PutTraceSegments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/api/API_PutTraceSegments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536656,
        "value": "Use AWS X-Ray SDK to upload a trace segment by executing PutTraceSegments API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536657,
        "value": "Pass multiple trace segments as a parameter of PutTraceSegments API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536658,
        "value": "Install AWS X-Ray on the different services that communicate with the application including the AWS resources that the application calls.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536659,
        "value": "Use X-Ray SDK to generate segment documents with subsegments and send them to the X-Ray daemon, which will buffer them and upload to the X-Ray API in batches.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 14,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536659,
        "questionId": 383230,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383230,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is utilizing AWS X-Ray to generate a visual representation of the requests flowing through their enterprise web application. Since the application interacts with multiple services, all requests must be traced in X-Ray, including any downstream calls made to AWS resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following actions should the developer implement for this scenario?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808812,
    "question": "CORS configuration ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. With CORS support, you can build rich client-side web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To configure your bucket to allow cross-origin requests, you create a CORS configuration, which is an XML document with rules that identify the origins that you will allow to access your bucket, the operations (HTTP methods) that will support each origin, and other operation-specific information. You can add up to 100 rules to the configuration. You add the XML document as the cors subresource to the bucket either programmatically or by using the Amazon S3 console as shown below:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(16).jpg\"><span>A CORS configuration is an XML file that contains a series of rules within a&nbsp;&lt;CORSRule&gt;. A configuration can have up to 100 rules. A rule is defined by one of the following tags:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AllowedOrigin</strong></b><span>&nbsp;– Specifies domain origins that you allow to make cross-domain requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AllowedMethod</strong></b><span>&nbsp;– Specifies a type of request you allow (GET, PUT, POST, DELETE, HEAD) in cross-domain requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AllowedHeader</strong></b><span>&nbsp;– Specifies the headers allowed in a preflight request.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;Below are some of the&nbsp;CORSRule&nbsp;elements:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">MaxAgeSeconds</strong></b><span>&nbsp; – Specifies the amount of time in seconds (in this example, 3000) that the browser caches an Amazon S3 response to a preflight OPTIONS request for the specified resource. By caching the response, the browser does not have to send preflight requests to Amazon S3 if the original request will be repeated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">ExposeHeader</strong></b><span>&nbsp; – Identifies the response headers (in this example,&nbsp;x-amz-server-side-encryption,&nbsp;x-amz-request-id, and&nbsp;x-amz-id-2) that customers are able to access from their applications (for example, from a JavaScript&nbsp;XMLHttpRequest&nbsp;object).</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answers in this scenario are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– It allows a user to view, add, remove or update objects inside the S3 bucket from the domain tutorialsdojo.com</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– This will cause the browser to cache an Amazon S3 response of a preflight OPTIONS request for 1 hour</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the request will fail if the&nbsp;x-amz-meta-custom-header&nbsp;header is not included</strong></b><span>&nbsp;is incorrect because the&nbsp;ExposeHeader&nbsp;element&nbsp;refers to the header that will be exposed to the response and not a constraint for the request.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">this configuration authorizes the user to perform actions on the S3 bucket</strong></b><span>&nbsp;is incorrect because&nbsp;this configuration actually does the opposite. It doesn’t authorize the user to perform actions on the S3 bucket.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;all HTTP Methods are allowed</strong></b><span>&nbsp;is incorrect because the configuration didn’t include the&nbsp;HEAD&nbsp;HTTP method.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>http://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/cors.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/cors.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b></p>",
    "choices": [
      {
        "id": 1536660,
        "value": "This will cause the browser to cache the response of the preflight OPTIONS request for 1 hour.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536661,
        "value": "All HTTP Methods are allowed.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536662,
        "value": "This configuration authorizes the user to perform actions on the S3 bucket.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536663,
        "value": "The request will fail if the x-amz-meta-custom-header header is not included.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536664,
        "value": "It allows a user to view, add, remove or update objects inside the S3 bucket from the domain tutorialsdojo.com.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 15,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536664,
        "questionId": 383231,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536660,
        "questionId": 383231,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383231,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You were recently hired as a developer for a leading insurance firm in Asia which has a hybrid cloud architecture with AWS. The project that was assigned to you involves setting up a static website using Amazon S3 with a CORS configuration as shown below:</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><pre data-highlight-language=\"java\"><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; \n&lt;CORSConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"&gt; \n    &lt;CORSRule&gt; \n        &lt;AllowedOrigin&gt;https://tutorialsdojo.com&lt;/AllowedOrigin&gt; \n        &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt; \n        &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt; \n        &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt; \n        &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt; \n        &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; \n        &lt;ExposeHeader&gt;ETag&lt;/ExposeHeader&gt; \n        &lt;ExposeHeader&gt;x-amz-meta-custom-header&lt;/ExposeHeader&gt; \n        &lt;MaxAgeSeconds&gt;3600&lt;/MaxAgeSeconds&gt; \n    &lt;/CORSRule&gt; \n&lt;/CORSConfiguration&gt;\n</code></pre><span>Which of the following statements are TRUE with regards to this S3 configuration? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808813,
    "question": "EC2 instance ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;segment document&nbsp;conveys information about a segment to X-Ray. A segment document can be up to 64 kB and contain a whole segment with subsegments, a fragment of a segment that indicates that a request is in progress, or a single subsegment that is sent separately. You can send segment documents directly to X-Ray by using the&nbsp;PutTraceSegments&nbsp;API.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>X-Ray compiles and processes segment documents to generate queryable&nbsp;trace summaries&nbsp;and&nbsp;full traces&nbsp;that you can access by using the&nbsp;GetTraceSummaries&nbsp;and&nbsp;BatchGetTraces&nbsp;APIs, respectively. In addition to the segments and subsegments that you send to X-Ray, the service uses information in subsegments to generate&nbsp;inferred segments&nbsp;and adds them to the full trace. Inferred segments represent downstream services and resources in the service map.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><br></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(17resize).jpg\"></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><br></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Below are the optional subsegment fields:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">namespace</strong></b><span>&nbsp;–&nbsp;aws&nbsp;for AWS SDK calls;&nbsp;remote&nbsp;for other downstream calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">http</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-http\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>http</span></a><span>&nbsp;object with information about an outgoing HTTP call.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">aws</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-aws\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>aws</span></a><span>&nbsp;object with information about the downstream AWS resource that your application called.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">error,&nbsp;throttle,&nbsp;fault, and&nbsp;cause</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-errors\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>error</span></a><span>&nbsp;fields that indicate an error occurred and that include information about the exception that caused the error.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">annotations</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-annotations\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>annotations</span></a><span>&nbsp;object with key-value pairs that you want X-Ray to index for search.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">metadata</strong></b><span>&nbsp;–&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html#api-segmentdocuments-metadata\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>metadata</span></a><span>&nbsp;object with any additional data that you want to store in the segment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">subsegments</strong></b><span>&nbsp;– array&nbsp;of subsegment objects.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">precursor_ids</strong></b><span>&nbsp;– array&nbsp;of subsegment IDs that identify subsegments with the same parent that was completed prior to this subsegment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the “metadata” field in the segment section to add custom data for your tracing. If you want to trace all the AWS SDK calls of your application, then you can add a subsegment and set the “namespace” field to “AWS”. Alternatively, you can set the “namespace” value to “remote” if you want to trace other downstream calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the valid considerations in this scenario are:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Set the&nbsp;namespace&nbsp;subsegment field to&nbsp;aws&nbsp;for AWS SDK calls and&nbsp;remote&nbsp;for other downstream calls.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">– Set the&nbsp;metadata&nbsp;object with any additional custom data that you want to store in the segment.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;annotations&nbsp;object with any additional custom data that you want to store in the segment</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this should be the&nbsp;metadata&nbsp;object and not the&nbsp;annotations&nbsp;object.&nbsp;Segments and subsegments can include an annotations object containing one or more fields that X-Ray indexes for use with filter expressions. Fields can have string, number, or Boolean values (no objects or arrays). X-Ray indexes up to 50 annotations per trace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;namespace&nbsp;subsegment field to&nbsp;remote&nbsp;for AWS SDK calls and&nbsp;aws&nbsp;for other downstream calls&nbsp;</strong></b><span>is incorrect because this should be the other way around. You should set the&nbsp;namespace&nbsp;subsegment field to&nbsp;aws&nbsp;for AWS SDK calls and&nbsp;remote&nbsp;for other downstream calls</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the&nbsp;metadata&nbsp;object with key-value pairs that you want X-Ray to index for search&nbsp;</strong></b><span>is incorrect because this should be the&nbsp;annotations&nbsp;object, and not the&nbsp;metadata&nbsp;object.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536665,
        "value": "Set the metadata object with key-value pairs that you want X-Ray to index for search.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536666,
        "value": "Set the metadata object with any additional custom data that you want to store in the segment.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536667,
        "value": "Set the namespace subsegment field to remote for AWS SDK calls and aws for other downstream calls.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536668,
        "value": "Set the namespace subsegment field to aws for AWS SDK calls and remote for other downstream calls.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536669,
        "value": "Set the annotations object with any additional custom data that you want to store in the segment.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 16,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536668,
        "questionId": 383232,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536666,
        "questionId": 383232,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383232,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is instrumenting an application that will be hosted in a large On-Demand EC2 instance in AWS. All of the downstream calls invoked by the application must be traced properly, including the AWS SDK calls. A user-defined data should also be present to expedite the troubleshooting process.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following are valid considerations in AWS X-Ray that the developer should follow? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808814,
    "question": "Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>AWS resources created for a worker environment tier include an Auto Scaling group, one or more Amazon EC2 instances, and an IAM role. For the worker environment tier, Elastic Beanstalk also creates and provisions an Amazon SQS queue if you don’t already have one. When you launch a worker environment tier, Elastic Beanstalk installs the necessary support files for your programming language of choice and a daemon on each EC2 instance in the Auto Scaling group.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The daemon is responsible for pulling requests from an Amazon SQS queue and then sending the data to the web application running in the worker environment tier that will process those messages. If you have multiple instances in your worker environment tier, each instance has its own daemon, but they all read from the same Amazon SQS queue.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(18).jpg\"><span>You can define periodic tasks in a file named&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">cron.yaml</strong></b><span>&nbsp;in your source bundle to add jobs to your worker environment’s queue automatically at a regular intervals. For example, you can configure and upload a cron.yaml file, which creates two periodic tasks: one that runs every 12 hours and a second that runs at 11 pm UTC every day.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, using the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">cron.yaml&nbsp;</strong></b><span>is the correct configuration file to be used in this scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Dockerrun.aws.json&nbsp;</strong></b><span>is incorrect because&nbsp;this configuration file is primarily used in multi-container Docker environments that are hosted in Elastic Beanstalk. This can be used alone or combined with source code and content in a source bundle to create an environment on a Docker platform.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">env.yaml&nbsp;</strong></b><span>is incorrect because this is primarily used&nbsp;to configure the environment name, solution stack, and environment links to use when creating your environment in Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">appspec.yml&nbsp;</strong></b><span>is incorrect because this is used to manage each application deployment as a series of lifecycle event hooks in CodeDeploy and not in Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html#worker-periodictasks\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html#worker-periodictasks</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536670,
        "value": "env.yaml",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536671,
        "value": "cron.yaml",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536672,
        "value": "appspec.yml",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536673,
        "value": "Dockerrun.aws.json",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 17,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536671,
        "questionId": 383233,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383233,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer is instructed to configure a worker daemon to queue messages based on a specific schedule using a worker environment hosted in Elastic Beanstalk. Periodic tasks should be defined to automatically add jobs to your worker environment’s queue at regular intervals.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which configuration file should the developer add to the source bundle to meet the above requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808815,
    "question": "X-Ray console ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use AWS Identity and Access Management (IAM) to grant X-Ray permissions to users and compute resources in your account. IAM controls access to the X-Ray service at the API level to enforce permissions uniformly, regardless of which client (console, AWS SDK, AWS CLI) your users employ.&nbsp;To use the X-Ray console to view service maps and segments, you only need read permissions. To enable console access, add the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayReadOnlyAccess</strong></b><span>&nbsp;managed policy to your IAM user.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For local development and testing, create an IAM user with read and write permissions. Generate access keys for the user and store them in the standard AWS SDK location. You can use these credentials with the X-Ray daemon, the AWS CLI, and the AWS SDK.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To deploy your instrumented app to AWS, create an IAM role with write permissions and assign it to the resources running your application.&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXRayDaemonWriteAccess</strong></b><span>&nbsp;includes permission to upload traces and some read permissions as well to support the use of sampling rules.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The read and write policies do not include permission to configure encryption key settings and sampling rules. Use&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayFullAccess</strong></b><span>&nbsp;to access these settings or add configuration APIs in a custom policy. For encryption and decryption with a customer managed key that you create, you also need permission to use the key.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayReadOnlyAccess</strong></b><span>&nbsp;managed policy is the most appropriate one to grant to the developer in order for her to access the X-Ray console. This also abides with the standard security advice of granting least privilege, or granting only the permissions required to perform a task.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXRayDaemonWriteAccess</strong></b><span>&nbsp;is incorrect because this policy is more suitable if you want to grant permission to upload traces to X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWSXrayFullAccess</strong></b><span>&nbsp;is incorrect. Although this can provide the required access to the developer, it does not abide with the standard security advice of granting least privilege. Hence, this is not the most appropriate policy to use.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AmazonS3ReadOnlyAccess</strong></b><span>&nbsp;is incorrect because&nbsp;this policy just provides the instance permission to download the X-Ray daemon from Amazon S3.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-permissions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-permissions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/security.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/security.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536674,
        "value": "AWSXrayFullAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536675,
        "value": "AmazonS3ReadOnlyAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536676,
        "value": "AWSXRayDaemonWriteAccess",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536677,
        "value": "AWSXrayReadOnlyAccess",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 18,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536677,
        "questionId": 383234,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383234,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A newly hired developer has been instructed to debug an application. She tried to access the X-Ray console to view service maps and segments but her current access is insufficient.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST appropriate managed policy that should be granted to the developer?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808816,
    "question": "EC2 instance",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can use the CloudWatch agent to collect both system metrics and log files from Amazon EC2 instances and on-premises servers. The agent supports both Windows Server and Linux, and enables you to select the metrics to be collected, including sub-resource metrics such as per-CPU core. Aside from the usual metrics, it also tracks the&nbsp;memory, swap, and disk space utilization metrics of your server.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(19).jpg\"><span>Hence, the most suitable solution to use in this scenario is to:</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><b><strong class=\"Editor__editor-text-bold___25KrR\">Install the Amazon CloudWatch Logs agent to the EC2 instance.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use AWS CloudShell to consolidate all metrics in a single dashboard</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because&nbsp;this service is simply a command-line interface used for managing AWS resources from a terminal. It is not a monitoring tool and does not collect or display EC2 instance metrics.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Using detailed monitoring in CloudWatch&nbsp;</strong></b><span>is incorrect because this will typically send metric data of the EC2 instance to CloudWatch in 1-minute periods instead of 5-minute intervals.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Install the AWS X-Ray daemon on the EC2 instance&nbsp;</strong></b><span>is incorrect. Although this is helpful for troubleshooting your application, it does not have the capability to track the memory and swap usage of the instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536678,
        "value": "Use detailed monitoring in CloudWatch.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536679,
        "value": "Install the AWS X-Ray daemon on the EC2 instance.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536680,
        "value": "Use AWS CloudShell to consolidate all metrics in a single dashboard.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536681,
        "value": "Install the Amazon CloudWatch Logs agent to the EC2 instance.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 19,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536681,
        "questionId": 383235,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383235,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A web application is currently deployed on an On-Demand Linux EC2 instance that connects to an Amazon RDS database. Users have frequently reported that the application crashes intermittently. The support team has reviewed the logs in CloudWatch but has been unable to identify the root cause. To enhance troubleshooting, the team needs to monitor additional metrics, including memory utilization, swap usage, and the count of idle and active processes running on the instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which solution would be the MOST appropriate to implement in this situation?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808817,
    "question": "Amazon EventBridge",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">DynamoDB stream</em></i><span>&nbsp;is an ordered flow of information about changes to items in an Amazon DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attribute(s) of the items that were modified. A&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">stream record</em></i><span>&nbsp;contains information about a data modification to a single item in a DynamoDB table. You can configure the stream so that the stream records capture additional information, such as the “before” and “after” images of modified items.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(21).jpg\"><span>All data in DynamoDB Streams is subject to a 24-hour lifetime. You can retrieve and analyze the last 24 hours of activity for any given table; however, data older than 24 hours is susceptible to trimming (removal) at any moment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>If you disable a stream on a table, the data in the stream will continue to be readable for 24 hours. After this time, the data expires and the stream records are automatically deleted. Note that there is no mechanism for manually deleting an existing stream; you just need to wait until the retention limit expires (24 hours), and all the stream records will be deleted.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">decrease the interval of running your function to 24 hours</strong></b><span>&nbsp;because in DynamoDB Streams, data older than 24 hours is susceptible to trimming (removal) at any moment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Increasing the interval of running your function to 48 hours&nbsp;</strong></b><span>is incorrect because this will actually make the problem worse. Considering that the data in DynamoDB Streams only lasts for 24 hours, you should actually decrease the interval of running your function and not further increase it.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the value of&nbsp;StreamViewType&nbsp;parameter in DynamoDB Streams to&nbsp;NEW_AND_OLD_IMAGES</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this just configures DynamoDB to write both the new and the old item images of the item to the stream. Setting the Stream View Type is actually irrelevant in this scenario since the problem is about missing data and not missing old or new values of the items.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Setting the value of&nbsp;StreamViewType&nbsp;parameter in DynamoDB Streams to&nbsp;NEW_IMAGE</strong></b><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">&nbsp;</strong></b></i><span>is incorrect because this just configures the DynamoDB to write only the new image of the item to the stream. Just as mentioned above, the root cause of the issue is the length of the interval of running the Lambda function and not the DynamoDB Streams configuration.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_StreamSpecification.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_StreamSpecification.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536682,
        "value": "Set the value of StreamViewType parameter in DynamoDB Streams to NEW_AND_OLD_IMAGES.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536683,
        "value": "Decrease the interval of running your function to 24 hours.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536684,
        "value": "Set the value of StreamViewType parameter in DynamoDB Streams to NEW_IMAGE.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536685,
        "value": "Increase the interval of running your function to 48 hours.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 20,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536683,
        "questionId": 383236,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383236,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A company is developing an online system that lets patients schedule appointments with their preferred doctors at medical centers all over the country. The company uses Amazon DynamoDB as its primary database. The DynamoDB Streams feature is enabled on the DynamoDB table to capture all changes made to the booking data. A Lambda function integrated with Amazon EventBridge (Amazon CloudWatch Events) is used to process the data stream every 36 hours and then store the results in an S3 bucket.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>There are a lot of updated items in DynamoDB that are not sent to the S3 bucket, even though there are no errors in the logs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST appropriate solution for this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808818,
    "question": "Elastic Beanstalk",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS WAF</strong></b><span>&nbsp;is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to an Amazon API Gateway API, Amazon CloudFront or an Application Load Balancer. AWS WAF also lets you control access to your content. Based on conditions that you specify, such as the IP addresses that requests originate from or the values of query strings, API Gateway, CloudFront or an Application Load Balancer responds to requests either with the requested content or with an HTTP 403 status code (Forbidden). You also can configure CloudFront to return a custom error page when a request is blocked.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(22).jpg\"><span>At the simplest level, AWS WAF lets you choose one of the following behaviors:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Allow all requests except the ones that you specify</strong></b><span>&nbsp;– This is useful when you want CloudFront or an Application Load Balancer to serve content for a public website, but you also want to block requests from attackers.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Block all requests except the ones that you specify</strong></b><span>&nbsp;– This is useful when you want to serve content for a restricted website whose users are readily identifiable by properties in web requests, such as the IP addresses that they use to browse to the website.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Count the requests that match the properties that you specify</strong></b><span>&nbsp;– When you want to allow or block requests based on new properties in web requests, you first can configure AWS WAF to count the requests that match those properties without allowing or blocking those requests. This lets you confirm that you didn’t accidentally configure AWS WAF to block all the traffic to your website. When you’re confident that you specified the correct properties, you can change the behavior to allow or block requests.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer in this scenario is&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS WAF.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon Guard</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\" style=\"font-family: Arial, sans-serif;\">​</strong></b><b><strong class=\"Editor__editor-text-bold___25KrR\">Duty</strong></b><span>&nbsp;is incorrect because this is just a threat detection service that continuously monitors malicious activity and unauthorized behavior to protect your AWS accounts and workloads.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">AWS Firewall Manager&nbsp;</strong></b><span>is incorrect because this just simplifies your AWS WAF and AWS Shield Advanced administration and maintenance tasks across multiple accounts and resources.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Network Access Control List</strong></b><span>&nbsp;is incorrect because this is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/waf/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/waf/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/blogs/security/three-most-important-aws-waf-rate-based-rules/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/blogs/security/three-most-important-aws-waf-rate-based-rules/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536686,
        "value": "Amazon GuardDuty",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536687,
        "value": "AWS WAF",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536688,
        "value": "AWS Firewall Manager",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536689,
        "value": "Network Access Control List",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 21,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536687,
        "questionId": 383237,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383237,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A leading insurance firm is hosting its customer portal in Elastic Beanstalk, which has an RDS database in AWS. The support team in your company discovered a lot of SQL injection attempts and cross-site scripting attacks on the portal, which is starting to affect the production environment.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following services should you implement to mitigate this attack?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808819,
    "question": "Lambda function",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can monitor API execution using CloudWatch, which collects and processes raw data from API Gateway into readable, near-real-time metrics. These statistics are recorded for a period of two weeks so that you can access historical information and gain a better perspective on how your web application or service is performing. By default, API Gateway metric data is automatically sent to CloudWatch in one-minute periods.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The metrics reported by API Gateway provide information that you can analyze in different ways. The list below shows some common uses for the metrics. These are suggestions to get you started, not a comprehensive list.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">IntegrationLatency</strong></b><span>&nbsp;metrics to measure the responsiveness of the backend.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Latency</strong></b><span>&nbsp;metrics to measure the overall responsiveness of your API calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheHitCount</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheMissCount</strong></b><span>&nbsp;metrics to optimize cache capacities to achieve a desired performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct metrics that you have to use in this scenario are&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Latency</strong></b><span>&nbsp;and</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;IntegrationLatency.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Count</strong></b><span>&nbsp;is incorrect because this&nbsp;metric simply gets the total number of API requests in a given period.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheMissCount</strong></b><span>&nbsp;is incorrect because this metric just gets the number of requests served from the backend in a given period when API caching is enabled.&nbsp;The&nbsp;Sum&nbsp;statistic represents this metric, namely, the total count of the cache misses in the given period.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheHitCount</strong></b><span>&nbsp;is incorrect because this&nbsp;fetches the number of requests served from the API cache in a given period.&nbsp;The&nbsp;Sum&nbsp;statistic represents this metric, namely, the total count of the cache hits in the given period.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring-cloudwatch.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring-cloudwatch.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536690,
        "value": "IntegrationLatency",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536691,
        "value": "Latency",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536692,
        "value": "CacheHitCount",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536693,
        "value": "Count",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536694,
        "value": "CacheMissCount",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 22,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536690,
        "questionId": 383238,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536691,
        "questionId": 383238,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383238,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>An API gateway with a Lambda proxy integration takes a long time to complete its processing. There were also occurrences where some requests timed out. You want to monitor the responsiveness of your API calls as well as the underlying Lambda function.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following CloudWatch metrics should you use to troubleshoot this issue? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808820,
    "question": "ASG",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The AWS X-Ray SDK does not send trace data directly to AWS X-Ray. To avoid calling the service every time your application serves a request, the SDK sends the trace data to a daemon, which collects segments for multiple requests and uploads them in batches. Use a script to run the daemon alongside your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To properly instrument your application hosted in an EC2 instance,&nbsp;you have to install the X-Ray daemon by using a user data script. This will install and run the daemon automatically when you launch the instance. To use the daemon on Amazon EC2, create a new instance profile role or add the managed policy to an existing one. This will grant the daemon permission to upload trace data to X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(24).jpg\"><span>The AWS X-Ray daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. The daemon works in conjunction with the AWS X-Ray SDKs and must be running so that data sent by the SDKs can reach the X-Ray service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Use a user data script to install the X-Ray daemon.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable AWS X-Ray tracing on the ASG’s launch template&nbsp;</strong></b><span>is incorrect. There’s no option to enable X-Ray tracing in a launch template of an ASG.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Enable AWS Web Application Firewall (WAF) on the ALB to monitor web requests&nbsp;</strong></b><span>is incorrect. Although&nbsp;it can help monitor and protect the application from common web exploits,&nbsp;it’s not capable of instrumenting the application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Refactor your application to send segment documents directly to X-Ray by using the&nbsp;PutTraceSegments&nbsp;API&nbsp;</strong></b><span>is incorrect. Although this solution will work, it entails a lot of manual effort to perform. You don’t need to do this because you can just install the X-Ray daemon on the instance to automate this process.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html#xray-daemon-permissions\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html#xray-daemon-permissions</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b></p>",
    "choices": [
      {
        "id": 1536695,
        "value": "Use a user data script to install the X-Ray daemon.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536696,
        "value": "Enable AWS X-Ray tracing on the ASG’s launch template.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536697,
        "value": "Refactor your application to send segment documents directly to X-Ray by using the PutTraceSegments API.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536698,
        "value": "Enable AWS Web Application Firewall (WAF) on the ALB to monitor web requests.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 23,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536695,
        "questionId": 383239,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383239,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>In the next financial year, a company has decided to develop a completely new version of its legacy application that will utilize Node.js and GraphQL. The new architecture aims to offer an end-to-end view of requests as they traverse the application and display a map of the underlying components.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To achieve this, the application will be hosted in an Auto Scaling group (ASG) of Linux EC2 instances behind an Application Load Balancer (ALB) and must be instrumented to send trace data to the AWS X-Ray.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following options is the MOST suitable way to satisfy this requirement?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808821,
    "question": "ECS cluster",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The AWS X-Ray SDK does not send trace data directly to AWS X-Ray. To avoid calling the service every time your application serves a request, the SDK sends the trace data to a daemon, which collects segments for multiple requests and uploads them in batches. Use a script to run the daemon alongside your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>To properly instrument your applications in Amazon ECS, you have to create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster. You can use port mappings and network mode settings in your task definition file to allow your application to communicate with the daemon container.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(25).jpg\"><span>The AWS X-Ray daemon is a software application that listens for traffic on UDP port 2000, gathers raw segment data, and relays it to the AWS X-Ray API. The daemon works in conjunction with the AWS X-Ray SDKs and must be running so that data sent by the SDKs can reach the X-Ray service.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct steps to properly instrument the application is to&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster.&nbsp;</strong></b><span>In addition,</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;you also have to configure the port mappings and network mode settings in your task definition file to allow traffic on UDP port 2000.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Configuring the port mappings and network mode settings in the container agent to allow traffic on TCP port 2000&nbsp;</strong></b><span>is incorrect because this should be done in the task definition and not in the container agent. Moreover, X-Ray is primarily using the UDP port 2000, so this should also be added alongside with the TCP port mapping.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Manually installing the X-Ray daemon to the instances via a user data script&nbsp;</strong></b><span>is incorrect because this is only applicable if your application is hosted in an EC2 instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding the&nbsp;xray-daemon.config&nbsp;configuration file in your Docker image</strong></b><span>&nbsp;is incorrect because this step is not suitable for ECS. The&nbsp;xray-daemon.config&nbsp;configuration file is primarily used in Elastic Beanstalk.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/scorekeep-ecs.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/scorekeep-ecs.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536699,
        "value": "Create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536700,
        "value": "Manually install the X-Ray daemon to the instances via a user data script.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536701,
        "value": "Configure the port mappings and network mode settings in your task definition file to allow traffic on UDP port 2000.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536702,
        "value": "Add the xray-daemon.config configuration file in your Docker image",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536703,
        "value": "Configure the port mappings and network mode settings in the container agent to allow traffic on TCP port 2000.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 24,
    "type": "MULTIPLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536699,
        "questionId": 383240,
        "response": null,
        "answerFeedback": null
      },
      {
        "isCorrect": true,
        "choiceId": 1536701,
        "questionId": 383240,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383240,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A Docker application hosted on an ECS cluster has encountered intermittent unavailability issues and timeouts. The lead DevOps engineer instructed you to instrument the application to detect where high latencies are occurring and to determine the specific services and paths impacting application performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following steps should you take to accomplish this task properly? (Select TWO.)</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808822,
    "question": "Elastic Beanstalk ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon CloudWatch agent</strong></b><span>&nbsp;enables you to collect both system metrics and log files from Amazon EC2 instances and on-premises servers. The agent supports both Windows Server and Linux and allows you to select the metrics to be collected, including sub-resource metrics such as per-CPU core.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(26).jpg\"><span>Metrics are data about the performance of your systems. By default, several services provide free metrics for resources (such as Amazon EC2 instances, Amazon EBS volumes, and Amazon RDS DB instances). You can also enable detailed monitoring on some resources, such as your Amazon EC2 instances, or publish your own application metrics. Amazon CloudWatch can load all the metrics in your account (both AWS resource metrics and application metrics that you provide) for search, graphing, and alarms.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>However, take note that CloudWatch does not monitor the memory, swap, and disk space utilization of your instances. If you need to track these metrics, you can install a CloudWatch agent in your EC2 instances.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CloudWatch does not track memory utilization by default.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The detailed monitoring is not enabled in CloudWatch</strong></b><span>&nbsp;is incorrect because&nbsp;this will just send metric data for your instance to CloudWatch in 1-minute periods, but not including the memory utilization.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">X-Ray Daemon is not installed to the EC2 instances</strong></b><span>&nbsp;is incorrect because X-Ray is primarily used for troubleshooting applications and not to monitor the actual EC2 instances. Even if the X-Ray Daemon is installed and is running in the instance, it will still not send the memory utilization metrics to CloudWatch.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:</span><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;The&nbsp;.ebextensions/xray-daemon.config&nbsp;file in Elastic Beanstalk is missing</strong></b><span>&nbsp;is incorrect because just like what is mentioned above, X-Ray will not send the memory utilization of the EC2 instance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536704,
        "value": "The .ebextensions/xray-daemon.config file in Elastic Beanstalk is missing.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536705,
        "value": "The detailed monitoring is not enabled in CloudWatch.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536706,
        "value": "CloudWatch does not track memory utilization by default.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536707,
        "value": "X-Ray Daemon is not installed on the EC2 instances.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 25,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": false,
        "choiceId": 1536707,
        "questionId": 383241,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383241,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A financial company has a cryptocurrency application that has been hosted in Elastic Beanstalk for a couple of months. Recently, the application’s performance has been degrading, so you decided to check the CPU and memory utilization of the underlying EC2 instances in CloudWatch. You can see the CPU utilization of the instances but not the memory utilization.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following is the MOST likely cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808823,
    "question": "API Gateway",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can monitor API execution using CloudWatch, which collects and processes raw data from API Gateway into readable, near-real-time metrics. These statistics are recorded for a period of two weeks so that you can access historical information and gain a better perspective on how your web application or service is performing. By default, API Gateway metric data is automatically sent to CloudWatch in one-minute periods.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(27).jpg\"><span>The metrics reported by API Gateway provide information that you can analyze in different ways. The list below shows some common uses for the metrics. These are suggestions to get you started, not a comprehensive list.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">IntegrationLatency</strong></b><span>&nbsp;metrics to measure the responsiveness of the backend.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Latency</strong></b><span>&nbsp;metrics to measure the overall responsiveness of your API calls.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;– Monitor the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheHitCount</strong></b><span>&nbsp;and&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">CacheMissCount</strong></b><span>&nbsp;metrics to optimize cache capacities to achieve a desired performance.&nbsp;CacheMissCount tracks the number of requests served from the backend in a given period,&nbsp;</span><u><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-underline___y38TS\">when API caching is enabled</strong></b></u><span>. On the other hand,&nbsp;CacheHitCount track the number of requests served from the API cache in a given period.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the root cause of this issue is that the&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">API Caching is not enabled in API Gateway&nbsp;</strong></b><span>which is why the&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">CacheHitCount</strong></b></i><span>&nbsp;and&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">CacheMissCount</strong></b></i><span>&nbsp;metrics are not populated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">they have not provided an IAM role to their API Gateway yet</strong></b><span>&nbsp;is incorrect because, in the first place, the scenario already mentioned that&nbsp;all metrics are being populated in their CloudWatch dashboard except for two metrics. This implies that some of the metrics are populated which means that the API Gateway already has an IAM Role associated with it.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">the provided IAM role to their API Gateway only has read access but no write privileges to CloudWatch</strong></b><span>&nbsp;is incorrect because just as what is mentioned above, there is no issue with the IAM Role since all metrics are being populated except only for&nbsp;CacheHitCount&nbsp;and&nbsp;CacheMissCount. This means that the associated IAM Role already has&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">write</em></i><span>&nbsp;privileges to write logs to CloudWatch to begin with. The only reason why those two metrics are not being populated is that the API Caching is not enabled.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">API Gateway Private Integrations has not been configured yet&nbsp;</strong></b><span>is incorrect because this feature only makes it easier to expose your HTTP/HTTPS resources behind an Amazon VPC for access by clients outside of the VPC.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring-cloudwatch.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring-cloudwatch.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536708,
        "value": "API Caching is not enabled in API Gateway.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536709,
        "value": "API Gateway Private Integrations has not been configured yet.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536710,
        "value": "They have not provided an IAM role to their API Gateway yet.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536711,
        "value": "The provided IAM role to their API Gateway only has read access but no write privileges to CloudWatch.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 26,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536708,
        "questionId": 383242,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383242,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A leading financial company has recently deployed its application to AWS using Lambda and API Gateway. However, they noticed that all metrics are being populated in their CloudWatch dashboard except for&nbsp;CacheHitCount&nbsp;and&nbsp;CacheMissCount.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What could be the MOST likely cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808824,
    "question": "Amazon API Gateway ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Amazon API Gateway Lambda proxy integration is a simple, powerful, and nimble mechanism to build an API with a setup of a single API method. The Lambda proxy integration allows the client to call a single Lambda function in the backend. The function accesses many resources or features of other AWS services, including calling other Lambda functions</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(28).jpg\"><span>In Lambda proxy integration, when a client submits an API request, API Gateway passes the raw request as-is to the integrated Lambda function, except that the order of the request parameters is not preserved. This&nbsp;</span><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-input-format\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>request data</span></a><span>&nbsp;includes the request headers, query string parameters, URL path variables, payload, and API configuration data. The configuration data can include current deployment stage name, stage variables, user identity, or authorization context (if any). The backend Lambda function parses the incoming request data to determine the response that it returns.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For API Gateway to pass the Lambda output as the API response to the client, the Lambda function must return the result in the following JSON format:</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>{</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>\"isBase64Encoded\": true|false,</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>\"statusCode\": httpStatusCode,</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>\"headers\": { \"headerName\": \"headerValue\", ... },</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>&nbsp;&nbsp;&nbsp; \"body\": \"...\"</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>}</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Since the Lambda function returns the result in XML format, it will cause the 502 errors in the API Gateway. Hence, the correct answer is that&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">there is an incompatible output returned from a Lambda proxy integration backend.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The API name of the Amazon API Gateway proxy</strong></b><span>&nbsp;is invalid is incorrect because there is nothing wrong with its&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">MyAPI</em></i><span>&nbsp;name.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">There has been an occasional out-of-order invocation due to heavy loads</strong></b><span>&nbsp;is incorrect. Although this is a valid cause of a 502 error, the issue is most likely caused by the Lambda function’s XML response instead of JSON.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">The endpoint request timed-out</strong></b><span>&nbsp;is incorrect because this will likely result in 504 errors and not 502’s.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/malformed-502-api-gateway/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://aws.amazon.com/premiumsupport/knowledge-center/malformed-502-api-gateway/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-output-format\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#api-gateway-simple-proxy-for-lambda-output-format</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/apigateway/api-reference/handling-errors/\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/apigateway/api-reference/handling-errors/</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536712,
        "value": "There is an incompatible output returned from a Lambda proxy integration backend.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536713,
        "value": "The endpoint request timed-out.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536714,
        "value": "There has been an occasional out-of-order invocation due to heavy loads.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536715,
        "value": "The API name of the Amazon API Gateway proxy is invalid.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 27,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536712,
        "questionId": 383243,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383243,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A developer configured an Amazon API Gateway proxy integration named&nbsp;MyAPI&nbsp;to work with a Lambda function. However, when the API is being called, the developer receives a&nbsp;502 Bad Gateway&nbsp;error. She tried invoking the underlying function, but it properly returned the result in XML format.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What is the MOST likely root cause of this issue?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808825,
    "question": "Elastic Beanstalk ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Even with sampling, a complex application generates a lot of data. The AWS X-Ray console provides an easy-to-navigate view of the service graph. It shows health and performance information that helps you identify issues and opportunities for optimization in your application. For advanced tracing, you can drill down to traces for individual requests, or use&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">filter expressions</strong></b><span>&nbsp;to find traces related to specific paths or users.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(29).jpg\"><span>When you instrument your application, the X-Ray SDK records information about incoming and outgoing requests, the AWS resources used, and the application itself. You can add other information to the segment document as annotations and metadata.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Annotations</strong></b><span>&nbsp;are simple key-value pairs that are indexed for use with&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>filter expressions</span></a><span>. Use annotations to record data that you want to use to group traces in the console or when calling the&nbsp;</span><a href=\"https://docs.aws.amazon.com/xray/latest/api/API_GetTraceSummaries.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>GetTraceSummaries</span></a><span>&nbsp;API. X-Ray indexes up to 50 annotations per trace.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Metadata</strong></b><span>&nbsp;are key-value pairs with values of any type, including objects and lists, but that is not indexed. Use metadata to record data you want to store in the trace but don’t need to use for searching traces. You can view annotations and metadata in the segment or subsegment details in the X-Ray console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A trace segment is a JSON representation of a request that your application serves. A trace segment records information about the original request, information about the work that your application does locally, and subsegments with information about downstream calls that your application makes to AWS resources, HTTP APIs, and SQL databases.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence,&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">adding annotations in the subsegment section of the segment document</strong></b><span>&nbsp;is the correct answer.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding annotations in the segment document&nbsp;</strong></b><span>is incorrect. Although the use of annotations is correct, you have to add this in the&nbsp;</span><i><b><strong class=\"Editor__editor-text-bold___25KrR Editor__editor-text-italic___C9n8O\">subsegment</strong></b></i><span>&nbsp;section of the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">segment</em></i><span>&nbsp;document since you want to trace the downstream call to RDS and not the actual request to your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding metadata in the segment document&nbsp;</strong></b><span>is incorrect because metadata is primarily used to record custom data that you want to store in the trace but not for searching traces since this can’t be picked up by filter expressions in the X-Ray Console. You have to use annotations instead. In addition, you have to add this in the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">subsegment</em></i><span>&nbsp;section of the&nbsp;</span><i><em class=\"Editor__editor-text-italic___C9n8O\">segment</em></i><span>&nbsp;document since you want to trace the downstream call to RDS and not the actual request to your application.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Adding metadata in the subsegment section of the segment document</strong></b><span>&nbsp;is incorrect because, just as mentioned above, metadata is just used to record custom data that you want to store in the trace but not for searching traces.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><b><strong class=\"Editor__editor-text-bold___25KrR\">&nbsp;</strong></b></p>",
    "choices": [
      {
        "id": 1536716,
        "value": "Add annotations in the segment document.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536717,
        "value": "Add annotations in the subsegment section of the segment document.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536718,
        "value": "Add metadata in the segment document.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536719,
        "value": "Add metadata in the subsegment section of the segment document",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 28,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536717,
        "questionId": 383244,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383244,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>A web application hosted in Elastic Beanstalk has a configuration file named&nbsp;.ebextensions/debugging.config&nbsp;which has the following content:</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>option_settings:</span><br><span> aws:elasticbeanstalk:xray:</span><br><span> XRayEnabled: true</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>For its database tier, it uses RDS with Multi-AZ deployments configuration and Read Replicas. There is a new requirement to record calls that your application makes to RDS and other internal or external HTTP web APIs. The tracing information should also include the actual SQL database queries sent by the application, which can be searched using the filter expressions in the X-Ray Console.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Which of the following should you do to satisfy the above task?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  },
  {
    "answerId": 38808826,
    "question": "Amazon Kinesis Data Stream ",
    "questionClass": "EDU",
    "hint": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">Amazon Kinesis Data Streams</strong></b><span>&nbsp;is a massively scalable, highly durable data ingestion and processing service optimized for streaming data. You can configure hundreds of thousands of data producers to continuously put data into a Kinesis data stream. Data will be available within milliseconds to your Amazon Kinesis applications, and those applications will receive data records in the order they were generated.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The purpose of resharding in Amazon Kinesis Data Streams is to enable your stream to adapt to changes in the rate of data flow. You split shards to increase the capacity (and cost) of your stream. You merge shards to reduce the cost (and capacity) of your stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>One approach to resharding could be to split every shard in the stream—which would double the stream’s capacity. However, this might provide more additional capacity than you actually need and, therefore, create unnecessary costs.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><img src=\"http://static.cdn.epam.com/uploads/edd5f87315fbce8b3b6bc0b7376c0f0e/Troubleshooting/Hint(30).jpg\"><span>You can also use metrics to determine which are your “hot” or “cold” shards, that is, shards that are receiving much more data or much less data than expected. You could then&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">selectively split the hot shards to increase capacity</strong></b><span>&nbsp;for the hash keys that target those shards. Similarly, you could merge cold shards to make better use of their unused capacity.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>You can obtain some performance data for your stream from the Amazon CloudWatch metrics that Kinesis Data Streams publishes. However, you can also collect some of your own metrics for your streams. One approach would be to log the hash key values generated by the partition keys for your data records. Recall that you specify the partition key at the time that you add the record to the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>Hence, the correct answer is:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Split every shard in the stream.</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Upgrade the instance type of the EC2 instances&nbsp;</strong></b><span>is incorrect. Although it will improve the processing time of the data in the stream, it will not increase the capacity of the stream itself. You have to reshard the stream in order to increase or decrease its capacity, and not just upgrade the EC2 instances which process the data in the stream.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Merge every shard in the stream</strong></b><span>&nbsp;is incorrect because&nbsp;merging shards will actually decrease the capacity of the stream rather than increase it. This is only useful if you want to save costs or if the data stream is underutilized, which are both not indicated in the scenario.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The option that says:&nbsp;</span><b><strong class=\"Editor__editor-text-bold___25KrR\">Integrate Amazon Data Firehose with the Amazon Kinesis Data Stream to increase the capacity of the stream</strong></b><i><em class=\"Editor__editor-text-italic___C9n8O\">&nbsp;</em></i><span>is incorrect because Data Firehose just provides a way to reliably transform and load streaming data into data stores and analytics tools. This method will not increase the capacity of the stream as it doesn’t mention anything about resharding.</span></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><b><strong class=\"Editor__editor-text-bold___25KrR\">References:</strong></b></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding-strategies.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding-strategies.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html\" target=\"_blank\" class=\"Editor__editor-link___3vl2C\"><span>https://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html</span></a></p><p class=\"Editor__editor-paragraph___HPmFS\"><span>&nbsp;</span></p>",
    "choices": [
      {
        "id": 1536720,
        "value": "Integrate Amazon Data Firehose with the Amazon Kinesis Data Stream to increase the capacity of the stream.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536721,
        "value": "Merge every shard in the stream.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536722,
        "value": "Upgrade the instance type of the EC2 instances.",
        "isCorrect": false,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      },
      {
        "id": 1536723,
        "value": "Split every shard in the stream.",
        "isCorrect": true,
        "isAdvancedEditor": false,
        "language": "",
        "responses": []
      }
    ],
    "idx": 29,
    "type": "SINGLE",
    "userAnswers": [
      {
        "isCorrect": true,
        "choiceId": 1536723,
        "questionId": 383245,
        "response": null,
        "answerFeedback": null
      }
    ],
    "exact": null,
    "isFinalScore": false,
    "media": {
      "audioUrl": null,
      "pictureUrl": null,
      "videoUrl": null
    },
    "score": null,
    "questionId": 383245,
    "description": "<p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>The developer has built a real-time IoT device monitoring application that leverages Amazon Kinesis Data Stream to ingest data. The application uses several EC2 instances for processing. Recently, the developer has observed a steady increase in the rate of data flowing into the stream, indicating that the stream’s capacity must be scaled up to sustain optimal performance.</span></p><p class=\"Editor__editor-paragraph___HPmFS\" dir=\"ltr\"><span>What should the developer do to increase the capacity of the stream?</span></p>",
    "language": "java",
    "file": null,
    "noMatchResponses": [],
    "answerReview": null,
    "answerFeedbacks": [],
    "topic": {
      "id": 8181,
      "name": "Troubleshooting and Optimization ",
      "skillId": "",
      "categoryId": 1623
    }
  }
]